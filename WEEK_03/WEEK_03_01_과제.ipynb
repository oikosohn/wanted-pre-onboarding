{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugGR7pnI4WSe"
      },
      "source": [
        "# Week3_1 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 토크나이징이 완료된 위키 백과 코퍼스를 다운받고 **단어 사전을 구축하는 함수를 구현**할 수 있다.\n",
        "- `Skip-Gram` 방식의 학습 데이터 셋을 생성하는 **Dataset과 Dataloader 클래스를 구현**할 수 있다.\n",
        "- **Negative Sampling** 함수를 구현할 수 있다. \n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- Skip-Gram을 학습 과정 튜토리얼을 따라하며, **Skip-Gram을 학습하는 클래스를 구현**할 수 있다. \n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- Skip-Gram 방식으로 word embedding을 학습하는 **Word2Vec 클래스를 구현**하고 실제로 학습할 수 있다.\n",
        "- 학습이 완료된 word embedding을 불러와 **Gensim 패키지를 사용해 유사한 단어**를 뽑을 수 있다. \n",
        "\n",
        "### Reference\n",
        "- [Skip-Gram negative sampling 한국어 튜토리얼](https://wikidocs.net/69141)\n",
        "    - (참고) 위 튜토리얼에서는 target word와 context word 페어의 레이블은 1로, target word와 negative sample word 페어의 레이블은 0이 되도록 학습 데이터를 구현해 binary classification을 구현한다. 하지만 우리는 word2vec 논문 방식을 그대로 따르기 위해 label을 생성하지 않고 대신 loss 함수를 변행해서 binary classification을 학습할 것이다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:29:36.641276Z",
          "start_time": "2022-02-19T14:29:36.638642Z"
        },
        "id": "HlEy3xfY4WSh"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:50:41.644583Z",
          "start_time": "2022-02-19T12:50:41.642937Z"
        },
        "id": "cBrr7-gt4jnf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:26:59.276355Z",
          "start_time": "2022-02-19T14:26:58.411434Z"
        },
        "id": "6mC9lhsJ4WSh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:30:05.586472Z",
          "start_time": "2022-02-19T14:30:05.583611Z"
        },
        "id": "17g7UZ5g4WSi"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:30:06.721039Z",
          "start_time": "2022-02-19T14:30:06.717559Z"
        },
        "id": "v3UlC7Jn4WSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165fa25c-6859-4b9f-fc85-88e77755de82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla K80\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8sfv5KY4WSk"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHs8_LU04WSj"
      },
      "source": [
        "### 토크나이징이 완료된 위키 백과 코퍼스 다운로드 및 불용어 사전 크롤링\n",
        "- 나의 구글 드라이브에 데이터를 다운받아 영구적으로 사용할 수 있도록 하자. \n",
        "    - [데이터 다운로드 출처](https://ratsgo.github.io/embedding/downloaddata.html)\n",
        "- 다운받은 데이터는 토크나이징이 완료된 상태이지만 불용어를 포함하고 있다. 따라서 향후 불용어를 제거하기 위해 불용어 사전을 크롤링하자. \n",
        "    - [불용어 사전 출처](https://www.ranks.nl/stopwords/korean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYiz1fdNsAqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81d2241-d551-48de-ba7a-01cf0af32b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:11.886643Z",
          "start_time": "2022-02-19T14:27:11.884858Z"
        },
        "id": "4QPBJ6UZ4WSj"
      },
      "outputs": [],
      "source": [
        "# 데이터 다운로드\n",
        "# !pip install gdown\n",
        "# !gdown https://drive.google.com/u/0/uc?id=1Ybp_DmzNEpsBrUKZ1-NoPDzCMO39f-fx\n",
        "\n",
        "# import zipfile\n",
        "# sample_zip = zipfile.ZipFile('/content/drive/MyDrive/원티드AIML/tokenized.zip')\n",
        "# sample_zip.extractall('/content/drive/MyDrive/원티드AIML/')\n",
        "# sample_zip.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:15.633947Z",
          "start_time": "2022-02-19T14:27:13.829982Z"
        },
        "id": "cTHCHmO24WSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da5cbcd-a121-46dd-8b24-08c014e9999b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ],
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:15.642775Z",
          "start_time": "2022-02-19T14:27:15.635333Z"
        },
        "id": "3d0IqhDF4WSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d5a729b-e6c3-4ab4-db0a-da3958c1300a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "stop_words[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t76Q1pQ4WSk"
      },
      "source": [
        "### 단어 사전 구축 함수 구현 \n",
        "- 문서 리스트를 입력 받아 사전을 생성하는 `make_vocab()` 함수를 구현하라.\n",
        "- 함수 정의\n",
        "    - 입력 매개변수\n",
        "        - docs : 문서 리스트\n",
        "        - min_count : 최소 단어 등장 빈도수 (단어 빈도가 `min_count` 미만인 단어는 사전에 포함하지 않음)\n",
        "    - 조건\n",
        "        - 문서 길이 제한\n",
        "            - 단어 개수가 3개 이하인 문서는 처리하지 않음. (skip)\n",
        "        - 사전에 포함되는 단어 빈도수 제한\n",
        "            - 단어가 빈도가 `min_count` 미만은 단어는 사전에 포함하지 않음.\n",
        "        - 불용어 제거 \n",
        "            - 불용어 리스트에 포함된 단어는 제거 \n",
        "    - 반환값 \n",
        "        - word2count : 단어별 빈도 사전 (key: 단어, value: 등장 횟수)\n",
        "        - wid2word : 단어별 인덱스(wid) 사전 (key: 단어 인덱스(int), value: 단어)\n",
        "        - word2wid : 인덱스(wid)별 단어 사전 (key: 단어, value: 단어 인덱스(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ta\n",
        "```\n",
        "# 코퍼스 로드\n",
        "_DATA_DIR=\"/content/drive/MyDrive/NLP강의/강의자료/tokenized\"\n",
        "\n",
        "with open(os.path.join(_DATA_DIR, \"wiki_ko_mecab.txt\")) as reader:\n",
        "    docs = reader.readlines()\n",
        "```"
      ],
      "metadata": {
        "id": "WDa0e_Uewl9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "data = open('/content/drive/MyDrive/원티드AIML/tokenized/wiki_ko_mecab.txt', 'r', encoding='utf-8')\n",
        "docs = data.readlines() # 전체 문장을 list에 저장하는 함수입니다."
      ],
      "metadata": {
        "id": "0gPJVIJgIdvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:03.423002Z",
          "start_time": "2022-02-19T14:33:03.419818Z"
        },
        "id": "WAKB6bbt4WSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8cc662-914d-47ed-82f0-ae1d366cf6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# wiki documents: 311,237\n"
          ]
        }
      ],
      "source": [
        "print(f\"# wiki documents: {len(docs):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:04.016885Z",
          "start_time": "2022-02-19T14:33:03.962269Z"
        },
        "id": "-OI1MCXv4WSl"
      },
      "outputs": [],
      "source": [
        "# 문서 개수를 500개로 줄임\n",
        "docs=random.sample(docs,500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"# wiki documents: {len(docs):,}\")"
      ],
      "metadata": {
        "id": "mP5wGu9YwDUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb14603e-1c94-4e93-bfa4-0cba88344727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# wiki documents: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:26.392627Z",
          "start_time": "2022-02-19T14:33:26.382358Z"
        },
        "id": "aJaEAVm9sAqv"
      },
      "outputs": [],
      "source": [
        "# 문서 내 숫자, 영어 대소문자, 특수문자를 제거 (re package 사용)\n",
        "import re\n",
        "docs = [re.sub('[^가-힣]', ' ', doc) for doc in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "bUxV3s_owwTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Check : {docs[0][:1000]}\")"
      ],
      "metadata": {
        "id": "sytiSICawMk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d23d525-8bc1-4d2b-f783-6bb8b716d6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check : 남모 공주            는 신라 의 공주   왕족 으로 법흥왕 과 보과 공주 부여 씨 의 딸 이 며 백제 동성왕 의 외손녀 였 다   경쟁자 인 준정 과 함께 신라 의 초대 여성 원화   화랑   였 다   그 가 준정 에게 암살 당한 것 을 계기 로 화랑 은 여성 이 아닌 남성 미소년 으로 선발 하 게 되 었 다   신라 진흥왕 에게 는 사촌 누나 이 자 이모 가 된다   신라 의 청소년 조직 이 었 던 화랑도 는 처음 에 는 남모   준정 두 미녀 를 뽑 아 이 를   원화 라 했으며 이 들 주위 에 는       여 명 의 무리 를 따르 게 하 였 다   그러나 준정 과 남모 는 서로 최고 가 되 고자 시기 하 였 다   준정 은 박영실 을 섬겼 는데   지소태후 는 자신 의 두 번 째 남편 이 기 도 한 그 를 싫어해서 준정 의 원화 를 없애 고 낭도 가 부족 한 남모 에게 위화랑 의 낭도 를 더 해 주 었 다   그 뒤 남모 는 준정 의 초대 로 그 의 집 에 갔 다가 억지로 권하 는 술 을 받아마시 고 취한 뒤 준정 에 의해 강물 에 던져져 살해 되 었 다   이 일 이 발각 돼 준 정도 사형 에 처해지 고 나라 에서 는 귀족 출신 의 잘 생기 고 품행 이 곧 은 남자 를 뽑 아 곱 게 단장 한 후 이 를 화랑 이 라 칭하 고 받들 게 하 였 다     부왕 신라 제     대 국왕 법흥왕 모후 보과 공주 부여 씨                   공주 남모 공주 외조부 백제 제     대 국왕 동성왕 외조모 신라 이찬 비지 의 딸   화랑전사 마루                  년   배우   박효빈   신라 법흥왕 백제 동성왕 준정 화랑 분류         년 죽음 분류   신라 의 왕녀 분류   신라 의 왕족 분류   화랑 분류   암살 된 사람 분류   독살 된 사람 분류   법흥왕 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "jydTQ80Cwv9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:26.392627Z",
          "start_time": "2022-02-19T14:33:26.382358Z"
        },
        "id": "V_R8kOo6CmWF",
        "outputId": "34460cce-e1df-4562-8ee7-cfed626405ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check : 남모 공주  南 毛 公主  는 신라 의 공주  왕족 으로 법흥왕 과 보과 공주 부여 씨 의 딸 이 며 백제 동성왕 의 외손녀 였 다  경쟁자 인 준정 과 함께 신라 의 초대 여성 원화  화랑  였 다  그 가 준정 에게 암살 당한 것 을 계기 로 화랑 은 여성 이 아닌 남성 미소년 으로 선발 하 게 되 었 다  신라 진흥왕 에게 는 사촌 누나 이 자 이모 가 된다  신라 의 청소년 조직 이 었 던 화랑도 는 처음 에 는 남모  준정 두 미녀 를 뽑 아 이 를  원화 라 했으며 이 들 주위 에 는    여 명 의 무리 를 따르 게 하 였 다  그러나 준정 과 남모 는 서로 최고 가 되 고자 시기 하 였 다  준정 은 박영실 을 섬겼 는데  지소태후 는 자신 의 두 번 째 남편 이 기 도 한 그 를 싫어해서 준정 의 원화 를 없애 고 낭도 가 부족 한 남모 에게 위화랑 의 낭도 를 더 해 주 었 다  그 뒤 남모 는 준정 의 초대 로 그 의 집 에 갔 다가 억지로 권하 는 술 을 받아마시 고 취한 뒤 준정 에 의해 강물 에 던져져 살해 되 었 다  이 일 이 발각 돼 준 정도 사형 에 처해지 고 나라 에서 는 귀족 출신 의 잘 생기 고 품행 이 곧 은 남자 를 뽑 아 곱 게 단장 한 후 이 를 화랑 이 라 칭하 고 받들 게 하 였 다   부왕 신라 제   대 국왕 법흥왕 모후 보과 공주 부여 씨  宝 果 公主 扶餘 氏   공주 남모 공주 외조부 백제 제   대 국왕 동성왕 외조모 신라 이찬 비지 의 딸  화랑전사 마루        년  배우  박효빈  신라 법흥왕 백제 동성왕 준정 화랑 분류     년 죽음 분류  신라 의 왕녀 분류  신라 의 왕족 분류  화랑 분류  암살 된 사람 분류  독살 된 사람 분류  법흥왕\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 문서 내 숫자, 영어 대소문자, 특수문자를 제거\n",
        "docs = [re.sub('[0-9a-zA-Z-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘〈〉|\\(\\)\\[\\]\\<\\>`\\'…》《]','', doc) for doc in docs]\n",
        "print(f\"Check : {docs[0][:1000]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "tsEkZpQnw5y9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:27.904880Z",
          "start_time": "2022-02-19T14:33:27.899620Z"
        },
        "id": "OAkkQsvO4WSl"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def make_vocab(docs:List[str], min_count:int):\n",
        "    \"\"\"\n",
        "    'docs'문서 리스트를 입력 받아 단어 사전을 생성.\n",
        "    \n",
        "    return \n",
        "        - word2count : 단어별 빈도 사전\n",
        "        - wid2word : 단어별 인덱스(wid) 사전 \n",
        "        - word2wid : 인덱스(wid)별 단어 사전\n",
        "    \"\"\"    \n",
        "    word2count = Counter()\n",
        "    word2id = dict()\n",
        "    id2word = dict()\n",
        "    \n",
        "    for doc in tqdm(docs):\n",
        "        word_list = doc.split()\n",
        "\n",
        "        # 1. 문서 길이 제한\n",
        "        # 2. 임시 딕셔너리(_word2count)에 단어별 등장 빈도 기록\n",
        "        # 3. 불용어 제거\n",
        "\n",
        "        # 불용어 제거\n",
        "        wo_sw_list = [word for word in word_list if not word in stop_words]\n",
        "\n",
        "        # 문서 길이 제한\n",
        "        if len(wo_sw_list) < 4:\n",
        "            continue\n",
        "\n",
        "        # 임시 딕셔너리(_word2count)에 단어별 등장 빈도 기록\n",
        "        _word2count = Counter(wo_sw_list)\n",
        "        dict.update(word2count, _word2count)\n",
        "\n",
        "    # 4. 토큰 최소 빈도를 만족하는 토큰만 사전에 추가\n",
        "    word2count = {key:value for key, value in word2count.items() if value >= min_count}\n",
        "    word2id = {key: idx for idx, (key, value) in enumerate(word2count.items())}\n",
        "    id2word = {idx: word for word, idx in word2id.items()}\n",
        "    return word2count, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_vocab(docs, min_count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XdBBMb1KyC9",
        "outputId": "31a76337-d108-4142-a7f5-3377d90397e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:03<00:00, 147.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'남모': 6,\n",
              "  '는': 14,\n",
              "  '준정': 9,\n",
              "  '화랑': 155,\n",
              "  '었': 10,\n",
              "  '주': 5,\n",
              "  '생산': 6,\n",
              "  '직경': 7,\n",
              "  '톤': 7,\n",
              "  '버전': 6,\n",
              "  '너지': 14,\n",
              "  '헝가리': 7,\n",
              "  '선수': 14,\n",
              "  '여자': 5,\n",
              "  '올림픽': 9,\n",
              "  '대포': 6,\n",
              "  '파이어': 8,\n",
              "  '구형': 5,\n",
              "  '미사일': 5,\n",
              "  '중국': 6,\n",
              "  '홍': 19,\n",
              "  '국수': 25,\n",
              "  '쿠스': 10,\n",
              "  '파우': 8,\n",
              "  '문자열': 11,\n",
              "  '시동': 6,\n",
              "  '입력': 5,\n",
              "  '사운드': 40,\n",
              "  '가장': 6,\n",
              "  '검사': 9,\n",
              "  '캐시': 9,\n",
              "  '호출': 7,\n",
              "  '게임': 5,\n",
              "  '섹션': 8,\n",
              "  '프로세서': 13,\n",
              "  '청안': 6,\n",
              "  '선남': 5,\n",
              "  '라마': 8,\n",
              "  '일본': 5,\n",
              "  '함대': 5,\n",
              "  '윤인완': 7,\n",
              "  '만들': 5,\n",
              "  '기원전': 20,\n",
              "  '종교': 5,\n",
              "  '가톨릭교회': 21,\n",
              "  '성': 9,\n",
              "  '보': 10,\n",
              "  '정부': 5,\n",
              "  '루이': 5,\n",
              "  '시녀': 5,\n",
              "  '아라곤': 10,\n",
              "  '유럽': 12,\n",
              "  '왕': 5,\n",
              "  '서': 7,\n",
              "  '영혼': 31,\n",
              "  '머리': 11,\n",
              "  '읍': 6,\n",
              "  '코지마': 6,\n",
              "  '극장판': 6,\n",
              "  '마사키': 31,\n",
              "  '오기노': 5,\n",
              "  '포맷': 6,\n",
              "  '스톤': 23,\n",
              "  '음반': 13,\n",
              "  '차트': 6,\n",
              "  '시몬스': 9,\n",
              "  '이사벨라': 10,\n",
              "  '콘스탄티누스': 12,\n",
              "  '혼인': 22,\n",
              "  '유지': 8,\n",
              "  '대머리': 8,\n",
              "  '우': 5,\n",
              "  '아종': 33,\n",
              "  '까': 12,\n",
              "  '숲': 9,\n",
              "  '필터': 24,\n",
              "  '기름': 6,\n",
              "  '청소': 10,\n",
              "  '구매': 6,\n",
              "  '기호': 6,\n",
              "  '주포': 5,\n",
              "  '램': 9,\n",
              "  '묶': 8,\n",
              "  '앙각': 5,\n",
              "  '분당': 5,\n",
              "  '커스': 5,\n",
              "  '갖추': 11,\n",
              "  '팽': 23,\n",
              "  '축구': 17,\n",
              "  '리그': 6,\n",
              "  '가제': 8,\n",
              "  '곡': 7,\n",
              "  '작곡': 10,\n",
              "  '테레비': 7,\n",
              "  '엘리': 8,\n",
              "  '펀트': 8,\n",
              "  '카운티': 6,\n",
              "  '알렉산드라': 10,\n",
              "  '나리': 20,\n",
              "  '시인': 6,\n",
              "  '가선': 36,\n",
              "  '친왕': 7,\n",
              "  '정': 9,\n",
              "  '가인': 6,\n",
              "  '고킨와카슈': 5,\n",
              "  '돌': 5,\n",
              "  '정치': 5,\n",
              "  '광': 8,\n",
              "  '야간': 7,\n",
              "  '포테마요': 15,\n",
              "  '코믹': 15,\n",
              "  '화': 20,\n",
              "  '스나오': 18,\n",
              "  '고양이': 8,\n",
              "  '메이트': 6,\n",
              "  '미캉': 10,\n",
              "  '모리야마': 9,\n",
              "  '땅': 9,\n",
              "  '원래': 5,\n",
              "  '구간': 18,\n",
              "  '코오롱': 61,\n",
              "  '조정': 6,\n",
              "  '인더스': 6,\n",
              "  '주식': 5,\n",
              "  '의류': 7,\n",
              "  '자동차': 6,\n",
              "  '부품': 6,\n",
              "  '케어': 8,\n",
              "  '션': 9,\n",
              "  '리조트': 5,\n",
              "  '적자': 10,\n",
              "  '메트로폴리탄': 11,\n",
              "  '카슈미르': 8,\n",
              "  '이끄': 5,\n",
              "  '콤': 6,\n",
              "  '갈라파고스': 16,\n",
              "  '갈색': 5,\n",
              "  '생물': 5,\n",
              "  '이사벨': 12,\n",
              "  '출장': 20,\n",
              "  '오쿠노': 13,\n",
              "  '성씨': 7,\n",
              "  '역': 38,\n",
              "  '교': 5,\n",
              "  '레고': 15,\n",
              "  '완구': 6,\n",
              "  '픽셀': 17,\n",
              "  '공략': 8,\n",
              "  '트랜스포머': 5,\n",
              "  '휴대': 5,\n",
              "  '전화': 5,\n",
              "  '기종': 5,\n",
              "  '이성주': 6,\n",
              "  '영화제': 8,\n",
              "  '권은희': 12,\n",
              "  '국회의원': 5,\n",
              "  '도입': 5,\n",
              "  '경찰서': 6,\n",
              "  '수서': 7,\n",
              "  '희': 5,\n",
              "  '위증': 7,\n",
              "  '앞': 5,\n",
              "  '손질': 7,\n",
              "  '처분': 10,\n",
              "  '수석': 5,\n",
              "  '인텔': 50,\n",
              "  '칩': 8,\n",
              "  '코어': 47,\n",
              "  '포레스트': 13,\n",
              "  '오페라': 5,\n",
              "  '하버드': 6,\n",
              "  '래피드': 39,\n",
              "  '마이너': 38,\n",
              "  '마이닝': 5,\n",
              "  '회로': 8,\n",
              "  '숨': 36,\n",
              "  '버그': 13,\n",
              "  '커뮤니티': 18,\n",
              "  '업데이트': 5,\n",
              "  '계산': 5,\n",
              "  '쿼드': 5,\n",
              "  '유료': 8,\n",
              "  '대부분': 5,\n",
              "  '불후': 10,\n",
              "  '발매': 6,\n",
              "  '상륙': 5,\n",
              "  '애쉬': 5,\n",
              "  '주말': 6,\n",
              "  '인생': 15,\n",
              "  '심사': 5,\n",
              "  '국민주의': 21,\n",
              "  '교황': 6,\n",
              "  '스튜어트': 5,\n",
              "  '자율': 5,\n",
              "  '혁명': 8,\n",
              "  '최': 14,\n",
              "  '학회': 9,\n",
              "  '사이클': 6,\n",
              "  '밴': 9,\n",
              "  '드로잉': 12,\n",
              "  '모형': 8,\n",
              "  '교통': 8,\n",
              "  '오카야마': 5,\n",
              "  '대검찰청': 5,\n",
              "  '수부': 5,\n",
              "  '검사장': 5,\n",
              "  '사무소': 18,\n",
              "  '한나라당': 5,\n",
              "  '사찰': 12,\n",
              "  '하차': 17,\n",
              "  '파일럿': 9,\n",
              "  '온주쿠': 6,\n",
              "  '나미': 7,\n",
              "  '철도': 5,\n",
              "  '부산': 8,\n",
              "  '배명': 7,\n",
              "  '루수': 6,\n",
              "  '언급': 8,\n",
              "  '드래': 10,\n",
              "  '깅': 10,\n",
              "  '인디언': 42,\n",
              "  '투쟁': 5,\n",
              "  '버지니아': 9,\n",
              "  '테네시': 5,\n",
              "  '어퍼': 10,\n",
              "  '행동': 5,\n",
              "  '프랑스령': 5,\n",
              "  '미시시피': 7,\n",
              "  '플로리다': 8,\n",
              "  '사우스': 5,\n",
              "  '캐롤라이나': 11,\n",
              "  '이로쿼이': 12,\n",
              "  '요새': 72,\n",
              "  '오하': 5,\n",
              "  '오하이오': 27,\n",
              "  '영토': 5,\n",
              "  '로버트슨': 6,\n",
              "  '퇴거': 6,\n",
              "  '헨더슨': 18,\n",
              "  '쿨라': 6,\n",
              "  '경고': 5,\n",
              "  '해밀턴': 7,\n",
              "  '기습': 10,\n",
              "  '민병대': 8,\n",
              "  '포로': 7,\n",
              "  '교향악단': 8,\n",
              "  '순천': 5,\n",
              "  '응진': 8,\n",
              "  '탱': 10,\n",
              "  '나한도': 5,\n",
              "  '제석': 5,\n",
              "  '존자': 6,\n",
              "  '암벽': 5,\n",
              "  '비트': 5,\n",
              "  '돌격': 7,\n",
              "  '낚시': 7,\n",
              "  '헤이그': 7,\n",
              "  '윤': 18,\n",
              "  '남근': 6,\n",
              "  '교육청': 6,\n",
              "  '시범': 5,\n",
              "  '크리어': 20,\n",
              "  '북미': 11,\n",
              "  '고리': 9,\n",
              "  '벡터': 25,\n",
              "  '접': 11,\n",
              "  '호모': 5,\n",
              "  '토피': 5,\n",
              "  '지하철': 6,\n",
              "  '시즈먼': 6,\n",
              "  '운행': 32,\n",
              "  '회전': 18,\n",
              "  '노선': 61,\n",
              "  '시간표': 8,\n",
              "  '미츠키': 6,\n",
              "  '미쓰키': 7,\n",
              "  '다무라': 7,\n",
              "  '트레버': 17,\n",
              "  '리전': 16,\n",
              "  '비아': 7,\n",
              "  '과업': 32,\n",
              "  '회피': 16,\n",
              "  '측면': 9,\n",
              "  '피드백': 16,\n",
              "  '끝내': 6,\n",
              "  '대개': 7,\n",
              "  '욕구': 7,\n",
              "  '메타분석': 5,\n",
              "  '결합': 8,\n",
              "  '효능감': 14,\n",
              "  '경혜': 22,\n",
              "  '군주': 6,\n",
              "  '묘지': 8,\n",
              "  '재산': 26,\n",
              "  '성종': 10,\n",
              "  '김포': 5,\n",
              "  '민': 6,\n",
              "  '엔진': 11,\n",
              "  '프렌즈': 5,\n",
              "  '하코다테': 11,\n",
              "  '미자': 5,\n",
              "  '아사히카와': 5,\n",
              "  '전동차': 8,\n",
              "  '전철': 22,\n",
              "  '에어포트': 9,\n",
              "  '신모리야마': 6,\n",
              "  '주오': 6,\n",
              "  '열차': 14,\n",
              "  '컨테이너': 12,\n",
              "  '맥주': 5,\n",
              "  '가온': 8,\n",
              "  '크리스마스': 7,\n",
              "  '탄생불': 6,\n",
              "  '입상': 5,\n",
              "  '불상': 7,\n",
              "  '띠': 5,\n",
              "  '비례': 5,\n",
              "  '도덕경': 15,\n",
              "  '노자': 14,\n",
              "  '판본': 7,\n",
              "  '왕필': 17,\n",
              "  '갑': 7,\n",
              "  '터널': 5,\n",
              "  '법칙': 7,\n",
              "  '케임브리지': 7,\n",
              "  '왕립': 7,\n",
              "  '성인': 5,\n",
              "  '정교회': 7,\n",
              "  '올스타': 5,\n",
              "  '대수': 21,\n",
              "  '천문대': 6,\n",
              "  '융합': 12,\n",
              "  '체코슬로바키아': 6,\n",
              "  '위임': 7,\n",
              "  '슈테': 9,\n",
              "  '마장': 22,\n",
              "  '반프레스토': 5,\n",
              "  '본작': 5,\n",
              "  '류네': 7,\n",
              "  '바스': 10,\n",
              "  '슈우': 27,\n",
              "  '남극': 6,\n",
              "  '대결': 5,\n",
              "  '기아스': 11,\n",
              "  '랑그': 12,\n",
              "  '왕국': 9,\n",
              "  '오졸': 5,\n",
              "  '정복': 8,\n",
              "  '론도': 15,\n",
              "  '알리': 10,\n",
              "  '태조': 6,\n",
              "  '태평동': 7,\n",
              "  '챔니스': 9,\n",
              "  '곤살로': 52,\n",
              "  '코르도바': 6,\n",
              "  '뇰라': 7,\n",
              "  '참호': 8,\n",
              "  '페르난도': 5,\n",
              "  '그라나다': 6,\n",
              "  '나폴리': 8,\n",
              "  '창병': 13,\n",
              "  '중장기병': 7,\n",
              "  '공성전': 7,\n",
              "  '전축': 5,\n",
              "  '오스만': 15,\n",
              "  '지휘관': 6,\n",
              "  '총독': 11,\n",
              "  '합스부르크': 12,\n",
              "  '카우': 5,\n",
              "  '아퀴나스': 84,\n",
              "  '수도회': 11,\n",
              "  '카시노': 5,\n",
              "  '알베르투스': 19,\n",
              "  '인문': 6,\n",
              "  '벙어리': 6,\n",
              "  '황소': 6,\n",
              "  '영민': 5,\n",
              "  '덩치': 7,\n",
              "  '오르비에토': 5,\n",
              "  '댁': 5,\n",
              "  '상징': 7,\n",
              "  '신학대전': 9,\n",
              "  '펜': 15,\n",
              "  '영원': 12,\n",
              "  '벌': 14,\n",
              "  '미완성': 7,\n",
              "  '미사': 10,\n",
              "  '공의회': 7,\n",
              "  '진위': 8,\n",
              "  '교리': 23,\n",
              "  '은총': 10,\n",
              "  '식물': 15,\n",
              "  '성공회': 6,\n",
              "  '대한제국': 21,\n",
              "  '일진회': 9,\n",
              "  '남원': 5,\n",
              "  '유로': 6,\n",
              "  '아야사토': 5,\n",
              "  '카트린느': 7,\n",
              "  '아이브': 6,\n",
              "  '하이츠': 16,\n",
              "  '훈장': 5,\n",
              "  '경시': 15,\n",
              "  '구두': 7,\n",
              "  '김동훈': 7,\n",
              "  '교단': 5,\n",
              "  '안수': 6,\n",
              "  '예수교': 5,\n",
              "  '장로회': 5,\n",
              "  '타이베이': 7,\n",
              "  '총통': 11,\n",
              "  '장왕': 7,\n",
              "  '진나라': 16,\n",
              "  '민중': 9,\n",
              "  '서진': 6,\n",
              "  '한족': 7,\n",
              "  '관중': 6,\n",
              "  '서하': 9,\n",
              "  '기도': 18,\n",
              "  '매춘': 10,\n",
              "  '명품': 15,\n",
              "  '합당': 6,\n",
              "  '북한': 6,\n",
              "  '안기부': 11,\n",
              "  '노태우': 7,\n",
              "  '가오리': 7,\n",
              "  '뿌': 10,\n",
              "  '기라티나': 32,\n",
              "  '포켓몬스터': 6,\n",
              "  '디아루가': 12,\n",
              "  '펄기아': 9,\n",
              "  '포켓몬': 12,\n",
              "  '어나더': 6,\n",
              "  '깨어진': 5,\n",
              "  '오리진': 8,\n",
              "  '섀도': 5,\n",
              "  '다이브': 5,\n",
              "  '퀸': 5,\n",
              "  '전송': 13,\n",
              "  '실버': 7,\n",
              "  '쉐': 5,\n",
              "  '팔츠': 6,\n",
              "  '에른스트': 6,\n",
              "  '세례': 7,\n",
              "  '로키산': 9,\n",
              "  '홍반': 9,\n",
              "  '감염병': 5,\n",
              "  '물기': 10,\n",
              "  '공예': 5,\n",
              "  '헬스': 5,\n",
              "  '콜로부스': 15,\n",
              "  '규슈': 11,\n",
              "  '플라자': 23,\n",
              "  '원담': 11,\n",
              "  '랜드': 15,\n",
              "  '라이온스': 5,\n",
              "  '특유재산': 6,\n",
              "  '민법': 5,\n",
              "  '무인': 9,\n",
              "  '니시지마': 5,\n",
              "  '우상': 10,\n",
              "  '스트로베리': 7,\n",
              "  '나이트': 7,\n",
              "  '카즈': 7,\n",
              "  '프리미엄': 5,\n",
              "  '레인': 19,\n",
              "  '내레이션': 8,\n",
              "  '신자': 7,\n",
              "  '내일': 5,\n",
              "  '케이크': 12,\n",
              "  '크림': 5,\n",
              "  '치즈': 7,\n",
              "  '간장': 7,\n",
              "  '피트': 6,\n",
              "  '이강주': 11,\n",
              "  '울금': 5,\n",
              "  '냄새': 5,\n",
              "  '스맥다운': 8,\n",
              "  '이기': 12,\n",
              "  '우소': 5,\n",
              "  '케인': 12,\n",
              "  '익스트림': 6,\n",
              "  '기야마': 5,\n",
              "  '가고시마': 5,\n",
              "  '후쿠오카': 45,\n",
              "  '야쿠': 15,\n",
              "  '미야노': 6,\n",
              "  '육상': 14,\n",
              "  '야쿠시마': 8,\n",
              "  '폭포': 10,\n",
              "  '로켓': 5,\n",
              "  '다이요': 6,\n",
              "  '피겨': 7,\n",
              "  '스케이팅': 7,\n",
              "  '슈저우': 11,\n",
              "  '야스케': 5,\n",
              "  '노부나가': 7,\n",
              "  '제천시': 5,\n",
              "  '단양군': 13,\n",
              "  '제천군': 6,\n",
              "  '선거구': 15,\n",
              "  '로케': 5,\n",
              "  '팔레': 7,\n",
              "  '스카': 5,\n",
              "  '레미콘': 8,\n",
              "  '골재': 12,\n",
              "  '배합': 6,\n",
              "  '슬래그': 5,\n",
              "  '숙의': 5,\n",
              "  '명종': 19,\n",
              "  '하딩': 10,\n",
              "  '판화': 12,\n",
              "  '몽실이': 11,\n",
              "  '몽실': 5,\n",
              "  '주사': 10,\n",
              "  '호아': 7,\n",
              "  '무덤': 7,\n",
              "  '여단': 16,\n",
              "  '뉴기니': 5,\n",
              "  '워든': 77,\n",
              "  '정규군': 5,\n",
              "  '진승': 26,\n",
              "  '오광': 11,\n",
              "  '부리': 7,\n",
              "  '진여': 5,\n",
              "  '진현': 6,\n",
              "  '형양': 5,\n",
              "  '진가': 7,\n",
              "  '이세황제': 6,\n",
              "  '장한': 13,\n",
              "  '장초군': 5,\n",
              "  '항량': 8,\n",
              "  '코넬': 20,\n",
              "  '농장': 10,\n",
              "  '순차': 5,\n",
              "  '피자': 14,\n",
              "  '페트라': 40,\n",
              "  '장관': 6,\n",
              "  '까마귀': 11,\n",
              "  '울음': 10,\n",
              "  '아제르바이잔': 9,\n",
              "  '크로마': 38,\n",
              "  '샘플링': 36,\n",
              "  '색차': 6,\n",
              "  '인코딩': 6,\n",
              "  '루마': 18,\n",
              "  '컴포넌트': 17,\n",
              "  '에일리어싱': 7,\n",
              "  '비월': 5,\n",
              "  '화소': 15,\n",
              "  '베른하르트': 9,\n",
              "  '방정식': 5,\n",
              "  '일식': 15,\n",
              "  '미적분학': 5,\n",
              "  '역학': 16,\n",
              "  '사회주의': 5,\n",
              "  '반공': 5,\n",
              "  '분자': 18,\n",
              "  '차관': 19,\n",
              "  '국민운동': 6,\n",
              "  '중앙일보': 5,\n",
              "  '쿠르디스탄': 5,\n",
              "  '프랑크푸르트': 6,\n",
              "  '반납': 9,\n",
              "  '센트': 9,\n",
              "  '계란': 22,\n",
              "  '수선': 12,\n",
              "  '미원': 6,\n",
              "  '기암': 6,\n",
              "  '멩거': 9,\n",
              "  '박서보': 44,\n",
              "  '미술가': 10,\n",
              "  '홍익': 21,\n",
              "  '종로': 7,\n",
              "  '서보': 5,\n",
              "  '현대전': 10,\n",
              "  '묘법': 14,\n",
              "  '단색화': 11,\n",
              "  '국전': 14,\n",
              "  '조형': 7,\n",
              "  '박람회': 7,\n",
              "  '인테리어': 5,\n",
              "  '이우환': 9,\n",
              "  '무라마츠': 5,\n",
              "  '대부': 59,\n",
              "  '박영덕': 7,\n",
              "  '조현': 15,\n",
              "  '바젤': 32,\n",
              "  '박여숙': 25,\n",
              "  '조현화': 7,\n",
              "  '샘터': 49,\n",
              "  '박람': 5,\n",
              "  '국제무역센터': 6,\n",
              "  '전람': 14,\n",
              "  '대청': 10,\n",
              "  '코엑스': 13,\n",
              "  '경복궁': 18,\n",
              "  '인전': 6,\n",
              "  '비엔날레': 12,\n",
              "  '협': 8,\n",
              "  '당전': 6,\n",
              "  '현대미': 28,\n",
              "  '술제': 25,\n",
              "  '윤형근': 9,\n",
              "  '김창렬': 13,\n",
              "  '도립': 6,\n",
              "  '송년': 6,\n",
              "  '흥원': 13,\n",
              "  '관훈': 22,\n",
              "  '정창섭': 10,\n",
              "  '로이드': 8,\n",
              "  '컨벤션': 8,\n",
              "  '강릉': 8,\n",
              "  '네이비': 10,\n",
              "  '멜번': 8,\n",
              "  '팜': 10,\n",
              "  '마이애미비치': 6,\n",
              "  '요미우리': 9,\n",
              "  '포스트': 5,\n",
              "  '탕': 5,\n",
              "  '큐브': 6,\n",
              "  '코지': 5,\n",
              "  '와일드': 11,\n",
              "  '프라임': 11,\n",
              "  '진로': 5,\n",
              "  '카트': 6,\n",
              "  '옹주': 12,\n",
              "  '감비아': 5,\n",
              "  '마산역': 47,\n",
              "  '경전선': 12,\n",
              "  '무궁화호': 6,\n",
              "  '산역': 6,\n",
              "  '부전': 10,\n",
              "  '디젤': 13,\n",
              "  '새마을호': 7,\n",
              "  '환승': 5,\n",
              "  '주차': 9,\n",
              "  '장악원': 7,\n",
              "  '융준': 5,\n",
              "  '철종': 21,\n",
              "  '즉석': 10,\n",
              "  '라이프치히': 10,\n",
              "  '정무': 20,\n",
              "  '비틀즈': 10,\n",
              "  '매카트니': 13,\n",
              "  '링고': 8,\n",
              "  '농어촌버스': 5,\n",
              "  '데라우치': 6,\n",
              "  '식물상': 22,\n",
              "  '클리어타입': 29,\n",
              "  '렌더링': 18,\n",
              "  '내장': 11,\n",
              "  '비트맵': 5,\n",
              "  '밀퍼드': 10,\n",
              "  '뉴질랜드': 9,\n",
              "  '트램': 7,\n",
              "  '맥키넌': 9,\n",
              "  '캠핑': 18,\n",
              "  '점심': 6,\n",
              "  '센스': 5,\n",
              "  '삼도': 6,\n",
              "  '용담': 6,\n",
              "  '노형동': 5,\n",
              "  '제주시': 46,\n",
              "  '와인': 10,\n",
              "  '이즈': 10,\n",
              "  '드라이브': 22,\n",
              "  '카터': 7,\n",
              "  '봉성군': 36,\n",
              "  '희빈': 6,\n",
              "  '윤임': 5,\n",
              "  '목욕': 5,\n",
              "  '니지마': 9,\n",
              "  '쿠사야': 9,\n",
              "  '건어물': 7,\n",
              "  '하치조': 5,\n",
              "  '소금물': 5,\n",
              "  '교통국': 9,\n",
              "  '드골': 6,\n",
              "  '프레더릭': 8,\n",
              "  '안사': 5,\n",
              "  '곡초': 7,\n",
              "  '양초': 5,\n",
              "  '사천시': 5,\n",
              "  '마도': 6,\n",
              "  '천초': 5,\n",
              "  '배영': 7,\n",
              "  '유대교': 6,\n",
              "  '민해경': 6,\n",
              "  '마젤란': 6,\n",
              "  '피그미': 10,\n",
              "  '테니스': 5,\n",
              "  '배구': 8,\n",
              "  '하치로가타': 6,\n",
              "  '함장': 8,\n",
              "  '수향': 6,\n",
              "  '저우장': 11,\n",
              "  '심만삼': 6,\n",
              "  '명물': 5,\n",
              "  '기저': 34,\n",
              "  '회생': 8,\n",
              "  '아파트': 5,\n",
              "  '청자': 5,\n",
              "  '상감': 7,\n",
              "  '용봉': 6,\n",
              "  '그릇': 8,\n",
              "  '숟가락': 5,\n",
              "  '황모': 5,\n",
              "  '히코네': 7,\n",
              "  '급행': 8,\n",
              "  '비바': 9,\n",
              "  '뉴마켓': 91,\n",
              "  '핀치': 89,\n",
              "  '멀록': 36,\n",
              "  '오처드': 12,\n",
              "  '블루밍턴': 17,\n",
              "  '제퍼슨': 23,\n",
              "  '엘긴': 83,\n",
              "  '밀스': 163,\n",
              "  '크로스비': 21,\n",
              "  '매켄지': 166,\n",
              "  '웰드': 14,\n",
              "  '카빌': 13,\n",
              "  '리치먼드힐': 101,\n",
              "  '상시': 61,\n",
              "  '아워': 76,\n",
              "  '마컴': 118,\n",
              "  '스토우': 56,\n",
              "  '비버': 26,\n",
              "  '크리크': 35,\n",
              "  '레슬리': 90,\n",
              "  '우드바인': 77,\n",
              "  '몽고메리': 6,\n",
              "  '버치': 29,\n",
              "  '벌록': 6,\n",
              "  '매코': 65,\n",
              "  '갤': 5,\n",
              "  '스워': 5,\n",
              "  '우튼': 15,\n",
              "  '빌리지': 33,\n",
              "  '파크웨이': 15,\n",
              "  '유니언': 27,\n",
              "  '그로브': 52,\n",
              "  '키플링': 17,\n",
              "  '이즐링턴': 35,\n",
              "  '더퍼린': 54,\n",
              "  '미너': 17,\n",
              "  '배서스트': 112,\n",
              "  '공휴일': 6,\n",
              "  '데니슨': 24,\n",
              "  '세네카': 13,\n",
              "  '레이크': 14,\n",
              "  '복스': 21,\n",
              "  '월마트': 17,\n",
              "  '밀리켄': 6,\n",
              "  '코원': 10,\n",
              "  '루지': 12,\n",
              "  '엘슨': 5,\n",
              "  '파이어니어': 19,\n",
              "  '메이플': 22,\n",
              "  '오크': 31,\n",
              "  '버러': 8,\n",
              "  '후버': 6,\n",
              "  '우드브릿지': 9,\n",
              "  '스태프': 39,\n",
              "  '슬리': 7,\n",
              "  '나파밸리': 13,\n",
              "  '러더퍼드': 81,\n",
              "  '밀러드': 10,\n",
              "  '오토': 6,\n",
              "  '헌팅': 6,\n",
              "  '셰퍼드': 17,\n",
              "  '엘즈미어': 7,\n",
              "  '마운트조이': 19,\n",
              "  '테스': 16,\n",
              "  '킹시티': 5,\n",
              "  '우즈': 8,\n",
              "  '힐우드': 6,\n",
              "  '마노': 5,\n",
              "  '헤이즐턴': 8,\n",
              "  '아파크': 10,\n",
              "  '브랜든': 7,\n",
              "  '다이스': 5,\n",
              "  '티에라': 5,\n",
              "  '멜빌': 17,\n",
              "  '크랜스턴': 5,\n",
              "  '맥노튼': 6,\n",
              "  '오로라': 33,\n",
              "  '인더스트리얼': 5,\n",
              "  '머레이': 11,\n",
              "  '로딕': 27,\n",
              "  '칼턴': 14,\n",
              "  '버지': 5,\n",
              "  '크레스트': 21,\n",
              "  '브리스톨': 9,\n",
              "  '스웨이': 10,\n",
              "  '스테드': 9,\n",
              "  '케스': 14,\n",
              "  '윅': 14,\n",
              "  '퀸스': 6,\n",
              "  '그리스트': 5,\n",
              "  '귈': 7,\n",
              "  '세이크리드': 12,\n",
              "  '도너': 7,\n",
              "  '사이크스': 5,\n",
              "  '헤이븐': 7,\n",
              "  '베티': 5,\n",
              "  '셀윈': 9,\n",
              "  '롤링': 9,\n",
              "  '레드스톤': 14,\n",
              "  '커머스': 18,\n",
              "  '셜리': 10,\n",
              "  '스파다': 7,\n",
              "  '리치먼드': 13,\n",
              "  '트렌치': 8,\n",
              "  '쉐프': 10,\n",
              "  '올랜도': 8,\n",
              "  '뉴커크': 12,\n",
              "  '폴스': 5,\n",
              "  '데본': 6,\n",
              "  '스코': 9,\n",
              "  '화이': 7,\n",
              "  '홀리': 9,\n",
              "  '캐니언': 7,\n",
              "  '처치': 5,\n",
              "  '엘리오트': 7,\n",
              "  '트뤼도': 7,\n",
              "  '닐': 16,\n",
              "  '스퀘어': 5,\n",
              "  '스토니': 5,\n",
              "  '테레사': 18,\n",
              "  '브릭스': 5,\n",
              "  '하이테크': 5,\n",
              "  '맥칼럼': 5,\n",
              "  '위너스': 5,\n",
              "  '키미지마': 6,\n",
              "  '남서부': 8,\n",
              "  '경전철': 9,\n",
              "  '사방': 7,\n",
              "  '당함': 6,\n",
              "  '투각': 10,\n",
              "  '전압': 5,\n",
              "  '클럭': 5,\n",
              "  '커넥터': 29,\n",
              "  '평평': 18,\n",
              "  '음성': 6,\n",
              "  '소경': 10,\n",
              "  '남원경': 8,\n",
              "  '삼성메디슨': 8,\n",
              "  '삼성그룹': 5,\n",
              "  '메디슨': 7,\n",
              "  '초음파': 8,\n",
              "  '한큐': 7,\n",
              "  '한신': 8,\n",
              "  '긴테쓰': 6,\n",
              "  '윤석양': 18,\n",
              "  '전두환': 5,\n",
              "  '혁노': 9,\n",
              "  '펠': 5,\n",
              "  '하위스': 5,\n",
              "  '데바나가리': 5,\n",
              "  '손숙': 16,\n",
              "  '무소속': 5,\n",
              "  '서귀포시': 24,\n",
              "  '밥상': 8,\n",
              "  '마린': 5,\n",
              "  '코끼리': 9,\n",
              "  '후지코': 5,\n",
              "  '플래퍼': 8,\n",
              "  '오노데라': 6,\n",
              "  '투니': 22,\n",
              "  '맥스': 7,\n",
              "  '초밥': 17,\n",
              "  '터보': 7,\n",
              "  '매드': 6,\n",
              "  '다빈치': 6,\n",
              "  '스티븐': 6,\n",
              "  '버거': 8,\n",
              "  '슐레겔': 6,\n",
              "  '탄광': 8,\n",
              "  '할레': 9,\n",
              "  '일본식': 14,\n",
              "  '기시': 8,\n",
              "  '참의원': 5,\n",
              "  '타로': 6,\n",
              "  '회로도': 15,\n",
              "  '불변량': 9,\n",
              "  '생피에르': 7,\n",
              "  '아카디아': 10,\n",
              "  '프랑스인': 5,\n",
              "  '노바스코샤': 6,\n",
              "  '뉴펀들랜드': 5,\n",
              "  '누벨': 9,\n",
              "  '권한': 15,\n",
              "  '크릭': 6,\n",
              "  '셀로': 13,\n",
              "  '원정군': 5,\n",
              "  '나이아가라': 5,\n",
              "  '타나': 11,\n",
              "  '베프': 8,\n",
              "  '그리슨': 10,\n",
              "  '딘위디': 7,\n",
              "  '콩트': 5,\n",
              "  '봉쇄': 5,\n",
              "  '보급품': 6,\n",
              "  '보드레': 9,\n",
              "  '허드슨': 5,\n",
              "  '컨더': 6,\n",
              "  '카리용': 5,\n",
              "  '퀘벡': 7,\n",
              "  '로던': 7,\n",
              "  '애버크롬비': 7,\n",
              "  '름': 8,\n",
              "  '름은': 5,\n",
              "  '화약': 7,\n",
              "  '옮김': 5,\n",
              "  '민사': 5,\n",
              "  '정례회': 6,\n",
              "  '호킹': 11,\n",
              "  '루게릭': 5,\n",
              "  '버시': 5,\n",
              "  '베르너': 6,\n",
              "  '강세': 6,\n",
              "  '올가': 28,\n",
              "  '니콜라이': 11,\n",
              "  '라스푸틴': 13,\n",
              "  '알렉세이': 9,\n",
              "  '황녀': 5,\n",
              "  '여철현': 5,\n",
              "  '석방': 5,\n",
              "  '퀸즐랜드': 5,\n",
              "  '태즈메이니아': 6,\n",
              "  '헌법학': 18,\n",
              "  '나바테아': 19,\n",
              "  '인족': 9,\n",
              "  '묘비': 5,\n",
              "  '흐르': 5,\n",
              "  '만두': 31,\n",
              "  '이혜승': 5,\n",
              "  '배달': 28,\n",
              "  '신문배달': 5,\n",
              "  '감별': 7,\n",
              "  '설거지': 6,\n",
              "  '김밥': 26,\n",
              "  '냉면': 22,\n",
              "  '가발': 9,\n",
              "  '세차': 11,\n",
              "  '얼음': 6,\n",
              "  '바지락': 7,\n",
              "  '수박': 10,\n",
              "  '타이어': 10,\n",
              "  '어묵': 8,\n",
              "  '아이스크림': 9,\n",
              "  '떡': 25,\n",
              "  '다슬기': 6,\n",
              "  '수건': 5,\n",
              "  '중식': 12,\n",
              "  '서빙': 5,\n",
              "  '추석': 6,\n",
              "  '달걀': 7,\n",
              "  '철판': 10,\n",
              "  '오므라이스': 6,\n",
              "  '족발': 8,\n",
              "  '수타': 5,\n",
              "  '우동': 19,\n",
              "  '볶음밥': 7,\n",
              "  '설렁탕': 7,\n",
              "  '떡볶이': 36,\n",
              "  '튀김': 10,\n",
              "  '명함': 5,\n",
              "  '방학': 19,\n",
              "  '삼겹살': 6,\n",
              "  '도넛': 11,\n",
              "  '썰': 6,\n",
              "  '원단': 9,\n",
              "  '가방': 6,\n",
              "  '초감각': 5,\n",
              "  '볶음': 8,\n",
              "  '빙수': 7,\n",
              "  '딤섬': 6,\n",
              "  '이색': 24,\n",
              "  '줄넘기': 5,\n",
              "  '장어': 10,\n",
              "  '뷔페': 12,\n",
              "  '꽈배기': 14,\n",
              "  '칼국수': 15,\n",
              "  '스카프': 5,\n",
              "  '비빔밥': 14,\n",
              "  '호떡': 13,\n",
              "  '분식': 5,\n",
              "  '찐빵': 12,\n",
              "  '간식': 7,\n",
              "  '수제비': 10,\n",
              "  '봉투': 6,\n",
              "  '짬뽕': 12,\n",
              "  '뻥튀기': 5,\n",
              "  '인방': 7,\n",
              "  '돈가스': 5,\n",
              "  '검수': 10,\n",
              "  '아이스': 5,\n",
              "  ...},\n",
              " {'남모': 0,\n",
              "  '는': 1,\n",
              "  '준정': 2,\n",
              "  '화랑': 3,\n",
              "  '었': 4,\n",
              "  '주': 5,\n",
              "  '생산': 6,\n",
              "  '직경': 7,\n",
              "  '톤': 8,\n",
              "  '버전': 9,\n",
              "  '너지': 10,\n",
              "  '헝가리': 11,\n",
              "  '선수': 12,\n",
              "  '여자': 13,\n",
              "  '올림픽': 14,\n",
              "  '대포': 15,\n",
              "  '파이어': 16,\n",
              "  '구형': 17,\n",
              "  '미사일': 18,\n",
              "  '중국': 19,\n",
              "  '홍': 20,\n",
              "  '국수': 21,\n",
              "  '쿠스': 22,\n",
              "  '파우': 23,\n",
              "  '문자열': 24,\n",
              "  '시동': 25,\n",
              "  '입력': 26,\n",
              "  '사운드': 27,\n",
              "  '가장': 28,\n",
              "  '검사': 29,\n",
              "  '캐시': 30,\n",
              "  '호출': 31,\n",
              "  '게임': 32,\n",
              "  '섹션': 33,\n",
              "  '프로세서': 34,\n",
              "  '청안': 35,\n",
              "  '선남': 36,\n",
              "  '라마': 37,\n",
              "  '일본': 38,\n",
              "  '함대': 39,\n",
              "  '윤인완': 40,\n",
              "  '만들': 41,\n",
              "  '기원전': 42,\n",
              "  '종교': 43,\n",
              "  '가톨릭교회': 44,\n",
              "  '성': 45,\n",
              "  '보': 46,\n",
              "  '정부': 47,\n",
              "  '루이': 48,\n",
              "  '시녀': 49,\n",
              "  '아라곤': 50,\n",
              "  '유럽': 51,\n",
              "  '왕': 52,\n",
              "  '서': 53,\n",
              "  '영혼': 54,\n",
              "  '머리': 55,\n",
              "  '읍': 56,\n",
              "  '코지마': 57,\n",
              "  '극장판': 58,\n",
              "  '마사키': 59,\n",
              "  '오기노': 60,\n",
              "  '포맷': 61,\n",
              "  '스톤': 62,\n",
              "  '음반': 63,\n",
              "  '차트': 64,\n",
              "  '시몬스': 65,\n",
              "  '이사벨라': 66,\n",
              "  '콘스탄티누스': 67,\n",
              "  '혼인': 68,\n",
              "  '유지': 69,\n",
              "  '대머리': 70,\n",
              "  '우': 71,\n",
              "  '아종': 72,\n",
              "  '까': 73,\n",
              "  '숲': 74,\n",
              "  '필터': 75,\n",
              "  '기름': 76,\n",
              "  '청소': 77,\n",
              "  '구매': 78,\n",
              "  '기호': 79,\n",
              "  '주포': 80,\n",
              "  '램': 81,\n",
              "  '묶': 82,\n",
              "  '앙각': 83,\n",
              "  '분당': 84,\n",
              "  '커스': 85,\n",
              "  '갖추': 86,\n",
              "  '팽': 87,\n",
              "  '축구': 88,\n",
              "  '리그': 89,\n",
              "  '가제': 90,\n",
              "  '곡': 91,\n",
              "  '작곡': 92,\n",
              "  '테레비': 93,\n",
              "  '엘리': 94,\n",
              "  '펀트': 95,\n",
              "  '카운티': 96,\n",
              "  '알렉산드라': 97,\n",
              "  '나리': 98,\n",
              "  '시인': 99,\n",
              "  '가선': 100,\n",
              "  '친왕': 101,\n",
              "  '정': 102,\n",
              "  '가인': 103,\n",
              "  '고킨와카슈': 104,\n",
              "  '돌': 105,\n",
              "  '정치': 106,\n",
              "  '광': 107,\n",
              "  '야간': 108,\n",
              "  '포테마요': 109,\n",
              "  '코믹': 110,\n",
              "  '화': 111,\n",
              "  '스나오': 112,\n",
              "  '고양이': 113,\n",
              "  '메이트': 114,\n",
              "  '미캉': 115,\n",
              "  '모리야마': 116,\n",
              "  '땅': 117,\n",
              "  '원래': 118,\n",
              "  '구간': 119,\n",
              "  '코오롱': 120,\n",
              "  '조정': 121,\n",
              "  '인더스': 122,\n",
              "  '주식': 123,\n",
              "  '의류': 124,\n",
              "  '자동차': 125,\n",
              "  '부품': 126,\n",
              "  '케어': 127,\n",
              "  '션': 128,\n",
              "  '리조트': 129,\n",
              "  '적자': 130,\n",
              "  '메트로폴리탄': 131,\n",
              "  '카슈미르': 132,\n",
              "  '이끄': 133,\n",
              "  '콤': 134,\n",
              "  '갈라파고스': 135,\n",
              "  '갈색': 136,\n",
              "  '생물': 137,\n",
              "  '이사벨': 138,\n",
              "  '출장': 139,\n",
              "  '오쿠노': 140,\n",
              "  '성씨': 141,\n",
              "  '역': 142,\n",
              "  '교': 143,\n",
              "  '레고': 144,\n",
              "  '완구': 145,\n",
              "  '픽셀': 146,\n",
              "  '공략': 147,\n",
              "  '트랜스포머': 148,\n",
              "  '휴대': 149,\n",
              "  '전화': 150,\n",
              "  '기종': 151,\n",
              "  '이성주': 152,\n",
              "  '영화제': 153,\n",
              "  '권은희': 154,\n",
              "  '국회의원': 155,\n",
              "  '도입': 156,\n",
              "  '경찰서': 157,\n",
              "  '수서': 158,\n",
              "  '희': 159,\n",
              "  '위증': 160,\n",
              "  '앞': 161,\n",
              "  '손질': 162,\n",
              "  '처분': 163,\n",
              "  '수석': 164,\n",
              "  '인텔': 165,\n",
              "  '칩': 166,\n",
              "  '코어': 167,\n",
              "  '포레스트': 168,\n",
              "  '오페라': 169,\n",
              "  '하버드': 170,\n",
              "  '래피드': 171,\n",
              "  '마이너': 172,\n",
              "  '마이닝': 173,\n",
              "  '회로': 174,\n",
              "  '숨': 175,\n",
              "  '버그': 176,\n",
              "  '커뮤니티': 177,\n",
              "  '업데이트': 178,\n",
              "  '계산': 179,\n",
              "  '쿼드': 180,\n",
              "  '유료': 181,\n",
              "  '대부분': 182,\n",
              "  '불후': 183,\n",
              "  '발매': 184,\n",
              "  '상륙': 185,\n",
              "  '애쉬': 186,\n",
              "  '주말': 187,\n",
              "  '인생': 188,\n",
              "  '심사': 189,\n",
              "  '국민주의': 190,\n",
              "  '교황': 191,\n",
              "  '스튜어트': 192,\n",
              "  '자율': 193,\n",
              "  '혁명': 194,\n",
              "  '최': 195,\n",
              "  '학회': 196,\n",
              "  '사이클': 197,\n",
              "  '밴': 198,\n",
              "  '드로잉': 199,\n",
              "  '모형': 200,\n",
              "  '교통': 201,\n",
              "  '오카야마': 202,\n",
              "  '대검찰청': 203,\n",
              "  '수부': 204,\n",
              "  '검사장': 205,\n",
              "  '사무소': 206,\n",
              "  '한나라당': 207,\n",
              "  '사찰': 208,\n",
              "  '하차': 209,\n",
              "  '파일럿': 210,\n",
              "  '온주쿠': 211,\n",
              "  '나미': 212,\n",
              "  '철도': 213,\n",
              "  '부산': 214,\n",
              "  '배명': 215,\n",
              "  '루수': 216,\n",
              "  '언급': 217,\n",
              "  '드래': 218,\n",
              "  '깅': 219,\n",
              "  '인디언': 220,\n",
              "  '투쟁': 221,\n",
              "  '버지니아': 222,\n",
              "  '테네시': 223,\n",
              "  '어퍼': 224,\n",
              "  '행동': 225,\n",
              "  '프랑스령': 226,\n",
              "  '미시시피': 227,\n",
              "  '플로리다': 228,\n",
              "  '사우스': 229,\n",
              "  '캐롤라이나': 230,\n",
              "  '이로쿼이': 231,\n",
              "  '요새': 232,\n",
              "  '오하': 233,\n",
              "  '오하이오': 234,\n",
              "  '영토': 235,\n",
              "  '로버트슨': 236,\n",
              "  '퇴거': 237,\n",
              "  '헨더슨': 238,\n",
              "  '쿨라': 239,\n",
              "  '경고': 240,\n",
              "  '해밀턴': 241,\n",
              "  '기습': 242,\n",
              "  '민병대': 243,\n",
              "  '포로': 244,\n",
              "  '교향악단': 245,\n",
              "  '순천': 246,\n",
              "  '응진': 247,\n",
              "  '탱': 248,\n",
              "  '나한도': 249,\n",
              "  '제석': 250,\n",
              "  '존자': 251,\n",
              "  '암벽': 252,\n",
              "  '비트': 253,\n",
              "  '돌격': 254,\n",
              "  '낚시': 255,\n",
              "  '헤이그': 256,\n",
              "  '윤': 257,\n",
              "  '남근': 258,\n",
              "  '교육청': 259,\n",
              "  '시범': 260,\n",
              "  '크리어': 261,\n",
              "  '북미': 262,\n",
              "  '고리': 263,\n",
              "  '벡터': 264,\n",
              "  '접': 265,\n",
              "  '호모': 266,\n",
              "  '토피': 267,\n",
              "  '지하철': 268,\n",
              "  '시즈먼': 269,\n",
              "  '운행': 270,\n",
              "  '회전': 271,\n",
              "  '노선': 272,\n",
              "  '시간표': 273,\n",
              "  '미츠키': 274,\n",
              "  '미쓰키': 275,\n",
              "  '다무라': 276,\n",
              "  '트레버': 277,\n",
              "  '리전': 278,\n",
              "  '비아': 279,\n",
              "  '과업': 280,\n",
              "  '회피': 281,\n",
              "  '측면': 282,\n",
              "  '피드백': 283,\n",
              "  '끝내': 284,\n",
              "  '대개': 285,\n",
              "  '욕구': 286,\n",
              "  '메타분석': 287,\n",
              "  '결합': 288,\n",
              "  '효능감': 289,\n",
              "  '경혜': 290,\n",
              "  '군주': 291,\n",
              "  '묘지': 292,\n",
              "  '재산': 293,\n",
              "  '성종': 294,\n",
              "  '김포': 295,\n",
              "  '민': 296,\n",
              "  '엔진': 297,\n",
              "  '프렌즈': 298,\n",
              "  '하코다테': 299,\n",
              "  '미자': 300,\n",
              "  '아사히카와': 301,\n",
              "  '전동차': 302,\n",
              "  '전철': 303,\n",
              "  '에어포트': 304,\n",
              "  '신모리야마': 305,\n",
              "  '주오': 306,\n",
              "  '열차': 307,\n",
              "  '컨테이너': 308,\n",
              "  '맥주': 309,\n",
              "  '가온': 310,\n",
              "  '크리스마스': 311,\n",
              "  '탄생불': 312,\n",
              "  '입상': 313,\n",
              "  '불상': 314,\n",
              "  '띠': 315,\n",
              "  '비례': 316,\n",
              "  '도덕경': 317,\n",
              "  '노자': 318,\n",
              "  '판본': 319,\n",
              "  '왕필': 320,\n",
              "  '갑': 321,\n",
              "  '터널': 322,\n",
              "  '법칙': 323,\n",
              "  '케임브리지': 324,\n",
              "  '왕립': 325,\n",
              "  '성인': 326,\n",
              "  '정교회': 327,\n",
              "  '올스타': 328,\n",
              "  '대수': 329,\n",
              "  '천문대': 330,\n",
              "  '융합': 331,\n",
              "  '체코슬로바키아': 332,\n",
              "  '위임': 333,\n",
              "  '슈테': 334,\n",
              "  '마장': 335,\n",
              "  '반프레스토': 336,\n",
              "  '본작': 337,\n",
              "  '류네': 338,\n",
              "  '바스': 339,\n",
              "  '슈우': 340,\n",
              "  '남극': 341,\n",
              "  '대결': 342,\n",
              "  '기아스': 343,\n",
              "  '랑그': 344,\n",
              "  '왕국': 345,\n",
              "  '오졸': 346,\n",
              "  '정복': 347,\n",
              "  '론도': 348,\n",
              "  '알리': 349,\n",
              "  '태조': 350,\n",
              "  '태평동': 351,\n",
              "  '챔니스': 352,\n",
              "  '곤살로': 353,\n",
              "  '코르도바': 354,\n",
              "  '뇰라': 355,\n",
              "  '참호': 356,\n",
              "  '페르난도': 357,\n",
              "  '그라나다': 358,\n",
              "  '나폴리': 359,\n",
              "  '창병': 360,\n",
              "  '중장기병': 361,\n",
              "  '공성전': 362,\n",
              "  '전축': 363,\n",
              "  '오스만': 364,\n",
              "  '지휘관': 365,\n",
              "  '총독': 366,\n",
              "  '합스부르크': 367,\n",
              "  '카우': 368,\n",
              "  '아퀴나스': 369,\n",
              "  '수도회': 370,\n",
              "  '카시노': 371,\n",
              "  '알베르투스': 372,\n",
              "  '인문': 373,\n",
              "  '벙어리': 374,\n",
              "  '황소': 375,\n",
              "  '영민': 376,\n",
              "  '덩치': 377,\n",
              "  '오르비에토': 378,\n",
              "  '댁': 379,\n",
              "  '상징': 380,\n",
              "  '신학대전': 381,\n",
              "  '펜': 382,\n",
              "  '영원': 383,\n",
              "  '벌': 384,\n",
              "  '미완성': 385,\n",
              "  '미사': 386,\n",
              "  '공의회': 387,\n",
              "  '진위': 388,\n",
              "  '교리': 389,\n",
              "  '은총': 390,\n",
              "  '식물': 391,\n",
              "  '성공회': 392,\n",
              "  '대한제국': 393,\n",
              "  '일진회': 394,\n",
              "  '남원': 395,\n",
              "  '유로': 396,\n",
              "  '아야사토': 397,\n",
              "  '카트린느': 398,\n",
              "  '아이브': 399,\n",
              "  '하이츠': 400,\n",
              "  '훈장': 401,\n",
              "  '경시': 402,\n",
              "  '구두': 403,\n",
              "  '김동훈': 404,\n",
              "  '교단': 405,\n",
              "  '안수': 406,\n",
              "  '예수교': 407,\n",
              "  '장로회': 408,\n",
              "  '타이베이': 409,\n",
              "  '총통': 410,\n",
              "  '장왕': 411,\n",
              "  '진나라': 412,\n",
              "  '민중': 413,\n",
              "  '서진': 414,\n",
              "  '한족': 415,\n",
              "  '관중': 416,\n",
              "  '서하': 417,\n",
              "  '기도': 418,\n",
              "  '매춘': 419,\n",
              "  '명품': 420,\n",
              "  '합당': 421,\n",
              "  '북한': 422,\n",
              "  '안기부': 423,\n",
              "  '노태우': 424,\n",
              "  '가오리': 425,\n",
              "  '뿌': 426,\n",
              "  '기라티나': 427,\n",
              "  '포켓몬스터': 428,\n",
              "  '디아루가': 429,\n",
              "  '펄기아': 430,\n",
              "  '포켓몬': 431,\n",
              "  '어나더': 432,\n",
              "  '깨어진': 433,\n",
              "  '오리진': 434,\n",
              "  '섀도': 435,\n",
              "  '다이브': 436,\n",
              "  '퀸': 437,\n",
              "  '전송': 438,\n",
              "  '실버': 439,\n",
              "  '쉐': 440,\n",
              "  '팔츠': 441,\n",
              "  '에른스트': 442,\n",
              "  '세례': 443,\n",
              "  '로키산': 444,\n",
              "  '홍반': 445,\n",
              "  '감염병': 446,\n",
              "  '물기': 447,\n",
              "  '공예': 448,\n",
              "  '헬스': 449,\n",
              "  '콜로부스': 450,\n",
              "  '규슈': 451,\n",
              "  '플라자': 452,\n",
              "  '원담': 453,\n",
              "  '랜드': 454,\n",
              "  '라이온스': 455,\n",
              "  '특유재산': 456,\n",
              "  '민법': 457,\n",
              "  '무인': 458,\n",
              "  '니시지마': 459,\n",
              "  '우상': 460,\n",
              "  '스트로베리': 461,\n",
              "  '나이트': 462,\n",
              "  '카즈': 463,\n",
              "  '프리미엄': 464,\n",
              "  '레인': 465,\n",
              "  '내레이션': 466,\n",
              "  '신자': 467,\n",
              "  '내일': 468,\n",
              "  '케이크': 469,\n",
              "  '크림': 470,\n",
              "  '치즈': 471,\n",
              "  '간장': 472,\n",
              "  '피트': 473,\n",
              "  '이강주': 474,\n",
              "  '울금': 475,\n",
              "  '냄새': 476,\n",
              "  '스맥다운': 477,\n",
              "  '이기': 478,\n",
              "  '우소': 479,\n",
              "  '케인': 480,\n",
              "  '익스트림': 481,\n",
              "  '기야마': 482,\n",
              "  '가고시마': 483,\n",
              "  '후쿠오카': 484,\n",
              "  '야쿠': 485,\n",
              "  '미야노': 486,\n",
              "  '육상': 487,\n",
              "  '야쿠시마': 488,\n",
              "  '폭포': 489,\n",
              "  '로켓': 490,\n",
              "  '다이요': 491,\n",
              "  '피겨': 492,\n",
              "  '스케이팅': 493,\n",
              "  '슈저우': 494,\n",
              "  '야스케': 495,\n",
              "  '노부나가': 496,\n",
              "  '제천시': 497,\n",
              "  '단양군': 498,\n",
              "  '제천군': 499,\n",
              "  '선거구': 500,\n",
              "  '로케': 501,\n",
              "  '팔레': 502,\n",
              "  '스카': 503,\n",
              "  '레미콘': 504,\n",
              "  '골재': 505,\n",
              "  '배합': 506,\n",
              "  '슬래그': 507,\n",
              "  '숙의': 508,\n",
              "  '명종': 509,\n",
              "  '하딩': 510,\n",
              "  '판화': 511,\n",
              "  '몽실이': 512,\n",
              "  '몽실': 513,\n",
              "  '주사': 514,\n",
              "  '호아': 515,\n",
              "  '무덤': 516,\n",
              "  '여단': 517,\n",
              "  '뉴기니': 518,\n",
              "  '워든': 519,\n",
              "  '정규군': 520,\n",
              "  '진승': 521,\n",
              "  '오광': 522,\n",
              "  '부리': 523,\n",
              "  '진여': 524,\n",
              "  '진현': 525,\n",
              "  '형양': 526,\n",
              "  '진가': 527,\n",
              "  '이세황제': 528,\n",
              "  '장한': 529,\n",
              "  '장초군': 530,\n",
              "  '항량': 531,\n",
              "  '코넬': 532,\n",
              "  '농장': 533,\n",
              "  '순차': 534,\n",
              "  '피자': 535,\n",
              "  '페트라': 536,\n",
              "  '장관': 537,\n",
              "  '까마귀': 538,\n",
              "  '울음': 539,\n",
              "  '아제르바이잔': 540,\n",
              "  '크로마': 541,\n",
              "  '샘플링': 542,\n",
              "  '색차': 543,\n",
              "  '인코딩': 544,\n",
              "  '루마': 545,\n",
              "  '컴포넌트': 546,\n",
              "  '에일리어싱': 547,\n",
              "  '비월': 548,\n",
              "  '화소': 549,\n",
              "  '베른하르트': 550,\n",
              "  '방정식': 551,\n",
              "  '일식': 552,\n",
              "  '미적분학': 553,\n",
              "  '역학': 554,\n",
              "  '사회주의': 555,\n",
              "  '반공': 556,\n",
              "  '분자': 557,\n",
              "  '차관': 558,\n",
              "  '국민운동': 559,\n",
              "  '중앙일보': 560,\n",
              "  '쿠르디스탄': 561,\n",
              "  '프랑크푸르트': 562,\n",
              "  '반납': 563,\n",
              "  '센트': 564,\n",
              "  '계란': 565,\n",
              "  '수선': 566,\n",
              "  '미원': 567,\n",
              "  '기암': 568,\n",
              "  '멩거': 569,\n",
              "  '박서보': 570,\n",
              "  '미술가': 571,\n",
              "  '홍익': 572,\n",
              "  '종로': 573,\n",
              "  '서보': 574,\n",
              "  '현대전': 575,\n",
              "  '묘법': 576,\n",
              "  '단색화': 577,\n",
              "  '국전': 578,\n",
              "  '조형': 579,\n",
              "  '박람회': 580,\n",
              "  '인테리어': 581,\n",
              "  '이우환': 582,\n",
              "  '무라마츠': 583,\n",
              "  '대부': 584,\n",
              "  '박영덕': 585,\n",
              "  '조현': 586,\n",
              "  '바젤': 587,\n",
              "  '박여숙': 588,\n",
              "  '조현화': 589,\n",
              "  '샘터': 590,\n",
              "  '박람': 591,\n",
              "  '국제무역센터': 592,\n",
              "  '전람': 593,\n",
              "  '대청': 594,\n",
              "  '코엑스': 595,\n",
              "  '경복궁': 596,\n",
              "  '인전': 597,\n",
              "  '비엔날레': 598,\n",
              "  '협': 599,\n",
              "  '당전': 600,\n",
              "  '현대미': 601,\n",
              "  '술제': 602,\n",
              "  '윤형근': 603,\n",
              "  '김창렬': 604,\n",
              "  '도립': 605,\n",
              "  '송년': 606,\n",
              "  '흥원': 607,\n",
              "  '관훈': 608,\n",
              "  '정창섭': 609,\n",
              "  '로이드': 610,\n",
              "  '컨벤션': 611,\n",
              "  '강릉': 612,\n",
              "  '네이비': 613,\n",
              "  '멜번': 614,\n",
              "  '팜': 615,\n",
              "  '마이애미비치': 616,\n",
              "  '요미우리': 617,\n",
              "  '포스트': 618,\n",
              "  '탕': 619,\n",
              "  '큐브': 620,\n",
              "  '코지': 621,\n",
              "  '와일드': 622,\n",
              "  '프라임': 623,\n",
              "  '진로': 624,\n",
              "  '카트': 625,\n",
              "  '옹주': 626,\n",
              "  '감비아': 627,\n",
              "  '마산역': 628,\n",
              "  '경전선': 629,\n",
              "  '무궁화호': 630,\n",
              "  '산역': 631,\n",
              "  '부전': 632,\n",
              "  '디젤': 633,\n",
              "  '새마을호': 634,\n",
              "  '환승': 635,\n",
              "  '주차': 636,\n",
              "  '장악원': 637,\n",
              "  '융준': 638,\n",
              "  '철종': 639,\n",
              "  '즉석': 640,\n",
              "  '라이프치히': 641,\n",
              "  '정무': 642,\n",
              "  '비틀즈': 643,\n",
              "  '매카트니': 644,\n",
              "  '링고': 645,\n",
              "  '농어촌버스': 646,\n",
              "  '데라우치': 647,\n",
              "  '식물상': 648,\n",
              "  '클리어타입': 649,\n",
              "  '렌더링': 650,\n",
              "  '내장': 651,\n",
              "  '비트맵': 652,\n",
              "  '밀퍼드': 653,\n",
              "  '뉴질랜드': 654,\n",
              "  '트램': 655,\n",
              "  '맥키넌': 656,\n",
              "  '캠핑': 657,\n",
              "  '점심': 658,\n",
              "  '센스': 659,\n",
              "  '삼도': 660,\n",
              "  '용담': 661,\n",
              "  '노형동': 662,\n",
              "  '제주시': 663,\n",
              "  '와인': 664,\n",
              "  '이즈': 665,\n",
              "  '드라이브': 666,\n",
              "  '카터': 667,\n",
              "  '봉성군': 668,\n",
              "  '희빈': 669,\n",
              "  '윤임': 670,\n",
              "  '목욕': 671,\n",
              "  '니지마': 672,\n",
              "  '쿠사야': 673,\n",
              "  '건어물': 674,\n",
              "  '하치조': 675,\n",
              "  '소금물': 676,\n",
              "  '교통국': 677,\n",
              "  '드골': 678,\n",
              "  '프레더릭': 679,\n",
              "  '안사': 680,\n",
              "  '곡초': 681,\n",
              "  '양초': 682,\n",
              "  '사천시': 683,\n",
              "  '마도': 684,\n",
              "  '천초': 685,\n",
              "  '배영': 686,\n",
              "  '유대교': 687,\n",
              "  '민해경': 688,\n",
              "  '마젤란': 689,\n",
              "  '피그미': 690,\n",
              "  '테니스': 691,\n",
              "  '배구': 692,\n",
              "  '하치로가타': 693,\n",
              "  '함장': 694,\n",
              "  '수향': 695,\n",
              "  '저우장': 696,\n",
              "  '심만삼': 697,\n",
              "  '명물': 698,\n",
              "  '기저': 699,\n",
              "  '회생': 700,\n",
              "  '아파트': 701,\n",
              "  '청자': 702,\n",
              "  '상감': 703,\n",
              "  '용봉': 704,\n",
              "  '그릇': 705,\n",
              "  '숟가락': 706,\n",
              "  '황모': 707,\n",
              "  '히코네': 708,\n",
              "  '급행': 709,\n",
              "  '비바': 710,\n",
              "  '뉴마켓': 711,\n",
              "  '핀치': 712,\n",
              "  '멀록': 713,\n",
              "  '오처드': 714,\n",
              "  '블루밍턴': 715,\n",
              "  '제퍼슨': 716,\n",
              "  '엘긴': 717,\n",
              "  '밀스': 718,\n",
              "  '크로스비': 719,\n",
              "  '매켄지': 720,\n",
              "  '웰드': 721,\n",
              "  '카빌': 722,\n",
              "  '리치먼드힐': 723,\n",
              "  '상시': 724,\n",
              "  '아워': 725,\n",
              "  '마컴': 726,\n",
              "  '스토우': 727,\n",
              "  '비버': 728,\n",
              "  '크리크': 729,\n",
              "  '레슬리': 730,\n",
              "  '우드바인': 731,\n",
              "  '몽고메리': 732,\n",
              "  '버치': 733,\n",
              "  '벌록': 734,\n",
              "  '매코': 735,\n",
              "  '갤': 736,\n",
              "  '스워': 737,\n",
              "  '우튼': 738,\n",
              "  '빌리지': 739,\n",
              "  '파크웨이': 740,\n",
              "  '유니언': 741,\n",
              "  '그로브': 742,\n",
              "  '키플링': 743,\n",
              "  '이즐링턴': 744,\n",
              "  '더퍼린': 745,\n",
              "  '미너': 746,\n",
              "  '배서스트': 747,\n",
              "  '공휴일': 748,\n",
              "  '데니슨': 749,\n",
              "  '세네카': 750,\n",
              "  '레이크': 751,\n",
              "  '복스': 752,\n",
              "  '월마트': 753,\n",
              "  '밀리켄': 754,\n",
              "  '코원': 755,\n",
              "  '루지': 756,\n",
              "  '엘슨': 757,\n",
              "  '파이어니어': 758,\n",
              "  '메이플': 759,\n",
              "  '오크': 760,\n",
              "  '버러': 761,\n",
              "  '후버': 762,\n",
              "  '우드브릿지': 763,\n",
              "  '스태프': 764,\n",
              "  '슬리': 765,\n",
              "  '나파밸리': 766,\n",
              "  '러더퍼드': 767,\n",
              "  '밀러드': 768,\n",
              "  '오토': 769,\n",
              "  '헌팅': 770,\n",
              "  '셰퍼드': 771,\n",
              "  '엘즈미어': 772,\n",
              "  '마운트조이': 773,\n",
              "  '테스': 774,\n",
              "  '킹시티': 775,\n",
              "  '우즈': 776,\n",
              "  '힐우드': 777,\n",
              "  '마노': 778,\n",
              "  '헤이즐턴': 779,\n",
              "  '아파크': 780,\n",
              "  '브랜든': 781,\n",
              "  '다이스': 782,\n",
              "  '티에라': 783,\n",
              "  '멜빌': 784,\n",
              "  '크랜스턴': 785,\n",
              "  '맥노튼': 786,\n",
              "  '오로라': 787,\n",
              "  '인더스트리얼': 788,\n",
              "  '머레이': 789,\n",
              "  '로딕': 790,\n",
              "  '칼턴': 791,\n",
              "  '버지': 792,\n",
              "  '크레스트': 793,\n",
              "  '브리스톨': 794,\n",
              "  '스웨이': 795,\n",
              "  '스테드': 796,\n",
              "  '케스': 797,\n",
              "  '윅': 798,\n",
              "  '퀸스': 799,\n",
              "  '그리스트': 800,\n",
              "  '귈': 801,\n",
              "  '세이크리드': 802,\n",
              "  '도너': 803,\n",
              "  '사이크스': 804,\n",
              "  '헤이븐': 805,\n",
              "  '베티': 806,\n",
              "  '셀윈': 807,\n",
              "  '롤링': 808,\n",
              "  '레드스톤': 809,\n",
              "  '커머스': 810,\n",
              "  '셜리': 811,\n",
              "  '스파다': 812,\n",
              "  '리치먼드': 813,\n",
              "  '트렌치': 814,\n",
              "  '쉐프': 815,\n",
              "  '올랜도': 816,\n",
              "  '뉴커크': 817,\n",
              "  '폴스': 818,\n",
              "  '데본': 819,\n",
              "  '스코': 820,\n",
              "  '화이': 821,\n",
              "  '홀리': 822,\n",
              "  '캐니언': 823,\n",
              "  '처치': 824,\n",
              "  '엘리오트': 825,\n",
              "  '트뤼도': 826,\n",
              "  '닐': 827,\n",
              "  '스퀘어': 828,\n",
              "  '스토니': 829,\n",
              "  '테레사': 830,\n",
              "  '브릭스': 831,\n",
              "  '하이테크': 832,\n",
              "  '맥칼럼': 833,\n",
              "  '위너스': 834,\n",
              "  '키미지마': 835,\n",
              "  '남서부': 836,\n",
              "  '경전철': 837,\n",
              "  '사방': 838,\n",
              "  '당함': 839,\n",
              "  '투각': 840,\n",
              "  '전압': 841,\n",
              "  '클럭': 842,\n",
              "  '커넥터': 843,\n",
              "  '평평': 844,\n",
              "  '음성': 845,\n",
              "  '소경': 846,\n",
              "  '남원경': 847,\n",
              "  '삼성메디슨': 848,\n",
              "  '삼성그룹': 849,\n",
              "  '메디슨': 850,\n",
              "  '초음파': 851,\n",
              "  '한큐': 852,\n",
              "  '한신': 853,\n",
              "  '긴테쓰': 854,\n",
              "  '윤석양': 855,\n",
              "  '전두환': 856,\n",
              "  '혁노': 857,\n",
              "  '펠': 858,\n",
              "  '하위스': 859,\n",
              "  '데바나가리': 860,\n",
              "  '손숙': 861,\n",
              "  '무소속': 862,\n",
              "  '서귀포시': 863,\n",
              "  '밥상': 864,\n",
              "  '마린': 865,\n",
              "  '코끼리': 866,\n",
              "  '후지코': 867,\n",
              "  '플래퍼': 868,\n",
              "  '오노데라': 869,\n",
              "  '투니': 870,\n",
              "  '맥스': 871,\n",
              "  '초밥': 872,\n",
              "  '터보': 873,\n",
              "  '매드': 874,\n",
              "  '다빈치': 875,\n",
              "  '스티븐': 876,\n",
              "  '버거': 877,\n",
              "  '슐레겔': 878,\n",
              "  '탄광': 879,\n",
              "  '할레': 880,\n",
              "  '일본식': 881,\n",
              "  '기시': 882,\n",
              "  '참의원': 883,\n",
              "  '타로': 884,\n",
              "  '회로도': 885,\n",
              "  '불변량': 886,\n",
              "  '생피에르': 887,\n",
              "  '아카디아': 888,\n",
              "  '프랑스인': 889,\n",
              "  '노바스코샤': 890,\n",
              "  '뉴펀들랜드': 891,\n",
              "  '누벨': 892,\n",
              "  '권한': 893,\n",
              "  '크릭': 894,\n",
              "  '셀로': 895,\n",
              "  '원정군': 896,\n",
              "  '나이아가라': 897,\n",
              "  '타나': 898,\n",
              "  '베프': 899,\n",
              "  '그리슨': 900,\n",
              "  '딘위디': 901,\n",
              "  '콩트': 902,\n",
              "  '봉쇄': 903,\n",
              "  '보급품': 904,\n",
              "  '보드레': 905,\n",
              "  '허드슨': 906,\n",
              "  '컨더': 907,\n",
              "  '카리용': 908,\n",
              "  '퀘벡': 909,\n",
              "  '로던': 910,\n",
              "  '애버크롬비': 911,\n",
              "  '름': 912,\n",
              "  '름은': 913,\n",
              "  '화약': 914,\n",
              "  '옮김': 915,\n",
              "  '민사': 916,\n",
              "  '정례회': 917,\n",
              "  '호킹': 918,\n",
              "  '루게릭': 919,\n",
              "  '버시': 920,\n",
              "  '베르너': 921,\n",
              "  '강세': 922,\n",
              "  '올가': 923,\n",
              "  '니콜라이': 924,\n",
              "  '라스푸틴': 925,\n",
              "  '알렉세이': 926,\n",
              "  '황녀': 927,\n",
              "  '여철현': 928,\n",
              "  '석방': 929,\n",
              "  '퀸즐랜드': 930,\n",
              "  '태즈메이니아': 931,\n",
              "  '헌법학': 932,\n",
              "  '나바테아': 933,\n",
              "  '인족': 934,\n",
              "  '묘비': 935,\n",
              "  '흐르': 936,\n",
              "  '만두': 937,\n",
              "  '이혜승': 938,\n",
              "  '배달': 939,\n",
              "  '신문배달': 940,\n",
              "  '감별': 941,\n",
              "  '설거지': 942,\n",
              "  '김밥': 943,\n",
              "  '냉면': 944,\n",
              "  '가발': 945,\n",
              "  '세차': 946,\n",
              "  '얼음': 947,\n",
              "  '바지락': 948,\n",
              "  '수박': 949,\n",
              "  '타이어': 950,\n",
              "  '어묵': 951,\n",
              "  '아이스크림': 952,\n",
              "  '떡': 953,\n",
              "  '다슬기': 954,\n",
              "  '수건': 955,\n",
              "  '중식': 956,\n",
              "  '서빙': 957,\n",
              "  '추석': 958,\n",
              "  '달걀': 959,\n",
              "  '철판': 960,\n",
              "  '오므라이스': 961,\n",
              "  '족발': 962,\n",
              "  '수타': 963,\n",
              "  '우동': 964,\n",
              "  '볶음밥': 965,\n",
              "  '설렁탕': 966,\n",
              "  '떡볶이': 967,\n",
              "  '튀김': 968,\n",
              "  '명함': 969,\n",
              "  '방학': 970,\n",
              "  '삼겹살': 971,\n",
              "  '도넛': 972,\n",
              "  '썰': 973,\n",
              "  '원단': 974,\n",
              "  '가방': 975,\n",
              "  '초감각': 976,\n",
              "  '볶음': 977,\n",
              "  '빙수': 978,\n",
              "  '딤섬': 979,\n",
              "  '이색': 980,\n",
              "  '줄넘기': 981,\n",
              "  '장어': 982,\n",
              "  '뷔페': 983,\n",
              "  '꽈배기': 984,\n",
              "  '칼국수': 985,\n",
              "  '스카프': 986,\n",
              "  '비빔밥': 987,\n",
              "  '호떡': 988,\n",
              "  '분식': 989,\n",
              "  '찐빵': 990,\n",
              "  '간식': 991,\n",
              "  '수제비': 992,\n",
              "  '봉투': 993,\n",
              "  '짬뽕': 994,\n",
              "  '뻥튀기': 995,\n",
              "  '인방': 996,\n",
              "  '돈가스': 997,\n",
              "  '검수': 998,\n",
              "  '아이스': 999,\n",
              "  ...},\n",
              " {0: '남모',\n",
              "  1: '는',\n",
              "  2: '준정',\n",
              "  3: '화랑',\n",
              "  4: '었',\n",
              "  5: '주',\n",
              "  6: '생산',\n",
              "  7: '직경',\n",
              "  8: '톤',\n",
              "  9: '버전',\n",
              "  10: '너지',\n",
              "  11: '헝가리',\n",
              "  12: '선수',\n",
              "  13: '여자',\n",
              "  14: '올림픽',\n",
              "  15: '대포',\n",
              "  16: '파이어',\n",
              "  17: '구형',\n",
              "  18: '미사일',\n",
              "  19: '중국',\n",
              "  20: '홍',\n",
              "  21: '국수',\n",
              "  22: '쿠스',\n",
              "  23: '파우',\n",
              "  24: '문자열',\n",
              "  25: '시동',\n",
              "  26: '입력',\n",
              "  27: '사운드',\n",
              "  28: '가장',\n",
              "  29: '검사',\n",
              "  30: '캐시',\n",
              "  31: '호출',\n",
              "  32: '게임',\n",
              "  33: '섹션',\n",
              "  34: '프로세서',\n",
              "  35: '청안',\n",
              "  36: '선남',\n",
              "  37: '라마',\n",
              "  38: '일본',\n",
              "  39: '함대',\n",
              "  40: '윤인완',\n",
              "  41: '만들',\n",
              "  42: '기원전',\n",
              "  43: '종교',\n",
              "  44: '가톨릭교회',\n",
              "  45: '성',\n",
              "  46: '보',\n",
              "  47: '정부',\n",
              "  48: '루이',\n",
              "  49: '시녀',\n",
              "  50: '아라곤',\n",
              "  51: '유럽',\n",
              "  52: '왕',\n",
              "  53: '서',\n",
              "  54: '영혼',\n",
              "  55: '머리',\n",
              "  56: '읍',\n",
              "  57: '코지마',\n",
              "  58: '극장판',\n",
              "  59: '마사키',\n",
              "  60: '오기노',\n",
              "  61: '포맷',\n",
              "  62: '스톤',\n",
              "  63: '음반',\n",
              "  64: '차트',\n",
              "  65: '시몬스',\n",
              "  66: '이사벨라',\n",
              "  67: '콘스탄티누스',\n",
              "  68: '혼인',\n",
              "  69: '유지',\n",
              "  70: '대머리',\n",
              "  71: '우',\n",
              "  72: '아종',\n",
              "  73: '까',\n",
              "  74: '숲',\n",
              "  75: '필터',\n",
              "  76: '기름',\n",
              "  77: '청소',\n",
              "  78: '구매',\n",
              "  79: '기호',\n",
              "  80: '주포',\n",
              "  81: '램',\n",
              "  82: '묶',\n",
              "  83: '앙각',\n",
              "  84: '분당',\n",
              "  85: '커스',\n",
              "  86: '갖추',\n",
              "  87: '팽',\n",
              "  88: '축구',\n",
              "  89: '리그',\n",
              "  90: '가제',\n",
              "  91: '곡',\n",
              "  92: '작곡',\n",
              "  93: '테레비',\n",
              "  94: '엘리',\n",
              "  95: '펀트',\n",
              "  96: '카운티',\n",
              "  97: '알렉산드라',\n",
              "  98: '나리',\n",
              "  99: '시인',\n",
              "  100: '가선',\n",
              "  101: '친왕',\n",
              "  102: '정',\n",
              "  103: '가인',\n",
              "  104: '고킨와카슈',\n",
              "  105: '돌',\n",
              "  106: '정치',\n",
              "  107: '광',\n",
              "  108: '야간',\n",
              "  109: '포테마요',\n",
              "  110: '코믹',\n",
              "  111: '화',\n",
              "  112: '스나오',\n",
              "  113: '고양이',\n",
              "  114: '메이트',\n",
              "  115: '미캉',\n",
              "  116: '모리야마',\n",
              "  117: '땅',\n",
              "  118: '원래',\n",
              "  119: '구간',\n",
              "  120: '코오롱',\n",
              "  121: '조정',\n",
              "  122: '인더스',\n",
              "  123: '주식',\n",
              "  124: '의류',\n",
              "  125: '자동차',\n",
              "  126: '부품',\n",
              "  127: '케어',\n",
              "  128: '션',\n",
              "  129: '리조트',\n",
              "  130: '적자',\n",
              "  131: '메트로폴리탄',\n",
              "  132: '카슈미르',\n",
              "  133: '이끄',\n",
              "  134: '콤',\n",
              "  135: '갈라파고스',\n",
              "  136: '갈색',\n",
              "  137: '생물',\n",
              "  138: '이사벨',\n",
              "  139: '출장',\n",
              "  140: '오쿠노',\n",
              "  141: '성씨',\n",
              "  142: '역',\n",
              "  143: '교',\n",
              "  144: '레고',\n",
              "  145: '완구',\n",
              "  146: '픽셀',\n",
              "  147: '공략',\n",
              "  148: '트랜스포머',\n",
              "  149: '휴대',\n",
              "  150: '전화',\n",
              "  151: '기종',\n",
              "  152: '이성주',\n",
              "  153: '영화제',\n",
              "  154: '권은희',\n",
              "  155: '국회의원',\n",
              "  156: '도입',\n",
              "  157: '경찰서',\n",
              "  158: '수서',\n",
              "  159: '희',\n",
              "  160: '위증',\n",
              "  161: '앞',\n",
              "  162: '손질',\n",
              "  163: '처분',\n",
              "  164: '수석',\n",
              "  165: '인텔',\n",
              "  166: '칩',\n",
              "  167: '코어',\n",
              "  168: '포레스트',\n",
              "  169: '오페라',\n",
              "  170: '하버드',\n",
              "  171: '래피드',\n",
              "  172: '마이너',\n",
              "  173: '마이닝',\n",
              "  174: '회로',\n",
              "  175: '숨',\n",
              "  176: '버그',\n",
              "  177: '커뮤니티',\n",
              "  178: '업데이트',\n",
              "  179: '계산',\n",
              "  180: '쿼드',\n",
              "  181: '유료',\n",
              "  182: '대부분',\n",
              "  183: '불후',\n",
              "  184: '발매',\n",
              "  185: '상륙',\n",
              "  186: '애쉬',\n",
              "  187: '주말',\n",
              "  188: '인생',\n",
              "  189: '심사',\n",
              "  190: '국민주의',\n",
              "  191: '교황',\n",
              "  192: '스튜어트',\n",
              "  193: '자율',\n",
              "  194: '혁명',\n",
              "  195: '최',\n",
              "  196: '학회',\n",
              "  197: '사이클',\n",
              "  198: '밴',\n",
              "  199: '드로잉',\n",
              "  200: '모형',\n",
              "  201: '교통',\n",
              "  202: '오카야마',\n",
              "  203: '대검찰청',\n",
              "  204: '수부',\n",
              "  205: '검사장',\n",
              "  206: '사무소',\n",
              "  207: '한나라당',\n",
              "  208: '사찰',\n",
              "  209: '하차',\n",
              "  210: '파일럿',\n",
              "  211: '온주쿠',\n",
              "  212: '나미',\n",
              "  213: '철도',\n",
              "  214: '부산',\n",
              "  215: '배명',\n",
              "  216: '루수',\n",
              "  217: '언급',\n",
              "  218: '드래',\n",
              "  219: '깅',\n",
              "  220: '인디언',\n",
              "  221: '투쟁',\n",
              "  222: '버지니아',\n",
              "  223: '테네시',\n",
              "  224: '어퍼',\n",
              "  225: '행동',\n",
              "  226: '프랑스령',\n",
              "  227: '미시시피',\n",
              "  228: '플로리다',\n",
              "  229: '사우스',\n",
              "  230: '캐롤라이나',\n",
              "  231: '이로쿼이',\n",
              "  232: '요새',\n",
              "  233: '오하',\n",
              "  234: '오하이오',\n",
              "  235: '영토',\n",
              "  236: '로버트슨',\n",
              "  237: '퇴거',\n",
              "  238: '헨더슨',\n",
              "  239: '쿨라',\n",
              "  240: '경고',\n",
              "  241: '해밀턴',\n",
              "  242: '기습',\n",
              "  243: '민병대',\n",
              "  244: '포로',\n",
              "  245: '교향악단',\n",
              "  246: '순천',\n",
              "  247: '응진',\n",
              "  248: '탱',\n",
              "  249: '나한도',\n",
              "  250: '제석',\n",
              "  251: '존자',\n",
              "  252: '암벽',\n",
              "  253: '비트',\n",
              "  254: '돌격',\n",
              "  255: '낚시',\n",
              "  256: '헤이그',\n",
              "  257: '윤',\n",
              "  258: '남근',\n",
              "  259: '교육청',\n",
              "  260: '시범',\n",
              "  261: '크리어',\n",
              "  262: '북미',\n",
              "  263: '고리',\n",
              "  264: '벡터',\n",
              "  265: '접',\n",
              "  266: '호모',\n",
              "  267: '토피',\n",
              "  268: '지하철',\n",
              "  269: '시즈먼',\n",
              "  270: '운행',\n",
              "  271: '회전',\n",
              "  272: '노선',\n",
              "  273: '시간표',\n",
              "  274: '미츠키',\n",
              "  275: '미쓰키',\n",
              "  276: '다무라',\n",
              "  277: '트레버',\n",
              "  278: '리전',\n",
              "  279: '비아',\n",
              "  280: '과업',\n",
              "  281: '회피',\n",
              "  282: '측면',\n",
              "  283: '피드백',\n",
              "  284: '끝내',\n",
              "  285: '대개',\n",
              "  286: '욕구',\n",
              "  287: '메타분석',\n",
              "  288: '결합',\n",
              "  289: '효능감',\n",
              "  290: '경혜',\n",
              "  291: '군주',\n",
              "  292: '묘지',\n",
              "  293: '재산',\n",
              "  294: '성종',\n",
              "  295: '김포',\n",
              "  296: '민',\n",
              "  297: '엔진',\n",
              "  298: '프렌즈',\n",
              "  299: '하코다테',\n",
              "  300: '미자',\n",
              "  301: '아사히카와',\n",
              "  302: '전동차',\n",
              "  303: '전철',\n",
              "  304: '에어포트',\n",
              "  305: '신모리야마',\n",
              "  306: '주오',\n",
              "  307: '열차',\n",
              "  308: '컨테이너',\n",
              "  309: '맥주',\n",
              "  310: '가온',\n",
              "  311: '크리스마스',\n",
              "  312: '탄생불',\n",
              "  313: '입상',\n",
              "  314: '불상',\n",
              "  315: '띠',\n",
              "  316: '비례',\n",
              "  317: '도덕경',\n",
              "  318: '노자',\n",
              "  319: '판본',\n",
              "  320: '왕필',\n",
              "  321: '갑',\n",
              "  322: '터널',\n",
              "  323: '법칙',\n",
              "  324: '케임브리지',\n",
              "  325: '왕립',\n",
              "  326: '성인',\n",
              "  327: '정교회',\n",
              "  328: '올스타',\n",
              "  329: '대수',\n",
              "  330: '천문대',\n",
              "  331: '융합',\n",
              "  332: '체코슬로바키아',\n",
              "  333: '위임',\n",
              "  334: '슈테',\n",
              "  335: '마장',\n",
              "  336: '반프레스토',\n",
              "  337: '본작',\n",
              "  338: '류네',\n",
              "  339: '바스',\n",
              "  340: '슈우',\n",
              "  341: '남극',\n",
              "  342: '대결',\n",
              "  343: '기아스',\n",
              "  344: '랑그',\n",
              "  345: '왕국',\n",
              "  346: '오졸',\n",
              "  347: '정복',\n",
              "  348: '론도',\n",
              "  349: '알리',\n",
              "  350: '태조',\n",
              "  351: '태평동',\n",
              "  352: '챔니스',\n",
              "  353: '곤살로',\n",
              "  354: '코르도바',\n",
              "  355: '뇰라',\n",
              "  356: '참호',\n",
              "  357: '페르난도',\n",
              "  358: '그라나다',\n",
              "  359: '나폴리',\n",
              "  360: '창병',\n",
              "  361: '중장기병',\n",
              "  362: '공성전',\n",
              "  363: '전축',\n",
              "  364: '오스만',\n",
              "  365: '지휘관',\n",
              "  366: '총독',\n",
              "  367: '합스부르크',\n",
              "  368: '카우',\n",
              "  369: '아퀴나스',\n",
              "  370: '수도회',\n",
              "  371: '카시노',\n",
              "  372: '알베르투스',\n",
              "  373: '인문',\n",
              "  374: '벙어리',\n",
              "  375: '황소',\n",
              "  376: '영민',\n",
              "  377: '덩치',\n",
              "  378: '오르비에토',\n",
              "  379: '댁',\n",
              "  380: '상징',\n",
              "  381: '신학대전',\n",
              "  382: '펜',\n",
              "  383: '영원',\n",
              "  384: '벌',\n",
              "  385: '미완성',\n",
              "  386: '미사',\n",
              "  387: '공의회',\n",
              "  388: '진위',\n",
              "  389: '교리',\n",
              "  390: '은총',\n",
              "  391: '식물',\n",
              "  392: '성공회',\n",
              "  393: '대한제국',\n",
              "  394: '일진회',\n",
              "  395: '남원',\n",
              "  396: '유로',\n",
              "  397: '아야사토',\n",
              "  398: '카트린느',\n",
              "  399: '아이브',\n",
              "  400: '하이츠',\n",
              "  401: '훈장',\n",
              "  402: '경시',\n",
              "  403: '구두',\n",
              "  404: '김동훈',\n",
              "  405: '교단',\n",
              "  406: '안수',\n",
              "  407: '예수교',\n",
              "  408: '장로회',\n",
              "  409: '타이베이',\n",
              "  410: '총통',\n",
              "  411: '장왕',\n",
              "  412: '진나라',\n",
              "  413: '민중',\n",
              "  414: '서진',\n",
              "  415: '한족',\n",
              "  416: '관중',\n",
              "  417: '서하',\n",
              "  418: '기도',\n",
              "  419: '매춘',\n",
              "  420: '명품',\n",
              "  421: '합당',\n",
              "  422: '북한',\n",
              "  423: '안기부',\n",
              "  424: '노태우',\n",
              "  425: '가오리',\n",
              "  426: '뿌',\n",
              "  427: '기라티나',\n",
              "  428: '포켓몬스터',\n",
              "  429: '디아루가',\n",
              "  430: '펄기아',\n",
              "  431: '포켓몬',\n",
              "  432: '어나더',\n",
              "  433: '깨어진',\n",
              "  434: '오리진',\n",
              "  435: '섀도',\n",
              "  436: '다이브',\n",
              "  437: '퀸',\n",
              "  438: '전송',\n",
              "  439: '실버',\n",
              "  440: '쉐',\n",
              "  441: '팔츠',\n",
              "  442: '에른스트',\n",
              "  443: '세례',\n",
              "  444: '로키산',\n",
              "  445: '홍반',\n",
              "  446: '감염병',\n",
              "  447: '물기',\n",
              "  448: '공예',\n",
              "  449: '헬스',\n",
              "  450: '콜로부스',\n",
              "  451: '규슈',\n",
              "  452: '플라자',\n",
              "  453: '원담',\n",
              "  454: '랜드',\n",
              "  455: '라이온스',\n",
              "  456: '특유재산',\n",
              "  457: '민법',\n",
              "  458: '무인',\n",
              "  459: '니시지마',\n",
              "  460: '우상',\n",
              "  461: '스트로베리',\n",
              "  462: '나이트',\n",
              "  463: '카즈',\n",
              "  464: '프리미엄',\n",
              "  465: '레인',\n",
              "  466: '내레이션',\n",
              "  467: '신자',\n",
              "  468: '내일',\n",
              "  469: '케이크',\n",
              "  470: '크림',\n",
              "  471: '치즈',\n",
              "  472: '간장',\n",
              "  473: '피트',\n",
              "  474: '이강주',\n",
              "  475: '울금',\n",
              "  476: '냄새',\n",
              "  477: '스맥다운',\n",
              "  478: '이기',\n",
              "  479: '우소',\n",
              "  480: '케인',\n",
              "  481: '익스트림',\n",
              "  482: '기야마',\n",
              "  483: '가고시마',\n",
              "  484: '후쿠오카',\n",
              "  485: '야쿠',\n",
              "  486: '미야노',\n",
              "  487: '육상',\n",
              "  488: '야쿠시마',\n",
              "  489: '폭포',\n",
              "  490: '로켓',\n",
              "  491: '다이요',\n",
              "  492: '피겨',\n",
              "  493: '스케이팅',\n",
              "  494: '슈저우',\n",
              "  495: '야스케',\n",
              "  496: '노부나가',\n",
              "  497: '제천시',\n",
              "  498: '단양군',\n",
              "  499: '제천군',\n",
              "  500: '선거구',\n",
              "  501: '로케',\n",
              "  502: '팔레',\n",
              "  503: '스카',\n",
              "  504: '레미콘',\n",
              "  505: '골재',\n",
              "  506: '배합',\n",
              "  507: '슬래그',\n",
              "  508: '숙의',\n",
              "  509: '명종',\n",
              "  510: '하딩',\n",
              "  511: '판화',\n",
              "  512: '몽실이',\n",
              "  513: '몽실',\n",
              "  514: '주사',\n",
              "  515: '호아',\n",
              "  516: '무덤',\n",
              "  517: '여단',\n",
              "  518: '뉴기니',\n",
              "  519: '워든',\n",
              "  520: '정규군',\n",
              "  521: '진승',\n",
              "  522: '오광',\n",
              "  523: '부리',\n",
              "  524: '진여',\n",
              "  525: '진현',\n",
              "  526: '형양',\n",
              "  527: '진가',\n",
              "  528: '이세황제',\n",
              "  529: '장한',\n",
              "  530: '장초군',\n",
              "  531: '항량',\n",
              "  532: '코넬',\n",
              "  533: '농장',\n",
              "  534: '순차',\n",
              "  535: '피자',\n",
              "  536: '페트라',\n",
              "  537: '장관',\n",
              "  538: '까마귀',\n",
              "  539: '울음',\n",
              "  540: '아제르바이잔',\n",
              "  541: '크로마',\n",
              "  542: '샘플링',\n",
              "  543: '색차',\n",
              "  544: '인코딩',\n",
              "  545: '루마',\n",
              "  546: '컴포넌트',\n",
              "  547: '에일리어싱',\n",
              "  548: '비월',\n",
              "  549: '화소',\n",
              "  550: '베른하르트',\n",
              "  551: '방정식',\n",
              "  552: '일식',\n",
              "  553: '미적분학',\n",
              "  554: '역학',\n",
              "  555: '사회주의',\n",
              "  556: '반공',\n",
              "  557: '분자',\n",
              "  558: '차관',\n",
              "  559: '국민운동',\n",
              "  560: '중앙일보',\n",
              "  561: '쿠르디스탄',\n",
              "  562: '프랑크푸르트',\n",
              "  563: '반납',\n",
              "  564: '센트',\n",
              "  565: '계란',\n",
              "  566: '수선',\n",
              "  567: '미원',\n",
              "  568: '기암',\n",
              "  569: '멩거',\n",
              "  570: '박서보',\n",
              "  571: '미술가',\n",
              "  572: '홍익',\n",
              "  573: '종로',\n",
              "  574: '서보',\n",
              "  575: '현대전',\n",
              "  576: '묘법',\n",
              "  577: '단색화',\n",
              "  578: '국전',\n",
              "  579: '조형',\n",
              "  580: '박람회',\n",
              "  581: '인테리어',\n",
              "  582: '이우환',\n",
              "  583: '무라마츠',\n",
              "  584: '대부',\n",
              "  585: '박영덕',\n",
              "  586: '조현',\n",
              "  587: '바젤',\n",
              "  588: '박여숙',\n",
              "  589: '조현화',\n",
              "  590: '샘터',\n",
              "  591: '박람',\n",
              "  592: '국제무역센터',\n",
              "  593: '전람',\n",
              "  594: '대청',\n",
              "  595: '코엑스',\n",
              "  596: '경복궁',\n",
              "  597: '인전',\n",
              "  598: '비엔날레',\n",
              "  599: '협',\n",
              "  600: '당전',\n",
              "  601: '현대미',\n",
              "  602: '술제',\n",
              "  603: '윤형근',\n",
              "  604: '김창렬',\n",
              "  605: '도립',\n",
              "  606: '송년',\n",
              "  607: '흥원',\n",
              "  608: '관훈',\n",
              "  609: '정창섭',\n",
              "  610: '로이드',\n",
              "  611: '컨벤션',\n",
              "  612: '강릉',\n",
              "  613: '네이비',\n",
              "  614: '멜번',\n",
              "  615: '팜',\n",
              "  616: '마이애미비치',\n",
              "  617: '요미우리',\n",
              "  618: '포스트',\n",
              "  619: '탕',\n",
              "  620: '큐브',\n",
              "  621: '코지',\n",
              "  622: '와일드',\n",
              "  623: '프라임',\n",
              "  624: '진로',\n",
              "  625: '카트',\n",
              "  626: '옹주',\n",
              "  627: '감비아',\n",
              "  628: '마산역',\n",
              "  629: '경전선',\n",
              "  630: '무궁화호',\n",
              "  631: '산역',\n",
              "  632: '부전',\n",
              "  633: '디젤',\n",
              "  634: '새마을호',\n",
              "  635: '환승',\n",
              "  636: '주차',\n",
              "  637: '장악원',\n",
              "  638: '융준',\n",
              "  639: '철종',\n",
              "  640: '즉석',\n",
              "  641: '라이프치히',\n",
              "  642: '정무',\n",
              "  643: '비틀즈',\n",
              "  644: '매카트니',\n",
              "  645: '링고',\n",
              "  646: '농어촌버스',\n",
              "  647: '데라우치',\n",
              "  648: '식물상',\n",
              "  649: '클리어타입',\n",
              "  650: '렌더링',\n",
              "  651: '내장',\n",
              "  652: '비트맵',\n",
              "  653: '밀퍼드',\n",
              "  654: '뉴질랜드',\n",
              "  655: '트램',\n",
              "  656: '맥키넌',\n",
              "  657: '캠핑',\n",
              "  658: '점심',\n",
              "  659: '센스',\n",
              "  660: '삼도',\n",
              "  661: '용담',\n",
              "  662: '노형동',\n",
              "  663: '제주시',\n",
              "  664: '와인',\n",
              "  665: '이즈',\n",
              "  666: '드라이브',\n",
              "  667: '카터',\n",
              "  668: '봉성군',\n",
              "  669: '희빈',\n",
              "  670: '윤임',\n",
              "  671: '목욕',\n",
              "  672: '니지마',\n",
              "  673: '쿠사야',\n",
              "  674: '건어물',\n",
              "  675: '하치조',\n",
              "  676: '소금물',\n",
              "  677: '교통국',\n",
              "  678: '드골',\n",
              "  679: '프레더릭',\n",
              "  680: '안사',\n",
              "  681: '곡초',\n",
              "  682: '양초',\n",
              "  683: '사천시',\n",
              "  684: '마도',\n",
              "  685: '천초',\n",
              "  686: '배영',\n",
              "  687: '유대교',\n",
              "  688: '민해경',\n",
              "  689: '마젤란',\n",
              "  690: '피그미',\n",
              "  691: '테니스',\n",
              "  692: '배구',\n",
              "  693: '하치로가타',\n",
              "  694: '함장',\n",
              "  695: '수향',\n",
              "  696: '저우장',\n",
              "  697: '심만삼',\n",
              "  698: '명물',\n",
              "  699: '기저',\n",
              "  700: '회생',\n",
              "  701: '아파트',\n",
              "  702: '청자',\n",
              "  703: '상감',\n",
              "  704: '용봉',\n",
              "  705: '그릇',\n",
              "  706: '숟가락',\n",
              "  707: '황모',\n",
              "  708: '히코네',\n",
              "  709: '급행',\n",
              "  710: '비바',\n",
              "  711: '뉴마켓',\n",
              "  712: '핀치',\n",
              "  713: '멀록',\n",
              "  714: '오처드',\n",
              "  715: '블루밍턴',\n",
              "  716: '제퍼슨',\n",
              "  717: '엘긴',\n",
              "  718: '밀스',\n",
              "  719: '크로스비',\n",
              "  720: '매켄지',\n",
              "  721: '웰드',\n",
              "  722: '카빌',\n",
              "  723: '리치먼드힐',\n",
              "  724: '상시',\n",
              "  725: '아워',\n",
              "  726: '마컴',\n",
              "  727: '스토우',\n",
              "  728: '비버',\n",
              "  729: '크리크',\n",
              "  730: '레슬리',\n",
              "  731: '우드바인',\n",
              "  732: '몽고메리',\n",
              "  733: '버치',\n",
              "  734: '벌록',\n",
              "  735: '매코',\n",
              "  736: '갤',\n",
              "  737: '스워',\n",
              "  738: '우튼',\n",
              "  739: '빌리지',\n",
              "  740: '파크웨이',\n",
              "  741: '유니언',\n",
              "  742: '그로브',\n",
              "  743: '키플링',\n",
              "  744: '이즐링턴',\n",
              "  745: '더퍼린',\n",
              "  746: '미너',\n",
              "  747: '배서스트',\n",
              "  748: '공휴일',\n",
              "  749: '데니슨',\n",
              "  750: '세네카',\n",
              "  751: '레이크',\n",
              "  752: '복스',\n",
              "  753: '월마트',\n",
              "  754: '밀리켄',\n",
              "  755: '코원',\n",
              "  756: '루지',\n",
              "  757: '엘슨',\n",
              "  758: '파이어니어',\n",
              "  759: '메이플',\n",
              "  760: '오크',\n",
              "  761: '버러',\n",
              "  762: '후버',\n",
              "  763: '우드브릿지',\n",
              "  764: '스태프',\n",
              "  765: '슬리',\n",
              "  766: '나파밸리',\n",
              "  767: '러더퍼드',\n",
              "  768: '밀러드',\n",
              "  769: '오토',\n",
              "  770: '헌팅',\n",
              "  771: '셰퍼드',\n",
              "  772: '엘즈미어',\n",
              "  773: '마운트조이',\n",
              "  774: '테스',\n",
              "  775: '킹시티',\n",
              "  776: '우즈',\n",
              "  777: '힐우드',\n",
              "  778: '마노',\n",
              "  779: '헤이즐턴',\n",
              "  780: '아파크',\n",
              "  781: '브랜든',\n",
              "  782: '다이스',\n",
              "  783: '티에라',\n",
              "  784: '멜빌',\n",
              "  785: '크랜스턴',\n",
              "  786: '맥노튼',\n",
              "  787: '오로라',\n",
              "  788: '인더스트리얼',\n",
              "  789: '머레이',\n",
              "  790: '로딕',\n",
              "  791: '칼턴',\n",
              "  792: '버지',\n",
              "  793: '크레스트',\n",
              "  794: '브리스톨',\n",
              "  795: '스웨이',\n",
              "  796: '스테드',\n",
              "  797: '케스',\n",
              "  798: '윅',\n",
              "  799: '퀸스',\n",
              "  800: '그리스트',\n",
              "  801: '귈',\n",
              "  802: '세이크리드',\n",
              "  803: '도너',\n",
              "  804: '사이크스',\n",
              "  805: '헤이븐',\n",
              "  806: '베티',\n",
              "  807: '셀윈',\n",
              "  808: '롤링',\n",
              "  809: '레드스톤',\n",
              "  810: '커머스',\n",
              "  811: '셜리',\n",
              "  812: '스파다',\n",
              "  813: '리치먼드',\n",
              "  814: '트렌치',\n",
              "  815: '쉐프',\n",
              "  816: '올랜도',\n",
              "  817: '뉴커크',\n",
              "  818: '폴스',\n",
              "  819: '데본',\n",
              "  820: '스코',\n",
              "  821: '화이',\n",
              "  822: '홀리',\n",
              "  823: '캐니언',\n",
              "  824: '처치',\n",
              "  825: '엘리오트',\n",
              "  826: '트뤼도',\n",
              "  827: '닐',\n",
              "  828: '스퀘어',\n",
              "  829: '스토니',\n",
              "  830: '테레사',\n",
              "  831: '브릭스',\n",
              "  832: '하이테크',\n",
              "  833: '맥칼럼',\n",
              "  834: '위너스',\n",
              "  835: '키미지마',\n",
              "  836: '남서부',\n",
              "  837: '경전철',\n",
              "  838: '사방',\n",
              "  839: '당함',\n",
              "  840: '투각',\n",
              "  841: '전압',\n",
              "  842: '클럭',\n",
              "  843: '커넥터',\n",
              "  844: '평평',\n",
              "  845: '음성',\n",
              "  846: '소경',\n",
              "  847: '남원경',\n",
              "  848: '삼성메디슨',\n",
              "  849: '삼성그룹',\n",
              "  850: '메디슨',\n",
              "  851: '초음파',\n",
              "  852: '한큐',\n",
              "  853: '한신',\n",
              "  854: '긴테쓰',\n",
              "  855: '윤석양',\n",
              "  856: '전두환',\n",
              "  857: '혁노',\n",
              "  858: '펠',\n",
              "  859: '하위스',\n",
              "  860: '데바나가리',\n",
              "  861: '손숙',\n",
              "  862: '무소속',\n",
              "  863: '서귀포시',\n",
              "  864: '밥상',\n",
              "  865: '마린',\n",
              "  866: '코끼리',\n",
              "  867: '후지코',\n",
              "  868: '플래퍼',\n",
              "  869: '오노데라',\n",
              "  870: '투니',\n",
              "  871: '맥스',\n",
              "  872: '초밥',\n",
              "  873: '터보',\n",
              "  874: '매드',\n",
              "  875: '다빈치',\n",
              "  876: '스티븐',\n",
              "  877: '버거',\n",
              "  878: '슐레겔',\n",
              "  879: '탄광',\n",
              "  880: '할레',\n",
              "  881: '일본식',\n",
              "  882: '기시',\n",
              "  883: '참의원',\n",
              "  884: '타로',\n",
              "  885: '회로도',\n",
              "  886: '불변량',\n",
              "  887: '생피에르',\n",
              "  888: '아카디아',\n",
              "  889: '프랑스인',\n",
              "  890: '노바스코샤',\n",
              "  891: '뉴펀들랜드',\n",
              "  892: '누벨',\n",
              "  893: '권한',\n",
              "  894: '크릭',\n",
              "  895: '셀로',\n",
              "  896: '원정군',\n",
              "  897: '나이아가라',\n",
              "  898: '타나',\n",
              "  899: '베프',\n",
              "  900: '그리슨',\n",
              "  901: '딘위디',\n",
              "  902: '콩트',\n",
              "  903: '봉쇄',\n",
              "  904: '보급품',\n",
              "  905: '보드레',\n",
              "  906: '허드슨',\n",
              "  907: '컨더',\n",
              "  908: '카리용',\n",
              "  909: '퀘벡',\n",
              "  910: '로던',\n",
              "  911: '애버크롬비',\n",
              "  912: '름',\n",
              "  913: '름은',\n",
              "  914: '화약',\n",
              "  915: '옮김',\n",
              "  916: '민사',\n",
              "  917: '정례회',\n",
              "  918: '호킹',\n",
              "  919: '루게릭',\n",
              "  920: '버시',\n",
              "  921: '베르너',\n",
              "  922: '강세',\n",
              "  923: '올가',\n",
              "  924: '니콜라이',\n",
              "  925: '라스푸틴',\n",
              "  926: '알렉세이',\n",
              "  927: '황녀',\n",
              "  928: '여철현',\n",
              "  929: '석방',\n",
              "  930: '퀸즐랜드',\n",
              "  931: '태즈메이니아',\n",
              "  932: '헌법학',\n",
              "  933: '나바테아',\n",
              "  934: '인족',\n",
              "  935: '묘비',\n",
              "  936: '흐르',\n",
              "  937: '만두',\n",
              "  938: '이혜승',\n",
              "  939: '배달',\n",
              "  940: '신문배달',\n",
              "  941: '감별',\n",
              "  942: '설거지',\n",
              "  943: '김밥',\n",
              "  944: '냉면',\n",
              "  945: '가발',\n",
              "  946: '세차',\n",
              "  947: '얼음',\n",
              "  948: '바지락',\n",
              "  949: '수박',\n",
              "  950: '타이어',\n",
              "  951: '어묵',\n",
              "  952: '아이스크림',\n",
              "  953: '떡',\n",
              "  954: '다슬기',\n",
              "  955: '수건',\n",
              "  956: '중식',\n",
              "  957: '서빙',\n",
              "  958: '추석',\n",
              "  959: '달걀',\n",
              "  960: '철판',\n",
              "  961: '오므라이스',\n",
              "  962: '족발',\n",
              "  963: '수타',\n",
              "  964: '우동',\n",
              "  965: '볶음밥',\n",
              "  966: '설렁탕',\n",
              "  967: '떡볶이',\n",
              "  968: '튀김',\n",
              "  969: '명함',\n",
              "  970: '방학',\n",
              "  971: '삼겹살',\n",
              "  972: '도넛',\n",
              "  973: '썰',\n",
              "  974: '원단',\n",
              "  975: '가방',\n",
              "  976: '초감각',\n",
              "  977: '볶음',\n",
              "  978: '빙수',\n",
              "  979: '딤섬',\n",
              "  980: '이색',\n",
              "  981: '줄넘기',\n",
              "  982: '장어',\n",
              "  983: '뷔페',\n",
              "  984: '꽈배기',\n",
              "  985: '칼국수',\n",
              "  986: '스카프',\n",
              "  987: '비빔밥',\n",
              "  988: '호떡',\n",
              "  989: '분식',\n",
              "  990: '찐빵',\n",
              "  991: '간식',\n",
              "  992: '수제비',\n",
              "  993: '봉투',\n",
              "  994: '짬뽕',\n",
              "  995: '뻥튀기',\n",
              "  996: '인방',\n",
              "  997: '돈가스',\n",
              "  998: '검수',\n",
              "  999: '아이스',\n",
              "  ...})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.157872Z",
          "start_time": "2022-02-19T14:33:28.473330Z"
        },
        "id": "ieS5SiQx4WSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ede273e-ed75-4a7b-c9e4-0ab0a4d9f5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 190.39it/s]\n"
          ]
        }
      ],
      "source": [
        "word2count, word2id, id2word = make_vocab(docs, min_count=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.754722Z",
          "start_time": "2022-02-19T14:33:30.752115Z"
        },
        "id": "cT1MRN1EJtx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0572e4e1-a8cd-439c-e05c-581d74d949b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14,508\n"
          ]
        }
      ],
      "source": [
        "doc_len = sum(word2count.values()) # 문서 내 모든 단어의 개수 (단어별 등장 빈도의 총 합)\n",
        "print(f\"{doc_len:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:32.916830Z",
          "start_time": "2022-02-19T14:33:32.914355Z"
        },
        "id": "e_1MneB54WSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00307f42-81a9-4e86-c110-c9df9b0f85d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# unique word : 1,267\n"
          ]
        }
      ],
      "source": [
        "print(f\"# unique word : {len(word2id):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "0e9qsRyLw2L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:27.904880Z",
          "start_time": "2022-02-19T14:33:27.899620Z"
        },
        "id": "-NbsbpTKw4jS"
      },
      "outputs": [],
      "source": [
        "def make_vocab(docs:List[str], min_count:int):\n",
        "    \"\"\"\n",
        "    'docs'문서 리스트를 입력 받아 단어 사전을 생성.\n",
        "    \n",
        "    return \n",
        "        - word2count : 단어별 빈도 사전\n",
        "        - wid2word : 단어별 인덱스(wid) 사전 \n",
        "        - word2wid : 인덱스(wid)별 단어 사전\n",
        "    \"\"\"\n",
        "\n",
        "    word2count = dict()\n",
        "    word2id = dict()\n",
        "    id2word = dict()\n",
        "\n",
        "    _word2count = dict() # 단어별 등장 빈도를 기록하기 위한 임시 딕셔너리 생성\n",
        "    for doc in tqdm(docs):\n",
        "        word_list = doc.split()\n",
        "        # 조건 1. 문서 길이 제한\n",
        "        if len(word_list)>3:\n",
        "            for word in word_list:\n",
        "                # 조건 2. 불용어 제거\n",
        "                if word in stop_words:\n",
        "                    continue\n",
        "                try:\n",
        "                    _word2count[word]+=1\n",
        "                except KeyError:\n",
        "                    _word2count[word]=1\n",
        "\n",
        "    # 조건 3. 토큰 최소 빈도를 만족하는 토큰만 사전(word2count)에 추가\n",
        "    idx=0\n",
        "    for w,c in _word2count.items():\n",
        "        if c<min_count:\n",
        "            continue\n",
        "        word2count[w] = c\n",
        "        word2id[w] = idx\n",
        "        id2word[idx] = w\n",
        "        idx+=1\n",
        "\n",
        "    \n",
        "    return word2count, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.157872Z",
          "start_time": "2022-02-19T14:33:28.473330Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76cf0a2-5676-444b-9b01-ac31d480b12c",
        "id": "5Plnp0nKw4jU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 185.87it/s]\n"
          ]
        }
      ],
      "source": [
        "word2count, word2id, id2word = make_vocab(docs, min_count=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.754722Z",
          "start_time": "2022-02-19T14:33:30.752115Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9381d931-24f0-4b9c-a174-e7fb1e6149a3",
        "id": "_sOJsmdbw4jU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164,843\n"
          ]
        }
      ],
      "source": [
        "doc_len = sum(word2count.values()) # 문서 내 모든 단어의 개수 (unique한 단어 개수 * 단어 등장 빈도)\n",
        "print(f\"{doc_len:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:32.916830Z",
          "start_time": "2022-02-19T14:33:32.914355Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce57158-7f85-4979-bab9-d127927fde71",
        "id": "5YZCHxdpw4jU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# unique word : 5,882\n"
          ]
        }
      ],
      "source": [
        "print(f\"# unique word : {len(word2id):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHxtZqtk4WSm"
      },
      "source": [
        "### Dataset 클래스 구현\n",
        "- Skip-Gram 방식의 학습 데이터 셋(`Tuple(target_word, context_word)`)을 생성하는 `CustomDataset` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()` 함수) 입력 매개변수\n",
        "        - docs: 문서 리스트\n",
        "        - word2id: 단어별 인덱스(wid) 사전\n",
        "        - window_size: Skip-Gram의 윈도우 사이즈\n",
        "    - 메소드\n",
        "        - `make_pair()`\n",
        "            - 문서를 단어로 쪼개고, 사전에 존재하는 단어들만 단어 인덱스로 변경\n",
        "            - Skip-gram 방식의 `(target_word, context_word)` 페어(tuple)들을 `pairs` 리스트에 담아 반환\n",
        "        - `__len__()`\n",
        "            - `pairs` 리스트의 개수 반환\n",
        "        - `__getitem__(index)`\n",
        "            - `pairs` 리스트를 인덱싱\n",
        "    - 주의 사항\n",
        "        - `nn.Module`를 부모 클래스로 상속 받음 \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import skipgrams\n",
        "import itertools"
      ],
      "metadata": {
        "id": "CBzDo-NcHlzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "koDSNeedxFEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.111290Z",
          "start_time": "2022-02-19T14:33:38.104531Z"
        },
        "id": "UPiLcYCZ4WSm"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문서 리스트를 받아 skip-gram 방식의 (target_word, context_word) 데이터 셋을 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, docs:List[str], word2id:Dict[str,int], window_size:int=5):\n",
        "        self.docs = docs\n",
        "        self.word2id = word2id\n",
        "        self.window_size = window_size\n",
        "        self.pairs = self.make_pair()\n",
        "\n",
        "    def make_pair(self):\n",
        "        \"\"\"\n",
        "        (target, context) 형식의 Skip-gram pair 데이터 셋 생성 \n",
        "        \"\"\"\n",
        "        \n",
        "        # 문서 쪼개고 인덱스 변경\n",
        "        pairs = []\n",
        "        processed_docs = []\n",
        "        for doc in self.docs:\n",
        "            split_doc = doc.split(' ')\n",
        "            processed_doc = []\n",
        "            for word in split_doc:\n",
        "                if word in word2id.keys():\n",
        "                    processed_doc.append(self.word2id[word])\n",
        "            processed_docs.append(processed_doc)\n",
        "\n",
        "        pairs = []\n",
        "        for d in processed_docs:\n",
        "            skipgram = list(skipgrams(d, 2, self.window_size))\n",
        "            for i in skipgram:\n",
        "                pairs.append(i)\n",
        "        return pairs\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx][0], self.pairs[idx][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "UbQl-oLTxDLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문서 리스트를 받아 skip-gram 방식의 (target_word, context_word) 데이터 셋을 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, docs:List[str], word2id:Dict[str,int], window_size:int=5):\n",
        "        self.docs = docs\n",
        "        self.word2id = word2id\n",
        "        self.window_size = window_size\n",
        "        self.pairs = self.make_pair()\n",
        "    \n",
        "    def make_pair(self):\n",
        "        \"\"\"\n",
        "        (target, context) 형식의 Skip-gram pair 데이터 셋 생성 \n",
        "        \"\"\"\n",
        "        pairs = []\n",
        "        for doc in tqdm(self.docs):\n",
        "            word_ids = [] # 문서 내 (사전에 존재하는) 단어의 인덱스를 저장하기 위한 리스트 (=학습 데이터)\n",
        "            for word in doc.split():\n",
        "                # 1. 사전(\bword2id)에 존재하는 단어만 단어 인덱스(wid)로 변경해 학습 데이터에 추가\n",
        "                if self.word2id.get(word):\n",
        "                    word_ids.append(self.word2id.get(word))\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            # 2. 학습 데이터 구축\n",
        "            for i, u in enumerate(word_ids):\n",
        "                for j in range(self.window_size):\n",
        "                    if i-1-j>=0: # target_word 기준 왼쪽 방향의 context_word들을 추가\n",
        "                        pairs.append((u, word_ids[i-1-j]))\n",
        "                    if i+1+j<len(word_ids): # target_word 기준 오른쪽 방향의 context_word들을 추가\n",
        "                        pairs.append((u, word_ids[i+1+j]))\n",
        "        return pairs\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx]"
      ],
      "metadata": {
        "id": "KyHk_RyjxES5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.945361Z",
          "start_time": "2022-02-19T14:33:38.385577Z"
        },
        "id": "YntOw2q94WSm"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(docs, word2id, window_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.949614Z",
          "start_time": "2022-02-19T14:33:38.946663Z"
        },
        "id": "-RpNbAjk4WSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f50ff70-751a-4f54-ba05-5b1a3f06b57c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166048"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:43.072635Z",
          "start_time": "2022-02-19T14:33:43.069526Z"
        },
        "id": "1FBwcL4H4WSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5ac481-6a39-426c-f39b-6583a5ec7878"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:51.040595Z",
          "start_time": "2022-02-19T14:33:51.031473Z"
        },
        "id": "wTAwTjKk4WSn",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42d760c-b11b-4b38-eb8d-9d1cd814b340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(남모, 는)\n",
            "(남모, 준정)\n",
            "(남모, 화랑)\n",
            "(남모, 준정)\n",
            "(남모, 화랑)\n",
            "(남모, 었)\n",
            "(는, 준정)\n",
            "(는, 화랑)\n",
            "(는, 준정)\n",
            "(는, 화랑)\n",
            "(는, 었)\n",
            "(는, 는)\n",
            "(준정, 화랑)\n",
            "(준정, 준정)\n",
            "(준정, 화랑)\n",
            "(준정, 었)\n",
            "(준정, 는)\n",
            "(준정, 었)\n",
            "(화랑, 준정)\n",
            "(화랑, 화랑)\n",
            "(화랑, 었)\n",
            "(화랑, 는)\n",
            "(화랑, 었)\n",
            "(화랑, 는)\n",
            "(준정, 화랑)\n",
            "(준정, 었)\n",
            "(준정, 는)\n",
            "(준정, 었)\n",
            "(준정, 는)\n",
            "(준정, 는)\n",
            "(화랑, 었)\n",
            "(화랑, 는)\n",
            "(화랑, 었)\n",
            "(화랑, 는)\n",
            "(화랑, 는)\n",
            "(화랑, 남모)\n",
            "(었, 는)\n",
            "(었, 었)\n",
            "(었, 는)\n",
            "(었, 는)\n",
            "(었, 남모)\n",
            "(었, 준정)\n",
            "(는, 었)\n",
            "(는, 는)\n",
            "(는, 는)\n",
            "(는, 남모)\n",
            "(는, 준정)\n",
            "(는, 는)\n",
            "(었, 는)\n",
            "(었, 는)\n",
            "(었, 남모)\n",
            "(었, 준정)\n",
            "(었, 는)\n",
            "(었, 준정)\n",
            "(는, 는)\n",
            "(는, 남모)\n",
            "(는, 준정)\n",
            "(는, 는)\n",
            "(는, 준정)\n",
            "(는, 남모)\n",
            "(는, 남모)\n",
            "(는, 준정)\n",
            "(는, 는)\n",
            "(는, 준정)\n",
            "(는, 남모)\n",
            "(는, 는)\n",
            "(남모, 준정)\n",
            "(남모, 는)\n",
            "(남모, 준정)\n",
            "(남모, 남모)\n",
            "(남모, 는)\n",
            "(남모, 준정)\n",
            "(준정, 는)\n",
            "(준정, 준정)\n",
            "(준정, 남모)\n",
            "(준정, 는)\n",
            "(준정, 준정)\n",
            "(준정, 는)\n",
            "(는, 준정)\n",
            "(는, 남모)\n",
            "(는, 는)\n",
            "(는, 준정)\n",
            "(는, 는)\n",
            "(는, 준정)\n",
            "(준정, 남모)\n",
            "(준정, 는)\n",
            "(준정, 준정)\n",
            "(준정, 는)\n",
            "(준정, 준정)\n",
            "(준정, 남모)\n",
            "(남모, 는)\n",
            "(남모, 준정)\n",
            "(남모, 는)\n",
            "(남모, 준정)\n",
            "(남모, 남모)\n",
            "(남모, 주)\n",
            "(는, 준정)\n",
            "(는, 는)\n",
            "(는, 준정)\n",
            "(는, 남모)\n"
          ]
        }
      ],
      "source": [
        "# verify (target word, context word)\n",
        "for i, pair in enumerate(dataset):\n",
        "    if i==100:\n",
        "        break\n",
        "    print(f\"({id2word[pair[0]]}, {id2word[pair[1]]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Z50-Dr4WSn"
      },
      "source": [
        "### 위에서 생성한 `dataset`으로 DataLoader  객체 생성\n",
        "- `DataLoader` 클래스로 `train_dataloader`객체를 생성하라. \n",
        "    - 생성자 매개변수와 값\n",
        "        - dataset = 위에서 생성한 dataset\n",
        "        - batch_size = 64\n",
        "        - shuffle = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qMTYP2jlTYBz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:02.645176Z",
          "start_time": "2022-02-19T14:34:02.642780Z"
        },
        "id": "GXcAvFB14WSn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:02.777322Z",
          "start_time": "2022-02-19T14:34:02.774335Z"
        },
        "id": "4Yfcwi_14WSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58c3a42-aaab-411b-888d-f9e58c531fac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2595"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTs16gsU4WSn"
      },
      "source": [
        "### Negative Sampling 함수 구현\n",
        "- Skip-Gram은 복잡도를 줄이기 위한 방법으로 negative sampling을 사용한다. \n",
        "- `sample_table`이 다음과 같이 주어졌을 때, sample_table에서 랜덤으로 값을 뽑아 (batch_size, n_neg_sample) shape의 matrix를 반환하는 `get_neg_v_negative_sampling()`함수를 구현하라. \n",
        "- Sample Table은 negative distribution을 따른다. \n",
        "    - [negative distribution 설명](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#How-are-negative-samples-drawn?)\n",
        "- 함수 정의\n",
        "    - 입력 매개변수\n",
        "        - batch_size : 배치 사이즈, matrix의 row 개수 \n",
        "        - n_neg_sample : negative sample의 개수, matrix의 column 개수\n",
        "    - 반환값 \n",
        "        - neg_v : 추출된 negative sample (2차원의 리스트)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unig_dist  = {'apple': 0.023, 'bee': 0.12, 'desk': 0.34, 'chair': 0.517}\n",
        "\n",
        "sum(unig_dist.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr3zHoaWXMqS",
        "outputId": "32cef854-e857-471e-92a4-bb878c6e3425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha      = 3 / 4\n",
        "\n",
        "noise_dist = {key: val ** alpha for key, val in unig_dist.items()}\n",
        "Z = sum(noise_dist.values())\n",
        "noise_dist_normalized = {key: val / Z for key, val in noise_dist.items()}\n",
        "noise_dist_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0A6jlLrXOSy",
        "outputId": "5771ee3d-e6f4-47c9-bf09-22f614e9538c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'apple': 0.044813853132981724,\n",
              " 'bee': 0.15470428538870049,\n",
              " 'chair': 0.4626305591982827,\n",
              " 'desk': 0.33785130228003507}"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dist_normalized.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMut1DCzZoUH",
        "outputId": "ec48517a-b60b-46b8-e116-b57e8cd68702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([0.044813853132981724, 0.15470428538870049, 0.33785130228003507, 0.4626305591982827])"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice(list(noise_dist_normalized.keys()), size=2, p=list(noise_dist_normalized.values()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AzIcFYlZjPS",
        "outputId": "83080119-2459-49ad-c3ff-a870de2432c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['chair', 'chair'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.397509Z",
          "start_time": "2022-02-19T14:34:11.386389Z"
        },
        "id": "PUqIB6dH4WSn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# negative sample을 추출할 sample table 생성 (해당 코드를 참고)\n",
        "sample_table = []\n",
        "sample_table_size = doc_len\n",
        "\n",
        "# noise distribution 생성\n",
        "alpha = 3/4\n",
        "frequency_list = np.array(list(word2count.values())) ** alpha\n",
        "Z = sum(frequency_list)\n",
        "ratio = frequency_list/Z\n",
        "negative_sample_dist = np.round(ratio*sample_table_size)\n",
        "\n",
        "for wid, c in enumerate(negative_sample_dist):\n",
        "    sample_table.extend([wid]*int(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "YH-gJAOIxYVt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.656046Z",
          "start_time": "2022-02-19T14:34:11.653325Z"
        },
        "id": "mQIVrOIR4WSn"
      },
      "outputs": [],
      "source": [
        "def get_neg_v_negative_sampling(batch_size:int, n_neg_sample:int):\n",
        "    \"\"\"\n",
        "    위에서 정의한 sample_table에서 (batch_size, n_neg_sample) shape만큼 랜덤 추출해 \"네거티브 샘플 메트릭스\"를 생성\n",
        "    np.random.choice() 함수 활용 (위에서 정의한 sample_table을 함수의 argument로 사용)\n",
        "    \"\"\"\n",
        "    neg_v = []\n",
        "    for _ in range(batch_size):\n",
        "        neg_v.append(np.random.choice(negative_sample_dist, size=n_neg_sample, p=ratio))    \n",
        "    return neg_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:12.345976Z",
          "start_time": "2022-02-19T14:34:12.333448Z"
        },
        "id": "8wwT4Af04WSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75ca033-3a2e-4a88-b8d9-8fbbd31e8910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([13.,  8., 11.,  8., 26.]),\n",
              " array([11., 11.,  8., 13.,  8.]),\n",
              " array([37., 35., 10., 10.,  8.]),\n",
              " array([91.,  7.,  7., 10.,  7.])]"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ],
      "source": [
        "get_neg_v_negative_sampling(4, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안\n"
      ],
      "metadata": {
        "id": "5xUMbwXqxVTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.656046Z",
          "start_time": "2022-02-19T14:34:11.653325Z"
        },
        "id": "f6lzLtpzxXVO"
      },
      "outputs": [],
      "source": [
        "def get_neg_v_negative_sampling(batch_size:int, n_neg_sample:int):\n",
        "    \"\"\"\n",
        "    (batch_size, n_neg_sample) shape의 네거티브 샘플 메트릭스 생성\n",
        "    \"\"\"\n",
        "    neg_v = np.random.choice(\n",
        "        sample_table, size=(batch_size, n_neg_sample)\n",
        "    ).tolist()\n",
        "    return neg_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:12.345976Z",
          "start_time": "2022-02-19T14:34:12.333448Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d2b67c-7692-4903-aac6-c2249b5525e8",
        "id": "QkQR03dgxXVO"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[52, 5544, 62, 3648, 2568],\n",
              " [394, 5247, 480, 4551, 1700],\n",
              " [340, 272, 86, 4529, 2120],\n",
              " [2025, 1128, 4625, 1168, 122]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "get_neg_v_negative_sampling(4, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLnDXPvJ4WSo"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5UubCzK4WSo"
      },
      "source": [
        "### 미니 튜토리얼\n",
        "- 아래 튜토리얼을 따라하며 Skip-Gram 모델의 `forward` 및 `loss` 연산 방식을 이해하자\n",
        "- Reference\n",
        "    - [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "    - [torch bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html)\n",
        "    - [Skip-Gram negative sampling loss function 설명 영문 블로그](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#Derivation-of-Cost-Function-in-Negative-Sampling)\n",
        "    - [Skip-Gram negative sampling loss function 설명 한글 블로그](https://reniew.github.io/22/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:46.954048Z",
          "start_time": "2022-02-19T12:51:46.951529Z"
        },
        "id": "IAR68hsY4WSo"
      },
      "outputs": [],
      "source": [
        "# hyper parameter example\n",
        "emb_size = 30000 # vocab size\n",
        "emb_dimension = 300 # word embedding 차원\n",
        "n_neg_sample = 5\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.340056Z",
          "start_time": "2022-02-19T12:51:47.300999Z"
        },
        "id": "zzOsVUn94WSo"
      },
      "outputs": [],
      "source": [
        "# 1. Embedding Matrix와 Context Matrix를 생성\n",
        "u_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)\n",
        "v_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.352240Z",
          "start_time": "2022-02-19T12:51:49.341437Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7J_ADc44WSo",
        "outputId": "94dc8379-df40-4403-9c3e-74c85533d807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target word idx : tensor([14572, 10481, 25327, 20031, 10027,  6139, 17569, 24028, 11394, 14033,\n",
            "        12346, 25481, 19493, 26680,   942,   955,  5524,   867, 27904,  2491,\n",
            "         2942,  9336, 24810, 19743, 25878, 25576,  8457, 20755, 23879, 23977,\n",
            "        23030, 29186]) Pos context word idx : tensor([10906,  9884, 24171, 22064,  8590, 27028, 14188,  8228, 24948, 12864,\n",
            "        16590,  4498, 10483, 17456, 25003,  7229,  3242, 22617,  1203, 26626,\n",
            "        25998,  1121, 14825, 11618, 10707, 21143,  9198,  3756, 15791, 17739,\n",
            "         1858,  3334]) Neg context word idx : [array([35.,  8.,  8., 30., 17.]), array([54., 14., 10., 19.,  8.]), array([10., 16.,  7., 54.,  9.]), array([12.,  9.,  8., 11.,  8.]), array([ 7., 13., 12.,  8., 19.]), array([12.,  8., 16.,  8.,  7.]), array([24., 10., 20., 19., 91.]), array([ 8., 10.,  8., 10., 31.]), array([11., 35., 13.,  8.,  8.]), array([67.,  9.,  7., 31.,  8.]), array([14., 13.,  8.,  8., 18.]), array([ 8., 11., 53., 26., 29.]), array([18.,  8., 13.,  9., 10.]), array([ 8.,  9., 14., 13.,  8.]), array([ 7.,  8., 26.,  9.,  7.]), array([ 7.,  7.,  9., 16., 28.]), array([ 7.,  9., 17., 13., 13.]), array([ 7.,  8., 24.,  7., 20.]), array([ 7.,  8.,  8., 86.,  7.]), array([ 8., 13.,  8., 13., 26.]), array([57., 14., 13.,  8., 19.]), array([21.,  8., 48.,  7., 10.]), array([20., 26., 86.,  7., 35.]), array([11., 10., 86., 19., 21.]), array([ 8., 11., 10.,  8.,  8.]), array([21., 13., 70., 43.,  8.]), array([ 9., 18.,  7.,  8., 22.]), array([ 7.,  8., 14., 22., 21.]), array([ 7., 13.,  7., 13., 17.]), array([ 7.,  8., 22., 13., 11.]), array([40., 13., 24., 11., 16.]), array([ 8.,  8.,  7., 86.,  7.])]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. wid(단어 인덱스)를 임의로 생성\n",
        "pos_u = torch.randint(high = emb_size, size = (batch_size,))\n",
        "pos_v = torch.randint(high = emb_size, size = (batch_size,))\n",
        "neg_v = get_neg_v_negative_sampling(batch_size, n_neg_sample)\n",
        "print(f\"Target word idx : {pos_u} Pos context word idx : {pos_v} Neg context word idx : {neg_v}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.364020Z",
          "start_time": "2022-02-19T12:51:49.353486Z"
        },
        "id": "4iEG0nCZ4WSo"
      },
      "outputs": [],
      "source": [
        "# 3. tensor로 변환\n",
        "pos_u = Variable(torch.LongTensor(pos_u)).to(device)\n",
        "pos_v = Variable(torch.LongTensor(pos_v)).to(device)\n",
        "neg_v = Variable(torch.LongTensor(neg_v)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:51.391896Z",
          "start_time": "2022-02-19T12:51:51.387084Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqbNbajG4WSo",
        "outputId": "f4fee845-71b7-4278-e693-07d8f09e75ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of pos_u embedding : torch.Size([32, 300])\n",
            " shape of pos_v embedding : torch.Size([32, 300])\n",
            " shape of neg_v embedding : torch.Size([32, 5, 300])\n"
          ]
        }
      ],
      "source": [
        "# 4. wid로 각각의 embedding matrix에서 word embedding 값을 가져오기\n",
        "pos_u = u_embedding(pos_u)\n",
        "pos_v = v_embedding(pos_v)\n",
        "neg_v = v_embedding(neg_v)\n",
        "print(f\"shape of pos_u embedding : {pos_u.shape}\\n shape of pos_v embedding : {pos_v.shape}\\n shape of neg_v embedding : {neg_v.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:53.121477Z",
          "start_time": "2022-02-19T12:51:52.646148Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDWUrSwo4WSo",
        "outputId": "60e4d25b-4f72-4ab0-fb22-6aa6a3024dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of pos logits : torch.Size([32])\n",
            "\n",
            "shape of logits : torch.Size([32, 5])\n"
          ]
        }
      ],
      "source": [
        "# 5. dot product \n",
        "pos_score = torch.mul(pos_u, pos_v) # 행렬 element-wise 곱\n",
        "pos_score = torch.sum(pos_score, dim=1)\n",
        "print(f\"shape of pos logits : {pos_score.shape}\\n\")\n",
        "\n",
        "neg_score = torch.bmm(neg_v, pos_u.unsqueeze(dim=2)).squeeze()\n",
        "print(f\"shape of logits : {neg_score.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:53.670418Z",
          "start_time": "2022-02-19T12:51:53.665671Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adOpcoL54WSo",
        "outputId": "4feb1410-86e9-41ad-c773-e8a0267d0d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos logits : -324.05657958984375\n",
            "neg logits : -1160.510009765625\n",
            "Loss : 1484.566650390625\n"
          ]
        }
      ],
      "source": [
        "# 6. loss 구하기\n",
        "pos_score = F.logsigmoid(pos_score)\n",
        "neg_score = F.logsigmoid(-1*neg_score) # negative의 logit은 minimize 하기 위해 -1 곱함\n",
        "print(f\"pos logits : {pos_score.sum()}\")\n",
        "print(f\"neg logits : {neg_score.sum()}\")\n",
        "loss = -1 * (torch.sum(pos_score) + torch.sum(neg_score))\n",
        "print(f\"Loss : {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muEceOGZ4WSo"
      },
      "source": [
        "### Skip-gram 클래스 구현\n",
        "- Skip-Gram 방식으로 단어 embedding을 학습하는 `SkipGram` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()` 함수) 입력 매개변수\n",
        "        - `vocab_size` : 사전내 단어 개수\n",
        "        - `emb_dimension` : 엠베딩 크기\n",
        "        - `device` : 연산 장치 종류\n",
        "    - 생성자에서 생성해야할 변수 \n",
        "        - `vocab_size` : 사전내 단어 개수\n",
        "        - `emb_dimension` : 엠베딩 크기\n",
        "        - `u_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (target_word)\n",
        "        - `v_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (context_word)\n",
        "    - 메소드\n",
        "        - `init_embedding()` (제공됨)\n",
        "            - 엠베딩 메트릭스 값을 초기화\n",
        "        - `forward()`\n",
        "            - 위 튜토리얼과 같이 dot product를 수행한 후 score를 생성\n",
        "            - loss를 반환 (loss 설명 추가)\n",
        "        - `save_emedding()` (제공됨)\n",
        "            - `u_embedding`의 단어 엠베딩 값을 단어 별로 파일에 저장\n",
        "    - 주의 사항     \n",
        "        - `nn.Module`를 부모 클래스로 상속 받음 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "kdU4SR4mxmqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:15.731306Z",
          "start_time": "2022-02-19T14:34:15.721129Z"
        },
        "id": "pnmMamP44WSo"
      },
      "outputs": [],
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size:int, emb_dimension:int, device:str):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.u_embedding = nn.Embedding(vocab_size, self.emb_dimension, sparse=True) .to(device)\n",
        "        self.v_embedding = nn.Embedding(vocab_size, self.emb_dimension, sparse=True) .to(device)\n",
        "        self.init_embedding()\n",
        "    \n",
        "    \n",
        "    def init_embedding(self):\n",
        "        \"\"\"\n",
        "        u_embedding과 v_embedding 메트릭스 값을 초기화\n",
        "        \"\"\"\n",
        "        initrange = 0.5 / self.emb_dimension\n",
        "        self.u_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.v_embedding.weight.data.uniform_(-0, 0)\n",
        "    \n",
        "    \n",
        "    def forward(self, pos_u, pos_v, neg_v):\n",
        "        \"\"\"\n",
        "        dot product를 수행한 후 score를 생성\n",
        "        loss 반환\n",
        "        \"\"\"    \n",
        "            \n",
        "        # 각각의 embedding matrix에서 word embedding 값을 가져오기\n",
        "        pos_u = self.u_embedding(pos_u)\n",
        "        pos_v = self.v_embedding(pos_v)\n",
        "        neg_v = self.v_embedding(neg_v)\n",
        "        \n",
        "        # dot product \n",
        "        pos_score = torch.sum(torch.mul(pos_u, pos_v), dim=1)\n",
        "        neg_score = torch.sum(torch.bmm(neg_v, pos_u.unsqueeze(2)).squeeze(), dim=1)\n",
        "        \n",
        "        # loss 구하기\n",
        "        loss = F.logsigmoid(pos_score).squeeze() + F.logsigmoid(-1*neg_score).squeeze()\n",
        "\n",
        "        return -1*loss.sum()\n",
        "    \n",
        "    def save_embedding(self, id2word, file_name, use_cuda):\n",
        "        \"\"\"\n",
        "        'file_name' 위치에 word와 word_embedding을 line-by로 저장\n",
        "        파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n",
        "        \"\"\"\n",
        "        if use_cuda: # parameter를 gpu 메모리에서 cpu 메모리로 옮김\n",
        "            embedding = self.u_embedding.weight.cpu().data.numpy()\n",
        "        else:\n",
        "            embedding = self.u_embedding.weight.data.numpy()\n",
        "\n",
        "        with open(file_name, 'w') as writer:\n",
        "            # 파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n",
        "            writer.write(f\"{len(id2word)} {embedding.shape[-1]}\\n\")\n",
        "            \n",
        "            for wid, word in id2word.items():\n",
        "                e = embedding[wid]\n",
        "                e = \" \".join([str(e_) for e_ in e])\n",
        "                writer.write(f\"{word} {e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "EIN5Ji2cxiut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size:int, emb_dimension:int, device:str):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.u_embedding = nn.Embedding(vocab_size, emb_dimension, sparse=True).to(device)\n",
        "        self.v_embedding = nn.Embedding(vocab_size, emb_dimension, sparse=True).to(device)\n",
        "        self.init_embedding()\n",
        "    \n",
        "    \n",
        "    def init_embedding(self):\n",
        "        \"\"\"\n",
        "        u_embedding과 v_embedding 메트릭스 값을 초기화\n",
        "        \"\"\"\n",
        "        initrange = 0.5 / self.emb_dimension\n",
        "        self.u_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.v_embedding.weight.data.uniform_(-0, 0)\n",
        "    \n",
        "    \n",
        "    def forward(self, pos_u, pos_v, neg_v):\n",
        "        \"\"\"\n",
        "        ...\n",
        "        \"\"\"    \n",
        "            \n",
        "        pos_u = self.u_embedding(pos_u)\n",
        "        pos_v = self.v_embedding(pos_v)\n",
        "        neg_v = self.v_embedding(neg_v)\n",
        "        \n",
        "        pos_score = torch.mul(pos_u, pos_v)\n",
        "        pos_score = torch.sum(pos_score, dim=1)\n",
        "        pos_score = F.logsigmoid(pos_score)\n",
        "        neg_score = torch.bmm(neg_v, pos_u.unsqueeze(dim=2)).squeeze()\n",
        "        neg_score = F.logsigmoid(-1 * neg_score)\n",
        "        \n",
        "        loss = -1 * (torch.sum(pos_score) + torch.sum(neg_score))\n",
        "        return loss\n",
        "    \n",
        "    def save_embedding(self, id2word, file_name, use_cuda):\n",
        "        \"\"\"\n",
        "        'file_name' 위치에 word와 word_embedding을 line-by로 저장\n",
        "        \"\"\"\n",
        "        if use_cuda: # parameter를 gpu 메모리에서 cpu 메모리로 옮김\n",
        "            embedding = self.u_embedding.weight.cpu().data.numpy()\n",
        "        else:\n",
        "            embedding = self.u_embedding.weight.data.numpy()\n",
        "        \n",
        "        with open(file_name, 'w') as writer:\n",
        "            # 파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n",
        "            writer.write(f\"{len(id2word)} {embedding.shape[-1]}\\n\")\n",
        "            \n",
        "            for wid, word in id2word.items():\n",
        "                e = embedding[wid]\n",
        "                e = \" \".join([str(e_) for e_ in e])\n",
        "                writer.write(f\"{word} {e}\\n\")\n",
        "                "
      ],
      "metadata": {
        "id": "rjy7LEDdxksv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqMo0zL4WSo"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSWd5gV24WSp"
      },
      "source": [
        "### Skip-Gram 방식의  Word2Vec 클래스 구현\n",
        "- Skip-Gram 방식으로 단어 embedding을 학습하는 `Word2Vec` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()`) 입력 매개 변수\n",
        "        - `input_file` : 학습할 문서 리스트\n",
        "        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n",
        "        - `device` : 연상 장치 종류\n",
        "        - `emb_dimension` : word embedding 차원\n",
        "        - `batch_size` : 학습 배치 사이즈\n",
        "        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n",
        "        - `n_neg_sample` : negative sample 개수\n",
        "        - `iteration` : 학습 반복 횟수\n",
        "        - `lr` : learning rate\n",
        "        - `min_count` : 사전에 추가될 단어의 최소 등장 빈도\n",
        "    - 생성자에서 생성해야 할 변수 \n",
        "        - `docs` : 학습할 문서 리스트\n",
        "        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n",
        "        - `word2count`, `word2id`, `id2word` : 위에서 구현한 `make_vocab()` 함수의 반환 값\n",
        "        - `device` : 연산 장치 종류\n",
        "        - `emb_size` : vocab의 (unique한) 단어 종류 \n",
        "        - `emb_dimension` : word embedding 차원\n",
        "        - `batch_size` : 학습 배치 사이즈\n",
        "        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n",
        "        - `n_neg_sample` : negative sample 개수\n",
        "        - `iteration` : 학습 반복 횟수\n",
        "        - `lr` : learning rate\n",
        "        - `model` : `SkipGram` 클래스의 인스턴스\n",
        "        - `optimizer` : `SGD` 클래스의 인스턴스\n",
        "    - 메소드\n",
        "        - `train()`\n",
        "            - 입력 매개변수 \n",
        "                - `train_dataloader`\n",
        "            - Iteration 횟수만큼 input_file 학습 데이터를 학습한다. 매 epoch마다 for loop 돌면서 batch 단위 학습 데이터를 skip gram 모델에 학습함. 학습이 끝나면 word embedding을 output_file_name 파일에 저장.\n",
        "- Reference\n",
        "    - [Optimizer - SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "H9Y-GaA8xtPk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:20.503555Z",
          "start_time": "2022-02-19T14:34:20.491585Z"
        },
        "id": "Td-GQrqI4WSp"
      },
      "outputs": [],
      "source": [
        "class Word2Vec:\n",
        "    def __init__(self, \n",
        "                input_file: List[str],\n",
        "                output_file_name: str,\n",
        "                 device: str,\n",
        "                 emb_dimension=300,\n",
        "                 batch_size = 64,\n",
        "                 window_size=5,\n",
        "                 n_neg_sample = 5,\n",
        "                 iteration=1,\n",
        "                 lr = 0.02,\n",
        "                 min_count=5):\n",
        "        self.docs = input_file\n",
        "        self.output_file_name = output_file_name\n",
        "        self.word2count, self.word2id, self.id2word = make_vocab(input_file, min_count=5)\n",
        "        self.device = device\n",
        "        self.emb_size = len(self.word2count)\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.batch_size = batch_size\n",
        "        self.window_size = window_size\n",
        "        self.n_neg_sample = n_neg_sample\n",
        "        self.iteration = iteration\n",
        "        self.lr = lr\n",
        "        self.model = SkipGram(vocab_size=self.emb_size, emb_dimension=self.emb_dimension, device=self.device)\n",
        "        self.optimizer = torch.optim.SGD(params=self.model.parameters(), lr=self.lr) # torch.optim.SGD 클래스 사용\n",
        "\n",
        "        # train() 함수에서 만든 임베딩 결과 파일들을 저장할 폴더 생성 (os.makedirs 사용)\n",
        "        os.makedirs(self.output_file_name, exist_ok=True)\n",
        "        \n",
        "    \n",
        "    def train(self, train_dataloader):\n",
        "        \n",
        "        # lr 값을 조절하는 스케줄러 인스턴스 변수를 생성\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer = self.optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=len(train_dataloader) * self.iteration\n",
        "        )\n",
        "        \n",
        "        for epoch in range(self.iteration):\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "            total_loss, batch_loss, batch_step = 0,0,0\n",
        "\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_step+=1\n",
        "\n",
        "                pos_u, pos_v = batch\n",
        "                # negative data 생성\n",
        "                neg_v = get_neg_v_negative_sampling(pos_u.shape[0], self.n_neg_sample)\n",
        "                \n",
        "                # 데이터를 tensor화 & device 설정\n",
        "                pos_u = torch.LongTensor(pos_u).to(self.device)\n",
        "                pos_v = torch.LongTensor(pos_v).to(self.device)\n",
        "                neg_v = torch.LongTensor(neg_v).to(self.device)\n",
        "\n",
        "                # model의 gradient 초기화\n",
        "                self.model.zero_grad() \n",
        "                # optimizer의 gradient 초기화\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                loss = self.model(pos_u, pos_v, neg_v)\n",
        "\n",
        "                # loss 계산\n",
        "                loss.backward()\n",
        "                # optimizer 업데이트\n",
        "                self.optimizer.step() \n",
        "                # scheduler 업데이트\n",
        "                self.scheduler.step()\n",
        "\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "                \n",
        "                if (step%500 == 0) and (step!=0):\n",
        "                    print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {self.optimizer.param_groups[0]['lr']:.4f}\")\n",
        "                    # 변수 초기화    \n",
        "                    batch_loss, batch_step = 0,0\n",
        "            \n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Saving Embedding...*****\")\n",
        "            self.model.save_embedding(self.id2word, os.path.join(self.output_file_name, f'w2v_{epoch}.txt'), True if 'cuda' in self.device.type else False)\n",
        "            print(f\"*****Epoch {epoch} Embedding Saved at {os.path.join(self.output_file_name, f'w2v_{epoch}.txt')}*****\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:29.561892Z",
          "start_time": "2022-02-19T14:34:26.103659Z"
        },
        "id": "Ywx9R8n24WSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44e08a7-e10b-4787-c2cf-ffebf18295ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 187.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2595\n",
            "*****Epoch 0 Train Start*****\n",
            "*****Epoch 0 Total Step 2595*****\n",
            "Step: 500 Loss: 40.2254 lr: 0.0187\n",
            "Step: 1000 Loss: 27.2442 lr: 0.0174\n",
            "Step: 1500 Loss: 22.1698 lr: 0.0161\n",
            "Step: 2000 Loss: 19.8511 lr: 0.0149\n",
            "Step: 2500 Loss: 17.9831 lr: 0.0136\n",
            "Epoch 0 Total Mean Loss : 25.2121\n",
            "*****Epoch 0 Train Finished*****\n",
            "\n",
            "*****Epoch 0 Saving Embedding...*****\n",
            "*****Epoch 0 Embedding Saved at ./word2vec_wiki/w2v_0.txt*****\n",
            "\n",
            "*****Epoch 1 Train Start*****\n",
            "*****Epoch 1 Total Step 2595*****\n",
            "Step: 500 Loss: 16.3507 lr: 0.0120\n",
            "Step: 1000 Loss: 15.3007 lr: 0.0108\n",
            "Step: 1500 Loss: 14.4759 lr: 0.0095\n",
            "Step: 2000 Loss: 13.6116 lr: 0.0082\n",
            "Step: 2500 Loss: 13.3432 lr: 0.0069\n",
            "Epoch 1 Total Mean Loss : 14.5554\n",
            "*****Epoch 1 Train Finished*****\n",
            "\n",
            "*****Epoch 1 Saving Embedding...*****\n",
            "*****Epoch 1 Embedding Saved at ./word2vec_wiki/w2v_1.txt*****\n",
            "\n",
            "*****Epoch 2 Train Start*****\n",
            "*****Epoch 2 Total Step 2595*****\n",
            "Step: 500 Loss: 12.9155 lr: 0.0054\n",
            "Step: 1000 Loss: 12.4151 lr: 0.0041\n",
            "Step: 1500 Loss: 12.1056 lr: 0.0028\n",
            "Step: 2000 Loss: 11.9435 lr: 0.0015\n",
            "Step: 2500 Loss: 11.8531 lr: 0.0002\n",
            "Epoch 2 Total Mean Loss : 12.2136\n",
            "*****Epoch 2 Train Finished*****\n",
            "\n",
            "*****Epoch 2 Saving Embedding...*****\n",
            "*****Epoch 2 Embedding Saved at ./word2vec_wiki/w2v_2.txt*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_file = os.path.join(\".\", \"word2vec_wiki\")\n",
        "# Word2Vec 클래스의 인스턴스 생성\n",
        "w2v = Word2Vec(docs, output_file, device, n_neg_sample=10, iteration=3)\n",
        "\n",
        "# 학습 데이터 셋 및 데이터 로더 생성 (위에서 생성한 w2v의 attribute들을 argument에 적절히 넣기)\n",
        "dataset = dataset\n",
        "train_dataloader = train_dataloader\n",
        "print(len(train_dataloader))\n",
        "\n",
        "# 학습\n",
        "w2v.train(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "OISVqeBhxuxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:20.503555Z",
          "start_time": "2022-02-19T14:34:20.491585Z"
        },
        "id": "lspubmRaxxdO"
      },
      "outputs": [],
      "source": [
        "class Word2Vec:\n",
        "    def __init__(self, \n",
        "                input_file: List[str],\n",
        "                output_file_name: str,\n",
        "                 device: str,\n",
        "                 emb_dimension=300,\n",
        "                 batch_size = 64,\n",
        "                 window_size=5,\n",
        "                 n_neg_sample = 5,\n",
        "                 iteration=1,\n",
        "                 lr = 0.02,\n",
        "                 min_count=5):\n",
        "        self.docs = input_file\n",
        "        self.output_file_name = output_file_name\n",
        "        self.word2count, self.word2id, self.id2word = make_vocab(self.docs, min_count=min_count)\n",
        "        self.device = device\n",
        "        self.emb_size = len(self.word2id)\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.batch_size =batch_size\n",
        "        self.window_size = window_size\n",
        "        self.n_neg_sample = n_neg_sample\n",
        "        self.iteration = iteration\n",
        "        self.lr = lr\n",
        "        self.model = SkipGram(self.emb_size, self.emb_dimension, self.device)\n",
        "        self.optimizer = SGD(\n",
        "            self.model.parameters(),\n",
        "            lr = self.lr\n",
        "        )\n",
        "        # 파일 저장할 폴더 생성\n",
        "        os.makedirs(self.output_file_name, exist_ok=True)\n",
        "        \n",
        "    \n",
        "    def train(self, train_dataloader):\n",
        "        \n",
        "        # lr 값을 조절하는 스케줄러 인스턴스 변수를 생성\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "            self.optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=len(train_dataloader)*self.iteration\n",
        "        )\n",
        "        \n",
        "        for epoch in range(self.iteration):\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "            total_loss, batch_loss, batch_step = 0,0,0\n",
        "\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_step+=1\n",
        "\n",
        "                pos_u, pos_v = batch\n",
        "                # negative data 생성\n",
        "                # neg_v = get_neg_v_negative_sampling(self.batch_size, self.n_neg_sample)\n",
        "                neg_v = get_neg_v_negative_sampling(pos_u.shape[0], self.n_neg_sample)\n",
        "                \n",
        "                # 데이터를 tensor화 & device 설정\n",
        "                pos_u = Variable(torch.LongTensor(pos_u)).to(self.device)\n",
        "                pos_v = Variable(torch.LongTensor(pos_v)).to(self.device)\n",
        "                neg_v = Variable(torch.LongTensor(neg_v)).to(self.device)\n",
        "\n",
        "                # gradient 초기화\n",
        "                self.optimizer.zero_grad()\n",
        "                self.model.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                loss = self.model.forward(pos_u, pos_v, neg_v)\n",
        "\n",
        "                # loss\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "                \n",
        "                if (step%500 == 0) and (step!=0):\n",
        "                    print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {self.optimizer.param_groups[0]['lr']:.4f}\")\n",
        "                    # 변수 초기화    \n",
        "                    batch_loss, batch_step = 0,0\n",
        "            \n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Saving Embedding...*****\")\n",
        "            self.model.save_embedding(self.id2word, os.path.join(self.output_file_name, f'w2v_{epoch}.txt'), True if 'cuda' in self.device.type else False)\n",
        "            print(f\"*****Epoch {epoch} Embedding Saved at {os.path.join(self.output_file_name, f'w2v_{epoch}.txt')}*****\\n\")\n",
        "                    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:29.561892Z",
          "start_time": "2022-02-19T14:34:26.103659Z"
        },
        "outputId": "805ed831-8ed6-4bf4-cfd2-ee9e7436e2dc",
        "id": "FKmq-Yo0xxdP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 297.95it/s]\n"
          ]
        }
      ],
      "source": [
        "# Word2Vec 클래스의 인스턴스 생성\n",
        "output_file = os.path.join(\".\", \"word2vec_wiki\")\n",
        "w2v = Word2Vec(docs, output_file, device, n_neg_sample=10, iteration=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:34.615469Z",
          "start_time": "2022-02-19T14:34:34.055502Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufBxjKxN4WSp",
        "outputId": "a2c60034-f27a-4bcf-d376-511404d7ff98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 956.28it/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21482"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 학습 데이터 셋 및 데이터 로더 생성\n",
        "dataset = CustomDataset(w2v.docs, w2v.word2id, w2v.window_size)\n",
        "train_dataloader = DataLoader(dataset, w2v.batch_size)\n",
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:45:38.362817Z",
          "start_time": "2022-02-19T14:34:37.382371Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9JBUrUJ34WSp",
        "outputId": "6c9d2d38-0d46-4628-bd8d-43fb40a781da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****Epoch 0 Train Start*****\n",
            "*****Epoch 0 Total Step 21482*****\n",
            "Step: 500 Loss: 484.5451 lr: 0.0198\n",
            "Step: 1000 Loss: 395.7239 lr: 0.0197\n",
            "Step: 1500 Loss: 248.9553 lr: 0.0195\n",
            "Step: 2000 Loss: 200.7881 lr: 0.0194\n",
            "Step: 2500 Loss: 119.2248 lr: 0.0192\n",
            "Step: 3000 Loss: 104.1140 lr: 0.0191\n",
            "Step: 3500 Loss: 229.0389 lr: 0.0189\n",
            "Step: 4000 Loss: 235.0788 lr: 0.0188\n",
            "Step: 4500 Loss: 237.9144 lr: 0.0186\n",
            "Step: 5000 Loss: 212.8852 lr: 0.0184\n",
            "Step: 5500 Loss: 192.6870 lr: 0.0183\n",
            "Step: 6000 Loss: 209.6250 lr: 0.0181\n",
            "Step: 6500 Loss: 215.1007 lr: 0.0180\n",
            "Step: 7000 Loss: 164.4239 lr: 0.0178\n",
            "Step: 7500 Loss: 170.4262 lr: 0.0177\n",
            "Step: 8000 Loss: 187.0456 lr: 0.0175\n",
            "Step: 8500 Loss: 204.3405 lr: 0.0174\n",
            "Step: 9000 Loss: 194.8780 lr: 0.0172\n",
            "Step: 9500 Loss: 205.0695 lr: 0.0171\n",
            "Step: 10000 Loss: 186.4944 lr: 0.0169\n",
            "Step: 10500 Loss: 185.5174 lr: 0.0167\n",
            "Step: 11000 Loss: 197.1707 lr: 0.0166\n",
            "Step: 11500 Loss: 194.6444 lr: 0.0164\n",
            "Step: 12000 Loss: 188.4481 lr: 0.0163\n",
            "Step: 12500 Loss: 197.3222 lr: 0.0161\n",
            "Step: 13000 Loss: 194.7771 lr: 0.0160\n",
            "Step: 13500 Loss: 195.8214 lr: 0.0158\n",
            "Step: 14000 Loss: 185.1680 lr: 0.0157\n",
            "Step: 14500 Loss: 189.6969 lr: 0.0155\n",
            "Step: 15000 Loss: 186.8213 lr: 0.0153\n",
            "Step: 15500 Loss: 190.8038 lr: 0.0152\n",
            "Step: 16000 Loss: 170.4494 lr: 0.0150\n",
            "Step: 16500 Loss: 192.8111 lr: 0.0149\n",
            "Step: 17000 Loss: 184.9003 lr: 0.0147\n",
            "Step: 17500 Loss: 185.6305 lr: 0.0146\n",
            "Step: 18000 Loss: 185.8654 lr: 0.0144\n",
            "Step: 18500 Loss: 189.6958 lr: 0.0143\n",
            "Step: 19000 Loss: 173.8700 lr: 0.0141\n",
            "Step: 19500 Loss: 189.8594 lr: 0.0139\n",
            "Step: 20000 Loss: 192.2000 lr: 0.0138\n",
            "Step: 20500 Loss: 198.4497 lr: 0.0136\n",
            "Step: 21000 Loss: 187.7875 lr: 0.0135\n",
            "Epoch 0 Total Mean Loss : 202.9676\n",
            "*****Epoch 0 Train Finished*****\n",
            "\n",
            "*****Epoch 0 Saving Embedding...*****\n",
            "*****Epoch 0 Embedding Saved at ./word2vec_wiki/w2v_0.txt*****\n",
            "\n",
            "*****Epoch 1 Train Start*****\n",
            "*****Epoch 1 Total Step 21482*****\n",
            "Step: 500 Loss: 193.4911 lr: 0.0132\n",
            "Step: 1000 Loss: 187.1919 lr: 0.0130\n",
            "Step: 1500 Loss: 149.1231 lr: 0.0129\n",
            "Step: 2000 Loss: 173.5729 lr: 0.0127\n",
            "Step: 2500 Loss: 111.5738 lr: 0.0126\n",
            "Step: 3000 Loss: 106.5843 lr: 0.0124\n",
            "Step: 3500 Loss: 186.4074 lr: 0.0122\n",
            "Step: 4000 Loss: 194.9714 lr: 0.0121\n",
            "Step: 4500 Loss: 195.0088 lr: 0.0119\n",
            "Step: 5000 Loss: 188.9668 lr: 0.0118\n",
            "Step: 5500 Loss: 178.8818 lr: 0.0116\n",
            "Step: 6000 Loss: 191.7482 lr: 0.0115\n",
            "Step: 6500 Loss: 197.7579 lr: 0.0113\n",
            "Step: 7000 Loss: 168.4209 lr: 0.0112\n",
            "Step: 7500 Loss: 168.6567 lr: 0.0110\n",
            "Step: 8000 Loss: 181.6353 lr: 0.0109\n",
            "Step: 8500 Loss: 196.0211 lr: 0.0107\n",
            "Step: 9000 Loss: 191.4741 lr: 0.0105\n",
            "Step: 9500 Loss: 197.6260 lr: 0.0104\n",
            "Step: 10000 Loss: 185.5579 lr: 0.0102\n",
            "Step: 10500 Loss: 182.2152 lr: 0.0101\n",
            "Step: 11000 Loss: 189.9476 lr: 0.0099\n",
            "Step: 11500 Loss: 189.7585 lr: 0.0098\n",
            "Step: 12000 Loss: 184.6092 lr: 0.0096\n",
            "Step: 12500 Loss: 195.0764 lr: 0.0095\n",
            "Step: 13000 Loss: 191.4367 lr: 0.0093\n",
            "Step: 13500 Loss: 192.0262 lr: 0.0091\n",
            "Step: 14000 Loss: 183.4224 lr: 0.0090\n",
            "Step: 14500 Loss: 187.3478 lr: 0.0088\n",
            "Step: 15000 Loss: 187.1950 lr: 0.0087\n",
            "Step: 15500 Loss: 192.7276 lr: 0.0085\n",
            "Step: 16000 Loss: 171.3071 lr: 0.0084\n",
            "Step: 16500 Loss: 192.0430 lr: 0.0082\n",
            "Step: 17000 Loss: 187.0110 lr: 0.0081\n",
            "Step: 17500 Loss: 188.1948 lr: 0.0079\n",
            "Step: 18000 Loss: 186.4071 lr: 0.0077\n",
            "Step: 18500 Loss: 191.9085 lr: 0.0076\n",
            "Step: 19000 Loss: 178.3674 lr: 0.0074\n",
            "Step: 19500 Loss: 189.2011 lr: 0.0073\n",
            "Step: 20000 Loss: 193.7389 lr: 0.0071\n",
            "Step: 20500 Loss: 195.9125 lr: 0.0070\n",
            "Step: 21000 Loss: 189.5715 lr: 0.0068\n",
            "Epoch 1 Total Mean Loss : 182.6888\n",
            "*****Epoch 1 Train Finished*****\n",
            "\n",
            "*****Epoch 1 Saving Embedding...*****\n",
            "*****Epoch 1 Embedding Saved at ./word2vec_wiki/w2v_1.txt*****\n",
            "\n",
            "*****Epoch 2 Train Start*****\n",
            "*****Epoch 2 Total Step 21482*****\n",
            "Step: 500 Loss: 193.3081 lr: 0.0065\n",
            "Step: 1000 Loss: 187.5862 lr: 0.0064\n",
            "Step: 1500 Loss: 149.0169 lr: 0.0062\n",
            "Step: 2000 Loss: 181.7055 lr: 0.0060\n",
            "Step: 2500 Loss: 125.2737 lr: 0.0059\n",
            "Step: 3000 Loss: 120.3993 lr: 0.0057\n",
            "Step: 3500 Loss: 187.0557 lr: 0.0056\n",
            "Step: 4000 Loss: 199.2047 lr: 0.0054\n",
            "Step: 4500 Loss: 198.6556 lr: 0.0053\n",
            "Step: 5000 Loss: 194.3407 lr: 0.0051\n",
            "Step: 5500 Loss: 186.2842 lr: 0.0050\n",
            "Step: 6000 Loss: 195.1073 lr: 0.0048\n",
            "Step: 6500 Loss: 203.8314 lr: 0.0046\n",
            "Step: 7000 Loss: 183.8470 lr: 0.0045\n",
            "Step: 7500 Loss: 182.0090 lr: 0.0043\n",
            "Step: 8000 Loss: 188.1357 lr: 0.0042\n",
            "Step: 8500 Loss: 198.4584 lr: 0.0040\n",
            "Step: 9000 Loss: 201.3073 lr: 0.0039\n",
            "Step: 9500 Loss: 198.3313 lr: 0.0037\n",
            "Step: 10000 Loss: 193.9402 lr: 0.0036\n",
            "Step: 10500 Loss: 187.6336 lr: 0.0034\n",
            "Step: 11000 Loss: 194.5650 lr: 0.0033\n",
            "Step: 11500 Loss: 192.8356 lr: 0.0031\n",
            "Step: 12000 Loss: 188.5741 lr: 0.0029\n",
            "Step: 12500 Loss: 197.9906 lr: 0.0028\n",
            "Step: 13000 Loss: 193.8125 lr: 0.0026\n",
            "Step: 13500 Loss: 198.6066 lr: 0.0025\n",
            "Step: 14000 Loss: 189.4090 lr: 0.0023\n",
            "Step: 14500 Loss: 190.9812 lr: 0.0022\n",
            "Step: 15000 Loss: 194.2522 lr: 0.0020\n",
            "Step: 15500 Loss: 203.1802 lr: 0.0019\n",
            "Step: 16000 Loss: 184.4098 lr: 0.0017\n",
            "Step: 16500 Loss: 194.7722 lr: 0.0015\n",
            "Step: 17000 Loss: 197.5684 lr: 0.0014\n",
            "Step: 17500 Loss: 199.2104 lr: 0.0012\n",
            "Step: 18000 Loss: 193.9008 lr: 0.0011\n",
            "Step: 18500 Loss: 201.4198 lr: 0.0009\n",
            "Step: 19000 Loss: 192.8857 lr: 0.0008\n",
            "Step: 19500 Loss: 193.0344 lr: 0.0006\n",
            "Step: 20000 Loss: 203.3453 lr: 0.0005\n",
            "Step: 20500 Loss: 197.2147 lr: 0.0003\n",
            "Step: 21000 Loss: 195.3592 lr: 0.0001\n",
            "Epoch 2 Total Mean Loss : 189.6529\n",
            "*****Epoch 2 Train Finished*****\n",
            "\n",
            "*****Epoch 2 Saving Embedding...*****\n",
            "*****Epoch 2 Embedding Saved at ./word2vec_wiki/w2v_2.txt*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "w2v.train(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTIm4vJ4WSp"
      },
      "source": [
        "### 유사한 단어 확인\n",
        "- 사전에 존재하는 단어들과 유사한 단어를 검색해보자. Gensim 패키지는 유사 단어 외에도 단어간의 유사도를 계산하는 여러 함수를 제공한다. 실험을 통해 word2vec의 한계점을 발견했다면 아래에 markdown으로 작성해보자. \n",
        "- [Gensim 패키지 document](https://radimrehurek.com/gensim/models/keyedvectors.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 풀이"
      ],
      "metadata": {
        "id": "O_CXshHQx6iO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:47:59.605389Z",
          "start_time": "2022-02-19T14:47:59.368925Z"
        },
        "id": "AKpBuVlP4WSp"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:06.590460Z",
          "start_time": "2022-02-19T14:49:05.174241Z"
        },
        "id": "AWTCodimsAq8"
      },
      "outputs": [],
      "source": [
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('./word2vec_wiki/w2v_2.txt', binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:11.324372Z",
          "start_time": "2022-02-19T14:49:11.315429Z"
        },
        "id": "MLMh_evrsAq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55512793-3adf-46b9-cd86-f640f3ae25ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('너지', 0.9981141686439514),\n",
              " ('었', 0.9978345632553101),\n",
              " ('일본', 0.99715256690979),\n",
              " ('배구', 0.9971135258674622),\n",
              " ('버전', 0.9969197511672974),\n",
              " ('비아', 0.9968982934951782),\n",
              " ('게임', 0.9968740344047546),\n",
              " ('나미', 0.9968181848526001),\n",
              " ('기라티나', 0.9966198801994324),\n",
              " ('는', 0.9966039657592773)]"
            ]
          },
          "metadata": {},
          "execution_count": 419
        }
      ],
      "source": [
        "word_vectors.most_similar(positive=['여자', '준정'], negative=['화랑'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word2vec의 한계점은?\n",
        "- vocab 사이즈가 커야지 많은 관계를 표현할 수 있다. vocab 사이즈가 작은 경우 완전 생뚱맞은 관계를 입력하면 이상한 값이 나온다.\n",
        "\n",
        "- vocabulary의 사이즈가 크고 vocab 외의 단어를 표현하지 못한다. 데이터 전체에 대한 정보를 담기 어렵다. 데이터 전체에 대한 빈도를 반영이 되지 않는다."
      ],
      "metadata": {
        "id": "X8lc8NQe4cT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모범 답안"
      ],
      "metadata": {
        "id": "eJAjoJKHx4Eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:47:59.605389Z",
          "start_time": "2022-02-19T14:47:59.368925Z"
        },
        "id": "mFAm0Txox5oO"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:06.590460Z",
          "start_time": "2022-02-19T14:49:05.174241Z"
        },
        "id": "_7WPtss_CmWM"
      },
      "outputs": [],
      "source": [
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('./word2vec_wiki/w2v_1.txt', binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:55:31.040003Z",
          "start_time": "2022-02-19T14:55:31.034836Z"
        },
        "id": "DVeJhIthCmWM",
        "outputId": "75164bbc-5617-4cf0-f979-bfdae550fcc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('주한', 0.9916805624961853),\n",
              " ('광역시', 0.991572380065918),\n",
              " ('육군사관학교', 0.9912100434303284),\n",
              " ('보병', 0.9907797574996948),\n",
              " ('방송국', 0.9904221892356873),\n",
              " ('박물관', 0.9901329278945923),\n",
              " ('한양', 0.9900871515274048),\n",
              " ('알아인', 0.9899305105209351),\n",
              " ('당원', 0.98966383934021),\n",
              " ('개신교도', 0.9896210432052612)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors.most_similar(positive=['대통령'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:11.324372Z",
          "start_time": "2022-02-19T14:49:11.315429Z"
        },
        "id": "cLFVRhPjCmWM",
        "outputId": "23df1bc2-1e59-49d2-fb83-8bca0c8215ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('막달레나', 0.9994158744812012),\n",
              " ('명탐정', 0.9993422627449036),\n",
              " ('재상', 0.9993184208869934),\n",
              " ('뉴캐슬', 0.9992764592170715),\n",
              " ('린든', 0.9992668628692627),\n",
              " ('줄넘기', 0.9992555975914001),\n",
              " ('공예', 0.9992364048957825),\n",
              " ('워즈', 0.9992086887359619),\n",
              " ('찹', 0.9991920590400696),\n",
              " ('배기', 0.9991424083709717)]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors.most_similar(positive=['코난'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week3_1_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}