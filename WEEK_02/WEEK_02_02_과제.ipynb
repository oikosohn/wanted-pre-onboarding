{"cells":[{"cell_type":"markdown","metadata":{"id":"592U6lXs3d2t"},"source":["# Week2_2 Assignment\n","\n","## [BASIC](#Basic) \n","- \"네이버 영화 감성 분류\" 데이터를 불러와 `pandas` 라이브러리를 사용해 **전처리** 할 수 있다.\n","- 적은 데이터로도 높은 성능을 내기 위해, pre-trained `BERT` 모델 위에 1개의 hidden layer를 쌓아 **fine-tuning**할 수 있다.\n","\n","## [CHALLENGE](#Challenge)\n","- 토큰화된 학습 데이터를 배치 단위로 갖는 **traindata iterator**를 구현할 수 있다. \n","\n","## [ADVANCED](#Advanced)\n","- **loss와 optimizer 함수**를 사용할 수 있다. \n","- traindata iterator를 for loop 돌며 **fine-tuning** 할 수 있다.\n","- fine-tuning의 2가지 방법론을 비교할 수 있다. \n","  - BERT 파라미터를 **freeze** 한 채 fine-tuning (Vision에서 주로 사용하는 방법론)\n","  - BERT 파라미터를 **unfreeze** 한 채 fine-tuning (NLP에서 주로 사용하는 방법론)\n","\n","\n","### Reference\n","- [huggingface 한국어 오픈소스 모델](https://huggingface.co/models?language=ko&sort=downloads&search=bert)\n","- [transformer BertForSequenceClassification 소스 코드](https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/bert/modeling_bert.py#L1501)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KSX-wQA1RD1h","executionInfo":{"status":"ok","timestamp":1647004341733,"user_tz":-540,"elapsed":6889,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["import os\n","import sys\n","import pandas as pd\n","import numpy as np \n","import torch\n","import random"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4Reyt-HvLnJv","executionInfo":{"status":"ok","timestamp":1647004341736,"user_tz":-540,"elapsed":25,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# seed\n","seed = 7777\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gUR6vb3L3d2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004341737,"user_tz":-540,"elapsed":22,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"422c5ab8-0ddb-4c46-fbab-bdd09fa6257c"},"outputs":[{"output_type":"stream","name":"stdout","text":["# available GPUs : 1\n","GPU name : Tesla K80\n","cuda\n"]}],"source":["# device type\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print(f\"# available GPUs : {torch.cuda.device_count()}\")\n","  print(f\"GPU name : {torch.cuda.get_device_name()}\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"c93M8XmjLnJw"},"source":["## Basic"]},{"cell_type":"markdown","metadata":{"id":"0REKl4EvT9G1"},"source":["### 데이터 다운로드 및 DataFrame 형태로 불러오기\n","- 내 구글 드라이브에 데이터를 다운받은 후 코랩에 드라이브를 마운트하면 데이터를 영구적으로 사용할 수 있음.\n","- [네이버영화감성분류](https://github.com/e9t/nsmc)\n","  - trainset: 150,000 \n","  - testset: 50,000 "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lEWUggR1R9rS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004358893,"user_tz":-540,"elapsed":17173,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"636415cd-aa69-4d93-ebb3-c0c67b0ebb32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"rov1s8IxSLqy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004358893,"user_tz":-540,"elapsed":15,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"74ebf6e1-11ac-4ea0-8fcb-dfb3b0a01b26"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/원티드AIML\n"]}],"source":["cd \"/content/gdrive/MyDrive/원티드AIML\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OjPGnbEjVYmj","executionInfo":{"status":"ok","timestamp":1647004358895,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# 데이터 다운로드\n","# !git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SueG9v14YbgF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004358896,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"dabac917-8631-48dd-9577-74595479906a"},"outputs":[{"output_type":"stream","name":"stdout","text":["My current directory : /content/gdrive/MyDrive/원티드AIML\n"]}],"source":["_CUR_DIR = os.path.abspath(os.curdir)\n","print(f\"My current directory : {_CUR_DIR}\")\n","_DATA_DIR = os.path.join(_CUR_DIR, \"nsmc\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9J6KQ8dzaHBi","executionInfo":{"status":"ok","timestamp":1647004371033,"user_tz":-540,"elapsed":1505,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# nsmc/ratings_train.txt를 DataFrame 형태로 불러오기\n","df = pd.read_csv(_DATA_DIR+'/ratings_train.txt', sep='\\t')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"3cUsoBEPahlo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004372455,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"fa3db2fd-fe79-4362-b69f-d6108667425b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150000, 3)"]},"metadata":{},"execution_count":11}],"source":["# 데이터 크기 확인\n","df.shape"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ic3k9CORaXzM","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1647004372828,"user_tz":-540,"elapsed":9,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"c112ecd1-a76d-40c5-f23c-fe9db40eb5b8"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-cb77ecdf-9d02-4b6c-ad00-02f5ba6c7838\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb77ecdf-9d02-4b6c-ad00-02f5ba6c7838')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cb77ecdf-9d02-4b6c-ad00-02f5ba6c7838 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cb77ecdf-9d02-4b6c-ad00-02f5ba6c7838');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{},"execution_count":12}],"source":["# 데이터 일부 확인\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"JA1F0tHWLnJz"},"source":["### 데이터 결측치 제거 및 데이터 수 줄이기 \n","- 학습 데이터 수는 150,000개로 매우 많은 양이다. 하지만 우리가 실생활에서 마주할 데이터는 이렇게 많지 않다. 이 때 유용하게 사용되는 것이 **fine-tuning** 학습 방법이다.   \n","- Fine-tuning은 단어의 의미를 이미 충분히 학습한 모델 (여기서는 **BERT**)을 가져와 그 위에 추가적인 Nueral Network 레이어를 쌓은 후 학습하는 방법론이다. 이미 BERT가 단어의 의미를 충분히 학습했기 때문에 **적은 데이터**로 학습해도 우수한 성능을 낼 수 있다는 장점이 있다. \n","- **데이터의 label의 비율이 5:5를 유지하면서** 학습 데이터 수를 150,000개에서 1,000개로 줄이\b는 함수 `label_evenly_balanced_dataset_sampler`를 구현하라.\n","  - 함수 정의 \n","    - 입력 매개변수\n","      - df : DataFrame\n","      - n_sample : df에서 샘플링할 row의 개수 (여기서는 1000개로 정의한다)\n","    - 조건\n","      - label의 비율이 5:5를 유지할 수 있도록 샘플링한다.\n","    - 반환값\n","      - row의 개수가 1000개인 dataframe"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Lh9BSiSeMms7","executionInfo":{"status":"ok","timestamp":1647004373199,"user_tz":-540,"elapsed":45,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# df에서 결측치 (na 값) 제거\n","\n","df = df.dropna(how = 'any')"]},{"cell_type":"markdown","source":["결측치를 제거한 후 라벨 분포를 보면 부정은 74825개, 긍정은 75170개의 리뷰가 있다."],"metadata":{"id":"yOGrTWIjHD3K"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"ommF5KH4akCJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004373200,"user_tz":-540,"elapsed":43,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"d159a6f8-75b5-45a2-e420-28a8fc7cfac6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    75170\n","1    74825\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":14}],"source":["# label별 데이터 수 확인\n","# pandas의 value_counts 함수 활용\n","# 0 -> 부정 1 -> 긍정\n","\n","df['label'].value_counts()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_ii06wCsc107","executionInfo":{"status":"ok","timestamp":1647004373655,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# 학습 데이터 샘플 개수 설정\n","\n","n_sample = 1000"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Hrkhl69Dc-kr","executionInfo":{"status":"ok","timestamp":1647004374031,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# 샘플링 함수 구현\n","# random 모듈에서 제공되는 함수 활용\n","# input: 학습 데이터 샘플 개수\n","# output: 샘플링 데이터\n","\n","\n","def label_evenly_balanced_dataset_sampler(df, sample_size):\n","  \"\"\"\n","  데이터 프레임의을 sample_size만큼 임의 추출해 새로운 데이터 프레임을 생성.\n","  이 때, \"label\"열의 값들이 동일한 비율을 갖도록(5:5) 할 것.\n","  \"\"\"\n","  zero = random.sample(df[df['label'] == 0].index.tolist(), n_sample//2)\n","  one = random.sample(df[df['label'] == 1].index.tolist(), n_sample//2)\n","  sample = df.loc[zero+one]\n","\n","  return sample\n","\n","sample_df = label_evenly_balanced_dataset_sampler(df, n_sample)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"hXLT6tAdaA34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004375208,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"9aa93471-f9f2-4f88-98c6-403d2e1d26bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    500\n","1    500\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":17}],"source":["# 검증\n","\n","sample_df.label.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"cLNUjgawLnJ1"},"source":["### CustomClassifier 클래스 구현\n","<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_bertclf.png?raw=true\" width=400>\n","\n","- 그림과 같이 사전 학습(pre-trained)된 `BERT` 모델을 불러와 그 위에 **1 hidden layer**와 **binary classifier layer**를 쌓아 fine-tunning 모델을 생성할 것이다.    \n","---\n","- hidden layer 1개와 output layer(binary classifier layer)를 갖는 `CustomClassifier` 클래스를 구현하라.\n","- 클래스 정의\n","  - 생성자 입력 매개변수\n","    - `hidden_size` : BERT의 embedding size\n","    - `n_label` : class(label) 개수\n","  - 생성자에서 생성할 변수\n","    - `bert` : BERT 모델 인스턴스 \n","    - `classifier` : 1 hidden layer + relu +  dropout + classifier layer를 stack한 `nn.Sequential` 모델\n","      - 첫번재 히든 레이어 (첫번째 `nn.Linear`)\n","        - input: BERT의 마지막 layer의 1번재 token ([CLS] 토큰) (shape: `hidden_size`)\n","        - output: (shape: `linear_layer_hidden_size`)\n","      - 아웃풋 레이어 (두번째 `nn.Linear`)\n","        - input: 첫번째 히든 레이어의 아웃풋 (shape: `linear_layer_hidden_size`)\n","        - output: target/label의 개수 (shape:2)\n","  - 메소드\n","    - `forward()`\n","      - BERT output에서 마지막 레이어의 첫번째 토큰 ('[CLS]')의 embedding을 가져와 `self.classifier`에 입력해 아웃풋으로 logits를 출력함.\n","  - 주의 사항\n","    - `CustomClassifier` 클래스는 부모 클래스로 `nn.Module`을 상속 받는다.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"U0WbqVv62Zvy","executionInfo":{"status":"ok","timestamp":1647004375211,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Im98H4-U1eQQ","executionInfo":{"status":"ok","timestamp":1647004617207,"user_tz":-540,"elapsed":302,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# classifier 구현\n","class CustomClassifier(nn.Module):\n","\n","  def __init__(self, hidden_size: int, n_label: int):\n","    super(CustomClassifier, self).__init__()\n","\n","    self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n","\n","    dropout_rate = 0.1\n","    linear_layer_hidden_size = 32\n","\n","    self.classifier = nn.Sequential(nn.Linear(hidden_size, linear_layer_hidden_size),\n","                                    nn.ReLU(), \n","                                    nn.Dropout(dropout_rate),\n","                                    nn.Linear(linear_layer_hidden_size, n_label)) # torch.nn에서 제공되는 Sequential, Linear, ReLU, Dropout 함수 활용\n","\n","  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n","    outputs = self.bert(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        token_type_ids=token_type_ids,\n","    )\n","    print('outputs')\n","    print(outputs)\n","\n","    # pooler_output\n","    # pooler_output : the last layer hidden-state of the first token of the sequence (classification token) further processed by a Linear layer and a Tanh activation function.\n","    cls_token_last_hidden_states = outputs['pooler_output'] \n","    \n","    print('pooler_output')\n","    print(cls_token_last_hidden_states)\n","\n","    # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n","    # 마지막 layer의 첫 번째 토큰 (\"[CLS]\") 벡터를 가져오기, shape = (1, hidden_size)\n","    last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n","    cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n","\n","    print('answer')\n","    print(cls_token_last_hidden_states)\n","\n","    logits = self.classifier(cls_token_last_hidden_states)\n","\n","    return logits"]},{"cell_type":"markdown","metadata":{"id":"9x7PU1t1LnJ1"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"YXesCG5TLnJ1"},"source":["### 학습 데이터를 배치 단위로 저장하는 이터레이터 함수 `data_iterator` 구현\n","- 데이터 프레임을 입력 받아 text를 \b토큰 id로 변환하고 label은 텐서로 변환해 배치만큼 잘라 (input, \btarget) 튜플 형태의 이터레이터를 생성하는 `data_iterator` 함수를 구현하라.\n","- 함수 정의 \n","  - 입력 매개변수\n","    - `input_column` : text 데이터 column 명\n","    - `target_column` : label 데이터 column 명\n","    -  `batch_size` : 배치 사이즈\n","  - 조건\n","    - 함수는 다음을 수행해야 함 \n","      - 데이터 프레임 랜덤 셔플링\n","      - `tokenizer_bert`로 text를 token_id로 변환 + 텐서화 \n","      - target(label)을 텐서화\n","  - 반환값 \n","    - (input, target) 튜플 형태의 이터레이터를 반환"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"q-tJERGI4Fzk","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004432474,"user_tz":-540,"elapsed":10427,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"a7397643-9bae-4c41-d2e8-9bd4d221504f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.8 MB 5.7 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 43.8 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 41.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 36.4 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n","\u001b[?25h"]}],"source":["!pip install transformers -qq"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"JlcYCOyW3d2t","executionInfo":{"status":"ok","timestamp":1647004432948,"user_tz":-540,"elapsed":486,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["from transformers import BertTokenizer, BertModel"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"C_U_c-Mf3d2t","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["c4d2e96f7af5441b9ab19a3c2aa391a6","bfb15349bdd64ce0b607415cd099ede0","4d56797b47414b37873f15dc66fd2a63","b1fa9519123546daad32dfd4f458182a","bed2fb92934d437bb1f6bb7366c10ee7","50abb0bb2cb949df8228ea0d8e180b3c","c30f5691f3c844bcb60788db49ecd536","c29f6203718b4a8ab5cd04cada9ca3e3","bbda07457c86491b8c04392d346ce0f2","f14ffbb2aa32480ea5a8a75677e2e535","09c4a0e102e2433e958fef48c82a7d32","ddc663740f78434c9ffbff23c15196cf","11dac798102d48e8a44d95275d208042","49f2460afd644f44b7bc20a891e9b3ac","561bce0e4a5e4dd0ac2d213f85df8f48","da1e71ffa2d3473cb035171868e8341f","b0dd5361f6f743c187c03103863daf04","99dc5bd2096547a3a459411dd305db2a","026c6eebe1304d399f22fb136562c000","ed110e59e7cf414d864ee67f2c1a5c51","10bf8bc16c9e495cbac8e539277d5ca3","68aa72069358477b9f9f16a151768236","5d4777f98dd242abb787823401f64f10","d1b097e4c38146a7826aaf702a8a6b25","3e1f721f1d584479aa19f87a7909f6be","3657867be1d349a894fb953995b11847","13168d576eeb4c5b9bd8f0e380c22044","366880aa3d294098bba52b87b64ba9f7","83b870e637434455a8ed99771d0f4e6c","8f10a37db47a4d98a982b433d7cee763","7e43486a0dca46d5a77af1c6b3c4deac","15f39b52556742b5a1e9775de27cbb9e","888990740d674c33b478f0a672ca11bc","7ffa3a3414cc4ac9ba28871830f95a0c","e6d641f6f95f4dcba65f1886180a772a","a2412c9a604f4ae496160019c3529535","53f49a479263432aa49011891ea10f80","7314e3fb1bd94a668744ac8236c0f6c9","b525c0b0a6604f5c8aac30cdd07ed835","4762ca351ca9402888aa9ea37d37af3b","727425711bc64dd6adfd9ff3449fe9ad","393d0a099629467f9c799d8743060c25","f4f18b1275e6480b9c43401cd758a007","d82c545da9f1475783e7d6ebe9ca77c2"]},"executionInfo":{"status":"ok","timestamp":1647004434459,"user_tz":-540,"elapsed":1518,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"66b2219b-472a-4f1d-9ac4-045bb1cbb8cc"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4d2e96f7af5441b9ab19a3c2aa391a6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddc663740f78434c9ffbff23c15196cf","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d4777f98dd242abb787823401f64f10","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ffa3a3414cc4ac9ba28871830f95a0c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{}}],"source":["tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\") # lower-cased version"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"p2VnIY-ALnJ2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004434460,"user_tz":-540,"elapsed":14,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"0e119237-5b73-4f02-a2be-8a1be98951c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence: 나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.\n","\n","Tokenized Sentence: {'input_ids': tensor([[    2,   717,  4647,   831,  2604,  2069,  4869,  2205, 18246,  3926,\n","          2088,  1170, 13964,  9379,   831,  2604,  2052,  9822, 23677,    18,\n","            18,    18,   831,  2604,  2052,  3760,  5429,  2507,  2053,    18,\n","             3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1]])}\n"]}],"source":["# 토크나이징 예시 (1개의 문장)\n","\n","# 1. string type의 문장을 가져옴\n","ex_sent = sample_df.document.iloc[0]\n","print(f\"Original Sentence: {ex_sent}\\n\")\n","\n","# 2. 문장을 토크나이즈 함. 이 때, 특수 토큰 (\"[CLS]\", \"[SPE]\")을 자동으로 추가하고 pytorch의 tensor형태로 변환해 반환함\n","tensor_sent = tokenizer_bert(\n","    ex_sent,\n","    add_special_tokens=True, # 문장의 앞에 문장 시작을 알리는 \"[CLS]\"토큰, 문장의 끝에 문장 끝을 알리는 \"[SPE]\"토큰을 자동으로 추가\n","    return_tensors='pt' # pytorch tensor로 반환할 것\n",")\n","print(f\"Tokenized Sentence: {tensor_sent}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"rtXP_wRFLnJ2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004434921,"user_tz":-540,"elapsed":473,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"65580da3-f774-4172-c079-d334ec6a41b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence 1: 나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.\n","Original Sentence 2: 현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...\n","\n","Tokenized Sentence list: {'input_ids': tensor([[    2,   717,  4647,   831,  2604,  2069,  4869,  2205, 18246,  3926,\n","          2088,  1170, 13964,  9379,   831,  2604,  2052,  9822, 23677,    18,\n","            18,    18,   831,  2604,  2052,  3760,  5429,  2507,  2053,    18,\n","             3],\n","        [    2,  1919,  2562,  2052,  7750,  2474,  2052,  2359,  6076,  1560,\n","          2886,  2918, 13964,    18,    18,  6354, 22023,  2119,  1556,  7436,\n","          2205,  2318,    18,    18,    18,     3,     0,     0,     0,     0,\n","             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 0, 0, 0, 0, 0]])}\n"]}],"source":["# 토크나이징 예시 (2개의 문장)\n","\n","# 1. 2개의 문장을 가진 list 생성\n","ex_sent_list = list(sample_df.document.iloc[:2].values)\n","for i, sent in enumerate(ex_sent_list):\n","    print(f\"Original Sentence {i+1}: {sent}\")\n","\n","# 2. 문장 리스트를 토크나이즈 함. 이 때, 리스트 내 문장들의 토큰 길이가 동일할 수 있도록 가장 긴 문장을 기준으로 부족한 위치에 \"[PAD]\" 토큰을 추가\n","tensor_sent_list = tokenizer_bert(\n","    ex_sent_list,\n","    add_special_tokens=True,\n","    return_tensors='pt',\n","    padding=\"longest\" # 가장 긴 문장을 기준으로 token개수를 맞춤. 모자란 토큰 위치는 \"[PAD]\" 토큰을 추가\n",")\n","\n","print(f\"\\nTokenized Sentence list: {tensor_sent_list}\")\n","\n","# 토크나이즈 된 두 문장의 길이가 동일함을 검증\n","assert tensor_sent_list['input_ids'][0].shape == tensor_sent_list['input_ids'][1].shape "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"tR22xs-xf1QH","executionInfo":{"status":"ok","timestamp":1647004434922,"user_tz":-540,"elapsed":16,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["def data_iterator(df, input_column, target_column, batch_size):\n","  \"\"\"\n","  데이터 프레임을 셔플한 후 \n","  데이터 프레임의 input_column을 batch_size만큼 잘라 토크나이즈 + 텐서화하고, target_column을 batch_size만큼 잘라 텐서화 하여\n","  (input, output) 튜플 형태의 이터레이터를 생성\n","  \"\"\"\n","\n","  global tokenizer_bert\n","\n","  # 1. 데이터 프레임 셔플\n","  #    pandas의 sample 함수 사용\n","  df = df.sample(frac=1, random_state = seed).reset_index(drop=True)\n","  # 2. 이터레이터 생성\n","  for idx in range(0, df.shape[0], batch_size):\n","    batch_df = df[idx:idx+batch_size] # batch_size만큼 데이터 추출\n","    tensorized_input = tokenizer_bert(list(batch_df[input_column]), # df의 text를 토크나이징 + token id로 변환 + 텐서화 (df의 input_column 사용)\n","                                      add_special_tokens=True,\n","                                      return_tensors='pt',\n","                                      padding=\"longest\")\n","    # tensorized_input = torch.from_numpy(tensorized_input.values.to_numpy())\n","    \n","    tensorized_target = torch.tensor(list(batch_df[target_column])) # target(label)을 텐서화 (df의 target_column 사용)\n","\n","    # print(type(tensorized_input))\n","    \n","    yield tensorized_input, tensorized_target # 튜플 형태로 yield"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"zTlAV0hqILmc","executionInfo":{"status":"ok","timestamp":1647004434923,"user_tz":-540,"elapsed":13,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["batch_size=32\n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"P9VNAMchf1QI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004434928,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"f1362af8-e04e-4a1c-fc4c-880bdde56fa8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'input_ids': tensor([[    2, 27740,  2899,  ...,     0,     0,     0],\n","         [    2, 24935, 29422,  ...,     0,     0,     0],\n","         [    2,  4380,  3785,  ...,     0,     0,     0],\n","         ...,\n","         [    2,  1453,    16,  ...,     0,     0,     0],\n","         [    2,  3771,  4229,  ...,     0,     0,     0],\n","         [    2,  3833, 15351,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]])},\n"," tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n","         1, 0, 1, 0, 1, 1, 0, 0]))"]},"metadata":{},"execution_count":28}],"source":["next(train_iterator)"]},{"cell_type":"markdown","metadata":{"id":"Cqnp2Q6ZLnJ2"},"source":["## Advanced"]},{"cell_type":"markdown","metadata":{"id":"cQVTqAUxLnJ2"},"source":["### `data_iterator` 함수로 생성한 이터레이터를 for loop 돌면서 배치 단위의 데이터를 모델에 학습하는 `train()` 함수 구현\n","- 함수 정의\n","  - 입력 매개변수\n","    - `model` : BERT + 1 hidden layer classifier 모델\n","    - `data_iterator` : train data iterator\n","- Reference\n","  - [Loss: CrossEntropyLoss official document](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n","  - [Optimizer: AdamW official document](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)\n","\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"-sE7xjYcRD1p","executionInfo":{"status":"ok","timestamp":1647004434930,"user_tz":-540,"elapsed":15,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["from torch.optim import AdamW\n","from torch.nn import CrossEntropyLoss\n","from numpy.core.fromnumeric import nonzero"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"7Er1qKtsf1QJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004630540,"user_tz":-540,"elapsed":2211,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"203609b7-1d88-401e-a84a-32856640bb04"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# 모델 클래스 정의\n","model = CustomClassifier(hidden_size=768, n_label=2)\n","\n","batch_size = 32\n","\n","# 데이터 이터레이터 정의 \n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n","\n","# 로스 및 옵티마이저\n","loss_fct = CrossEntropyLoss()\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=2e-5,\n","    eps=1e-8\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ZvY5rxDKHQAp","executionInfo":{"status":"ok","timestamp":1647004630541,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["def train(model, data_iterator):\n","\n","  global loss_fct # 위에서 정의한 loss 함수\n","\n","  # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n","  total_loss, batch_loss, batch_count = 0,0,0\n","  \n","  # model을 train 모드로 설정 & device 할당\n","  model.train()\n","  model.to(device)\n","\n","## 파라미터 freeze 됐는지 확인\n","#   for name, param in model.named_parameters():\n","#       if param.requires_grad == True:\n","#           print(name)\n","\n","  # data iterator를 돌면서 하나씩 학습\n","  for step, batch in enumerate(data_iterator):\n","    batch_count+=1\n","    \n","    # tensor 연산 전, 각 tensor에 device 할당\n","    batch = tuple(item.to(device) for item in batch)\n","    \n","    batch_input, batch_label = batch\n","    \n","    # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n","    model.zero_grad()\n","    \n","    # forward\n","    logits = model(input_ids = batch_input['input_ids'],\n","                   attention_mask = batch_input['attention_mask'],\n","                   token_type_ids = batch_input['token_type_ids'])\n","    # loss\n","    loss = loss_fct(logits, batch_label)\n","    batch_loss += loss.item()\n","    total_loss += loss.item()\n","    \n","    # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n","    loss.backward()\n","    \n","    # optimizer 업데이트\n","    optimizer.step()\n","      \n","    # 배치 10개씩 처리할 때마다 평균 loss를 출력\n","    if (step % 10 == 0 and step != 0):\n","      print(f\"Step : {step}, Avg Loss : {batch_loss / batch_count:.4f}\")\n","      \n","      # 변수 초기화 \n","      batch_loss, batch_count = 0,0\n","  \n","  print(f\"Mean Loss : {total_loss/(step+1):.4f}\")\n","  print(\"Train Finished\")"]},{"cell_type":"markdown","metadata":{"id":"OEYo8z9RLnJ2"},"source":["### 지금까지 구현한 함수와 클래스를 모두 불러와 `train()` 함수를 실행하자\n","- fine-tuning 모델 클래스 (`CustomClassifier`)\n","    - hidden_size = 768\n","    - n_label = 2\n","- 데이터 이터레이터 함수 (`data_iterator`)\n","    - batch_size = 32\n","- loss \n","    - `CrossEntropyLoss()`\n","- optimizer\n","    - optimizer는 loss(오차)를 상쇄하기 위해 파라미터를 업데이트 하는 과정\n","    - `optimizer.step()` 시 파라미터가 업데이트 됨 \n","    - lr = 2e-5\n","- Reference\n","  - [Optimizer 종류 설명 한국어 블로그 ](https://ganghee-lee.tistory.com/24)\n","    "]},{"cell_type":"code","execution_count":36,"metadata":{"id":"uCODIxCfFEDP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647004665362,"user_tz":-540,"elapsed":32565,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"fd0688b1-f9e6-4cee-8bf2-51cf90ceff8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2405, -2.0301, -0.2789,  ...,  1.6514, -1.0523,  0.7214],\n","         [ 1.3040, -0.3682,  1.0060,  ...,  0.1948,  0.5877,  0.0244],\n","         [-1.0414,  0.0187, -1.0248,  ...,  0.4635, -0.7240, -1.0967],\n","         ...,\n","         [ 0.6508,  0.0977, -0.1423,  ...,  1.3135,  0.2194,  0.9910],\n","         [ 1.4506,  0.2821, -0.7432,  ...,  1.0171, -0.3024,  0.5549],\n","         [ 1.7693, -0.7122, -0.1817,  ...,  0.7357,  0.0621,  0.6490]],\n","\n","        [[ 0.5720, -0.7431, -0.1344,  ...,  1.1870, -0.6276,  0.8877],\n","         [-0.6487, -0.3163, -0.0671,  ...,  0.5401,  0.8663,  0.6951],\n","         [ 0.2707,  0.3195, -0.8519,  ...,  0.0815,  0.9714, -0.4739],\n","         ...,\n","         [ 0.8271, -0.4628,  0.1003,  ...,  0.2523, -0.5042,  1.5827],\n","         [ 0.9589,  0.0105, -0.1909,  ...,  0.9937, -0.2009,  1.1557],\n","         [ 0.7760, -0.3162,  0.2393,  ...,  0.8773, -0.0873,  0.8169]],\n","\n","        [[ 1.4331,  0.1135,  0.1091,  ...,  0.5326, -1.1903,  0.4948],\n","         [ 0.5408, -0.8674, -0.3570,  ..., -0.3193, -0.5996,  1.2711],\n","         [-0.7368, -1.3051,  0.6529,  ...,  1.2516,  1.3143, -0.1168],\n","         ...,\n","         [ 0.5820,  0.0571,  0.4277,  ..., -0.3458, -0.3174, -0.0541],\n","         [ 0.7286, -0.3687,  0.2256,  ...,  0.0286, -1.2707,  0.2600],\n","         [ 1.7012, -1.1729,  0.1635,  ...,  0.3508, -1.5420,  0.5349]],\n","\n","        ...,\n","\n","        [[-0.6693, -2.1827, -0.3535,  ..., -0.2293, -1.3599,  0.4877],\n","         [ 0.0317, -1.2407, -0.1136,  ...,  0.7732,  0.5200,  0.7824],\n","         [-0.5097,  0.0872,  0.0859,  ...,  0.0155, -1.1099,  1.1000],\n","         ...,\n","         [ 0.4623, -1.2449, -0.4717,  ...,  0.1896,  0.0562,  1.0381],\n","         [ 0.1999, -0.9378, -0.6868,  ..., -0.2958, -0.3990,  0.6746],\n","         [ 0.0044, -0.7611, -0.2820,  ...,  0.2217, -0.3418,  0.6100]],\n","\n","        [[ 0.4555, -2.2738,  0.5932,  ...,  0.7287, -1.3531,  1.0139],\n","         [-0.3381, -1.7587,  0.2471,  ...,  0.4839,  0.4225,  1.3198],\n","         [ 0.2939, -1.7190, -0.4784,  ..., -0.1054,  1.2047,  0.5787],\n","         ...,\n","         [ 0.5081, -1.4895,  0.8187,  ...,  0.7911, -0.7665,  1.0167],\n","         [ 1.3213, -1.7414,  0.1626,  ...,  0.1641, -0.9267,  1.4452],\n","         [ 0.4501, -1.5388,  0.7651,  ..., -0.1879, -1.1526,  0.8178]],\n","\n","        [[ 1.1978, -0.7933, -0.8070,  ...,  0.1217, -1.0830,  0.2286],\n","         [ 0.6833, -1.1081, -0.5429,  ..., -0.0294, -0.0776, -0.0907],\n","         [ 0.7086,  0.9890, -1.0696,  ..., -0.4250,  0.0330,  0.3877],\n","         ...,\n","         [ 0.8577, -0.2740, -0.0077,  ...,  0.4835, -1.2117,  0.8315],\n","         [ 1.3124, -0.2946, -0.3941,  ...,  0.3872, -0.7993,  0.1069],\n","         [ 0.7049, -0.8520, -0.1228,  ...,  0.3628, -0.5631,  0.4759]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.7907, -0.0873, -0.6068,  ...,  0.2519,  0.2956,  0.8231],\n","        [ 0.6900,  0.0266, -0.0185,  ..., -0.0356, -0.1080, -0.7975],\n","        [-0.0382, -0.2718, -0.5299,  ..., -0.6007,  0.6565,  0.7099],\n","        ...,\n","        [ 0.3575, -0.4005, -0.4951,  ..., -0.3253,  0.3549,  0.5141],\n","        [ 0.6973,  0.0419, -0.4735,  ..., -0.1678, -0.1042,  0.8389],\n","        [ 0.3533, -0.0877,  0.4325,  ...,  0.4566, -0.4677, -0.5794]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.7907, -0.0873, -0.6068,  ...,  0.2519,  0.2956,  0.8231],\n","        [ 0.6900,  0.0266, -0.0185,  ..., -0.0356, -0.1080, -0.7975],\n","        [-0.0382, -0.2718, -0.5299,  ..., -0.6007,  0.6565,  0.7099],\n","        ...,\n","        [ 0.3575, -0.4005, -0.4951,  ..., -0.3253,  0.3549,  0.5141],\n","        [ 0.6973,  0.0419, -0.4735,  ..., -0.1678, -0.1042,  0.8389],\n","        [ 0.3533, -0.0877,  0.4325,  ...,  0.4566, -0.4677, -0.5794]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.2405, -2.0301, -0.2789,  ...,  1.6514, -1.0523,  0.7214],\n","        [ 0.5720, -0.7431, -0.1344,  ...,  1.1870, -0.6276,  0.8877],\n","        [ 1.4331,  0.1135,  0.1091,  ...,  0.5326, -1.1903,  0.4948],\n","        ...,\n","        [-0.6693, -2.1827, -0.3535,  ..., -0.2293, -1.3599,  0.4877],\n","        [ 0.4555, -2.2738,  0.5932,  ...,  0.7287, -1.3531,  1.0139],\n","        [ 1.1978, -0.7933, -0.8070,  ...,  0.1217, -1.0830,  0.2286]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.7257, -1.6460, -0.4222,  ..., -0.0309, -0.3025, -0.0855],\n","         [ 0.4892, -1.0872, -0.5251,  ...,  0.5455,  1.4047,  0.3363],\n","         [ 0.7276, -1.5717, -0.1923,  ..., -0.4358,  1.2527,  0.7578],\n","         ...,\n","         [ 0.6686, -0.8136, -0.1095,  ...,  0.0764,  0.7403,  0.6358],\n","         [ 0.5060, -0.8547,  0.2925,  ..., -0.1793,  0.6558, -0.1565],\n","         [ 0.1642, -0.6521, -0.3170,  ..., -0.1823,  0.2550,  0.0076]],\n","\n","        [[ 0.1159, -0.9467, -0.1192,  ...,  0.8374, -1.1049, -0.2296],\n","         [ 1.4330,  1.3361,  0.0872,  ...,  0.6139,  0.8649, -0.8294],\n","         [ 2.7131,  1.1370,  0.2983,  ...,  0.1157, -0.0472, -0.6997],\n","         ...,\n","         [ 0.8153,  0.3613,  0.1233,  ...,  0.2249, -0.8285, -0.1725],\n","         [ 1.4584,  0.5151,  0.2835,  ...,  0.2064, -0.9674, -0.3213],\n","         [ 1.5868,  0.7204, -0.0315,  ...,  0.8828, -1.6705,  0.2266]],\n","\n","        [[ 1.0430,  0.4897,  0.5508,  ...,  0.5852, -1.2356, -0.1573],\n","         [ 0.9092,  0.3156,  0.9525,  ..., -0.3696,  1.2850, -0.2586],\n","         [ 0.8017,  0.1343,  0.7852,  ...,  1.1136, -0.1086,  0.5534],\n","         ...,\n","         [ 0.8094,  0.0598,  0.5817,  ...,  0.8866, -0.4621,  0.7457],\n","         [ 0.7759,  0.7535,  0.4853,  ...,  0.8186, -0.4694,  0.6848],\n","         [ 1.5309,  0.8451,  0.6224,  ...,  0.8433,  0.3059,  0.6349]],\n","\n","        ...,\n","\n","        [[ 0.6016, -1.2973,  0.1588,  ...,  0.0185, -0.7730,  0.0355],\n","         [-0.1303, -0.1278,  1.3106,  ...,  0.6566,  0.5563,  0.3363],\n","         [-0.0666, -1.2992, -0.1616,  ..., -0.2990,  0.2494,  0.0767],\n","         ...,\n","         [ 1.1578, -0.7487,  0.8183,  ...,  0.7428, -0.1281,  0.2702],\n","         [ 0.5287, -1.4174,  0.2390,  ..., -0.3734, -0.5468,  1.0640],\n","         [ 0.7957, -1.0014,  0.5495,  ...,  0.1604, -0.3290,  0.2949]],\n","\n","        [[ 0.5680, -0.8713,  0.5155,  ...,  0.8382, -1.1197,  0.1875],\n","         [ 0.3965, -2.0226,  0.6355,  ...,  0.9628, -1.3785, -1.3337],\n","         [ 0.1830, -0.0849,  0.5199,  ...,  1.2822, -1.2314,  0.2709],\n","         ...,\n","         [ 0.4519, -1.0293,  0.3535,  ..., -0.0467, -0.6988,  0.1708],\n","         [ 0.3452, -0.5564,  0.6719,  ..., -0.0503, -0.6182,  0.0701],\n","         [ 0.2797, -0.9193,  0.4362,  ...,  0.1934, -0.9066, -0.1162]],\n","\n","        [[ 0.1968, -0.5743,  0.3485,  ...,  0.4879, -1.5910,  0.0351],\n","         [ 0.1403, -1.1482, -1.1287,  ...,  0.3223,  0.2655, -0.1930],\n","         [ 0.0829, -0.9667,  0.2109,  ...,  1.0686,  0.6672,  0.0416],\n","         ...,\n","         [ 1.4105, -1.1008,  0.0936,  ..., -0.2923, -0.5128, -0.0406],\n","         [ 0.4048, -1.5093,  0.3792,  ...,  0.1618,  0.2397, -0.7002],\n","         [ 1.0974, -1.3929,  0.5555,  ...,  0.7424, -0.8536,  0.0671]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.3076, -0.5055,  0.1500,  ..., -0.0074, -0.4807, -0.9298],\n","        [ 0.2316, -0.1792,  0.2894,  ...,  0.3385, -0.6901,  0.8460],\n","        [ 0.2863, -0.2179,  0.3350,  ...,  0.7184, -0.3697,  0.9246],\n","        ...,\n","        [ 0.1496, -0.5988, -0.4949,  ..., -0.4063,  0.0477, -0.6149],\n","        [-0.1337,  0.4602, -0.4173,  ..., -0.2213, -0.0139, -0.9878],\n","        [ 0.7435, -0.0264, -0.2551,  ..., -0.1649,  0.1071,  0.5288]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.3076, -0.5055,  0.1500,  ..., -0.0074, -0.4807, -0.9298],\n","        [ 0.2316, -0.1792,  0.2894,  ...,  0.3385, -0.6901,  0.8460],\n","        [ 0.2863, -0.2179,  0.3350,  ...,  0.7184, -0.3697,  0.9246],\n","        ...,\n","        [ 0.1496, -0.5988, -0.4949,  ..., -0.4063,  0.0477, -0.6149],\n","        [-0.1337,  0.4602, -0.4173,  ..., -0.2213, -0.0139, -0.9878],\n","        [ 0.7435, -0.0264, -0.2551,  ..., -0.1649,  0.1071,  0.5288]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.7257, -1.6460, -0.4222,  ..., -0.0309, -0.3025, -0.0855],\n","        [ 0.1159, -0.9467, -0.1192,  ...,  0.8374, -1.1049, -0.2296],\n","        [ 1.0430,  0.4897,  0.5508,  ...,  0.5852, -1.2356, -0.1573],\n","        ...,\n","        [ 0.6016, -1.2973,  0.1588,  ...,  0.0185, -0.7730,  0.0355],\n","        [ 0.5680, -0.8713,  0.5155,  ...,  0.8382, -1.1197,  0.1875],\n","        [ 0.1968, -0.5743,  0.3485,  ...,  0.4879, -1.5910,  0.0351]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.9893e-01, -1.4331e+00,  4.8852e-01,  ..., -2.6494e-02,\n","          -1.9781e+00,  3.7202e-01],\n","         [ 4.6176e-02, -1.5830e+00,  2.0593e-01,  ..., -2.0790e-01,\n","          -8.8199e-01,  6.8945e-01],\n","         [-2.6547e-01, -2.3464e-01, -1.6143e-01,  ..., -4.0620e-01,\n","          -4.1105e-01, -3.8264e-01],\n","         ...,\n","         [ 7.9844e-01, -5.7750e-01,  3.4638e-01,  ..., -3.2760e-01,\n","          -5.0850e-01, -3.3578e-01],\n","         [ 1.1291e+00, -1.0525e+00,  2.1647e-01,  ...,  3.4070e-01,\n","           1.4633e-01, -8.5922e-02],\n","         [ 3.9016e-01, -7.1383e-01,  2.0867e-01,  ..., -1.6050e-01,\n","           1.0254e-01, -6.8539e-01]],\n","\n","        [[-6.5855e-01, -2.2668e-01, -2.0750e-01,  ..., -2.4829e-01,\n","          -6.4008e-02,  8.4896e-01],\n","         [-4.1458e-01,  4.8810e-01,  1.3290e+00,  ...,  3.4163e-01,\n","           1.0558e+00,  1.3729e+00],\n","         [-3.7787e-01, -1.3632e+00, -5.4684e-02,  ..., -1.4124e-01,\n","          -2.9844e-01,  6.8445e-01],\n","         ...,\n","         [ 8.2200e-02,  3.4408e-01,  8.0157e-01,  ...,  3.1125e-02,\n","           6.5452e-01,  8.5383e-01],\n","         [-2.4711e-02,  4.0646e-01,  1.1091e+00,  ...,  1.0012e-02,\n","           8.1208e-01,  6.4663e-01],\n","         [ 6.2001e-02,  4.2680e-01,  1.1167e+00,  ...,  1.5849e-02,\n","           4.6885e-01,  6.2435e-01]],\n","\n","        [[ 1.1923e+00, -1.5614e+00, -1.9453e-01,  ...,  5.3625e-01,\n","          -1.9290e+00, -1.1248e-01],\n","         [ 1.9461e+00,  7.2641e-01,  5.5927e-01,  ..., -2.8960e-01,\n","           6.7901e-01,  1.1754e-01],\n","         [ 8.1279e-01,  1.3707e+00,  1.3631e-01,  ..., -1.0385e-01,\n","          -5.0704e-01, -1.1711e+00],\n","         ...,\n","         [ 7.2748e-01, -9.7753e-01,  5.9473e-01,  ...,  1.0388e+00,\n","          -3.3711e-01,  2.3522e-01],\n","         [ 4.9673e-01, -8.3424e-01,  8.2244e-01,  ...,  1.1857e+00,\n","          -5.0312e-01, -4.6291e-01],\n","         [ 1.1754e+00, -5.3150e-01,  9.3913e-01,  ...,  5.8828e-01,\n","          -3.3579e-01,  7.0675e-01]],\n","\n","        ...,\n","\n","        [[ 1.0955e+00, -1.7642e+00, -2.3873e-03,  ...,  4.1812e-01,\n","          -6.3136e-01, -4.1778e-02],\n","         [-7.1235e-01, -1.5564e+00, -6.1987e-01,  ...,  1.3108e-03,\n","          -2.8048e-01,  1.3983e-01],\n","         [ 4.4026e-01, -3.0956e-01,  1.4215e-01,  ...,  3.1144e-01,\n","          -1.5126e-01, -7.5496e-03],\n","         ...,\n","         [ 8.3961e-01, -5.7476e-01, -1.2236e-01,  ...,  3.8178e-01,\n","          -1.2273e+00,  5.6422e-01],\n","         [ 1.1254e+00, -1.8133e-01,  3.2863e-01,  ...,  1.0771e+00,\n","          -3.4447e-01,  1.2002e-01],\n","         [ 7.1115e-01, -3.4714e-01, -7.5169e-02,  ...,  8.7980e-01,\n","          -8.3046e-01, -2.2748e-01]],\n","\n","        [[ 7.9724e-01, -2.0883e-01, -8.2999e-01,  ...,  1.0676e+00,\n","          -8.6514e-01, -5.8900e-01],\n","         [ 4.3765e-01, -1.5901e-01, -1.8957e-01,  ...,  9.8453e-01,\n","          -5.0709e-02, -2.8679e-01],\n","         [ 4.4012e-02, -9.4862e-02,  4.3609e-01,  ...,  7.2429e-01,\n","           2.4115e-01,  3.4380e-01],\n","         ...,\n","         [ 2.1874e+00,  2.0898e-01, -3.6788e-01,  ..., -3.0050e-01,\n","          -3.9835e-01, -1.2883e+00],\n","         [ 1.0231e+00, -1.5286e-01, -2.0473e-01,  ...,  2.2456e-01,\n","          -4.6026e-01, -2.7085e-01],\n","         [ 9.8779e-01, -6.7727e-01,  5.8812e-01,  ...,  3.2722e-01,\n","          -7.3578e-01,  1.9599e-01]],\n","\n","        [[ 1.3152e+00, -1.6797e-01, -1.8867e-01,  ...,  4.3978e-01,\n","          -1.2773e+00, -5.3461e-01],\n","         [ 1.4007e+00, -5.9347e-01, -3.3696e-01,  ..., -3.7148e-01,\n","           5.9883e-01,  5.8746e-01],\n","         [ 2.7931e-01,  5.3475e-01, -2.9431e-01,  ...,  8.9129e-02,\n","          -8.7970e-01,  1.2174e-01],\n","         ...,\n","         [ 9.8736e-01, -2.9006e-01,  8.9107e-03,  ...,  4.4717e-01,\n","          -6.0114e-01,  8.0269e-01],\n","         [ 1.4441e+00, -2.3180e-01,  3.7694e-01,  ..., -2.9499e-01,\n","          -3.0408e-01, -9.5766e-02],\n","         [ 7.8290e-01,  6.5546e-01, -3.9987e-01,  ...,  7.1292e-01,\n","          -1.4348e+00, -1.6975e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0897,  0.0241, -0.2093,  ...,  0.2860, -0.4478,  0.4658],\n","        [-0.2558, -0.1716,  0.2741,  ..., -0.3066, -0.3097, -0.9526],\n","        [ 0.4714,  0.3684,  0.2860,  ..., -0.1133,  0.4617,  0.0599],\n","        ...,\n","        [ 0.3885, -0.0768, -0.7070,  ..., -0.3128, -0.4535, -0.8541],\n","        [ 0.4687, -0.5154, -0.1043,  ..., -0.2542,  0.0023,  0.9471],\n","        [ 0.4022, -0.2193, -0.5531,  ...,  0.1903, -0.2919, -0.1969]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[-0.0897,  0.0241, -0.2093,  ...,  0.2860, -0.4478,  0.4658],\n","        [-0.2558, -0.1716,  0.2741,  ..., -0.3066, -0.3097, -0.9526],\n","        [ 0.4714,  0.3684,  0.2860,  ..., -0.1133,  0.4617,  0.0599],\n","        ...,\n","        [ 0.3885, -0.0768, -0.7070,  ..., -0.3128, -0.4535, -0.8541],\n","        [ 0.4687, -0.5154, -0.1043,  ..., -0.2542,  0.0023,  0.9471],\n","        [ 0.4022, -0.2193, -0.5531,  ...,  0.1903, -0.2919, -0.1969]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.4989, -1.4331,  0.4885,  ..., -0.0265, -1.9781,  0.3720],\n","        [-0.6586, -0.2267, -0.2075,  ..., -0.2483, -0.0640,  0.8490],\n","        [ 1.1923, -1.5614, -0.1945,  ...,  0.5362, -1.9290, -0.1125],\n","        ...,\n","        [ 1.0955, -1.7642, -0.0024,  ...,  0.4181, -0.6314, -0.0418],\n","        [ 0.7972, -0.2088, -0.8300,  ...,  1.0676, -0.8651, -0.5890],\n","        [ 1.3152, -0.1680, -0.1887,  ...,  0.4398, -1.2773, -0.5346]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.6882e+00, -1.3249e+00, -1.3812e-01,  ...,  1.1226e+00,\n","          -1.2576e+00,  6.5984e-01],\n","         [ 2.0585e-01, -1.6099e+00, -3.1840e-01,  ..., -8.6617e-02,\n","          -2.4718e-02,  2.2703e-01],\n","         [ 2.9869e-01, -1.1952e+00,  5.0746e-01,  ...,  2.2185e-01,\n","          -6.0721e-01, -9.0167e-01],\n","         ...,\n","         [ 8.8728e-01, -1.5152e-01, -6.2736e-01,  ..., -4.2870e-01,\n","          -7.0380e-01, -3.4506e-01],\n","         [ 1.1550e+00, -1.6293e-01,  9.1777e-01,  ...,  1.0744e+00,\n","          -8.2880e-01,  1.3020e-01],\n","         [ 1.5368e+00,  2.7164e-01, -4.4557e-01,  ...,  1.3195e-01,\n","          -2.7516e-01,  4.0261e-01]],\n","\n","        [[ 8.0913e-01, -1.4243e-01, -1.2189e-01,  ...,  6.7465e-01,\n","          -1.4617e+00, -5.5556e-03],\n","         [ 4.8199e-01, -1.3290e+00,  7.1317e-01,  ..., -4.1574e-01,\n","          -7.3591e-01, -5.3706e-01],\n","         [ 2.3644e-01,  5.6743e-01,  9.3044e-01,  ...,  3.5756e-01,\n","          -4.9585e-01, -2.0780e-01],\n","         ...,\n","         [ 1.2931e+00,  3.9990e-01,  5.4955e-01,  ...,  3.2472e-01,\n","          -9.4690e-01,  1.0952e-01],\n","         [ 1.7971e+00, -2.3136e-01,  3.0598e-01,  ...,  3.5346e-01,\n","          -8.2471e-01,  5.3690e-01],\n","         [ 1.6852e+00, -3.9067e-01, -3.8237e-02,  ...,  5.4918e-01,\n","          -1.6387e+00,  3.6360e-01]],\n","\n","        [[ 1.8575e+00, -1.7698e-01, -5.8874e-01,  ...,  8.5954e-01,\n","          -1.5515e+00,  3.2213e-01],\n","         [ 1.4138e+00, -1.3381e+00, -2.1226e-01,  ...,  5.1623e-01,\n","          -4.6799e-01, -3.8931e-01],\n","         [ 1.8996e+00, -6.6425e-01,  9.0767e-01,  ...,  8.8187e-01,\n","           9.9046e-02,  4.9226e-01],\n","         ...,\n","         [ 1.3453e+00, -1.9970e+00, -2.1000e-01,  ..., -5.8009e-01,\n","          -3.7369e+00,  1.0081e-01],\n","         [ 8.2649e-01, -1.8443e+00,  3.2572e-01,  ...,  4.9242e-01,\n","          -3.0851e+00,  1.0911e+00],\n","         [ 1.1415e+00, -5.2091e-01,  3.5004e-01,  ...,  5.1449e-01,\n","           1.7515e-02,  9.4899e-01]],\n","\n","        ...,\n","\n","        [[ 3.6929e-01, -8.9681e-01, -5.6659e-01,  ...,  1.1754e+00,\n","          -2.0589e+00,  8.4205e-01],\n","         [ 1.0381e-01, -9.9681e-01,  2.3354e-01,  ...,  7.8210e-01,\n","          -8.0173e-02,  6.7792e-01],\n","         [ 5.1668e-01,  3.5632e-02, -9.4415e-01,  ...,  1.9446e+00,\n","          -8.2088e-01, -2.8372e-01],\n","         ...,\n","         [ 7.4547e-01, -7.3090e-02,  1.0016e-02,  ...,  1.3055e+00,\n","          -3.7095e-01,  1.6604e+00],\n","         [ 1.2323e+00, -1.0116e+00,  4.2426e-01,  ...,  1.3087e+00,\n","           4.8483e-03,  1.0722e+00],\n","         [ 1.2027e+00, -7.6634e-01,  1.7960e-02,  ..., -2.3460e-01,\n","          -1.2269e+00,  1.4292e+00]],\n","\n","        [[ 1.1902e+00, -2.0440e+00, -2.8036e-01,  ...,  8.0356e-01,\n","          -3.7532e-01,  3.9032e-01],\n","         [-1.1100e+00, -1.9404e+00, -3.1908e-01,  ...,  1.1141e-01,\n","          -1.3233e+00,  5.3837e-02],\n","         [ 1.2619e+00, -8.6358e-01,  6.5920e-01,  ...,  7.5071e-01,\n","          -1.0610e+00,  3.6100e-01],\n","         ...,\n","         [ 1.4203e+00, -2.4132e+00, -3.3130e-01,  ...,  4.6185e-02,\n","          -4.3370e-01,  7.5777e-01],\n","         [ 2.3546e-01, -1.8883e+00,  1.9940e-01,  ...,  3.2352e-01,\n","          -6.1350e-01,  6.5365e-01],\n","         [ 2.5734e-01, -1.7045e+00,  1.1088e-02,  ...,  4.0279e-01,\n","          -6.5947e-01,  5.3821e-01]],\n","\n","        [[-3.0449e-03,  6.7086e-02, -2.0750e-02,  ...,  3.7676e-01,\n","          -1.5193e+00, -1.0212e-01],\n","         [-2.5823e-01,  6.1181e-01, -3.7416e-02,  ...,  7.9141e-01,\n","           5.0955e-01, -9.5474e-01],\n","         [ 5.8284e-01, -1.9898e-01,  1.2031e+00,  ..., -5.4109e-02,\n","           6.2989e-02, -8.7270e-01],\n","         ...,\n","         [ 1.9712e-01,  9.2292e-01,  1.3517e+00,  ...,  8.9095e-01,\n","          -1.2471e+00,  1.1108e-01],\n","         [ 2.8867e-01, -7.7399e-01, -8.4591e-02,  ...,  3.6263e-01,\n","          -7.7110e-01,  4.5899e-01],\n","         [ 5.7834e-01, -1.4788e+00,  1.4575e+00,  ...,  1.7399e+00,\n","          -2.2133e+00,  7.4190e-03]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.1376, -0.0922,  0.2756,  ..., -0.0161, -0.5277, -0.8504],\n","        [ 0.3343, -0.0860,  0.3928,  ...,  0.4623, -0.3122,  0.6548],\n","        [ 0.4927,  0.1198,  0.5970,  ..., -0.5121,  0.0813,  0.8462],\n","        ...,\n","        [ 0.6183,  0.2399, -0.0641,  ..., -0.2636,  0.1823,  0.7441],\n","        [ 0.1688,  0.1149, -0.1508,  ..., -0.2393, -0.3323, -0.7569],\n","        [ 0.2208,  0.1077,  0.4775,  ...,  0.4039,  0.6465,  0.7825]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[-0.1376, -0.0922,  0.2756,  ..., -0.0161, -0.5277, -0.8504],\n","        [ 0.3343, -0.0860,  0.3928,  ...,  0.4623, -0.3122,  0.6548],\n","        [ 0.4927,  0.1198,  0.5970,  ..., -0.5121,  0.0813,  0.8462],\n","        ...,\n","        [ 0.6183,  0.2399, -0.0641,  ..., -0.2636,  0.1823,  0.7441],\n","        [ 0.1688,  0.1149, -0.1508,  ..., -0.2393, -0.3323, -0.7569],\n","        [ 0.2208,  0.1077,  0.4775,  ...,  0.4039,  0.6465,  0.7825]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 1.6882, -1.3249, -0.1381,  ...,  1.1226, -1.2576,  0.6598],\n","        [ 0.8091, -0.1424, -0.1219,  ...,  0.6746, -1.4617, -0.0056],\n","        [ 1.8575, -0.1770, -0.5887,  ...,  0.8595, -1.5515,  0.3221],\n","        ...,\n","        [ 0.3693, -0.8968, -0.5666,  ...,  1.1754, -2.0589,  0.8421],\n","        [ 1.1902, -2.0440, -0.2804,  ...,  0.8036, -0.3753,  0.3903],\n","        [-0.0030,  0.0671, -0.0207,  ...,  0.3768, -1.5193, -0.1021]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0096,  0.3348,  0.8599,  ..., -0.3541, -1.4343,  0.2820],\n","         [ 1.0284, -0.0340,  1.4095,  ...,  0.4837, -0.1416, -0.3248],\n","         [ 0.9765,  1.1633, -0.4194,  ...,  0.8474, -1.0927, -0.0888],\n","         ...,\n","         [ 1.0732, -0.4417,  1.6072,  ...,  0.4542, -0.5784,  0.9828],\n","         [ 1.3831,  0.2364,  1.4487,  ...,  0.6933, -1.0005,  0.0184],\n","         [ 0.9960,  0.5837,  1.2746,  ...,  0.9792, -1.1118,  0.1366]],\n","\n","        [[-0.4394,  0.4855, -0.6960,  ...,  1.0340, -1.4820, -0.3906],\n","         [ 0.4585, -0.4852,  0.8768,  ...,  0.2636, -0.6144,  0.1330],\n","         [-0.1179, -1.5553, -0.4239,  ...,  0.5777, -0.5558, -0.5571],\n","         ...,\n","         [ 0.3218,  0.3323,  0.0513,  ...,  0.2432,  0.2368, -0.3889],\n","         [ 0.1686, -0.3209, -0.2018,  ...,  0.5564,  0.3176, -0.2088],\n","         [ 0.2656,  0.0027,  0.1498,  ...,  0.1733, -0.0228, -0.2502]],\n","\n","        [[ 0.8305, -0.7770, -0.9477,  ...,  0.3998, -0.3765, -0.6448],\n","         [ 0.1779,  0.2969, -0.6226,  ..., -0.6740,  0.0198,  0.1706],\n","         [ 0.0274, -0.4350, -0.4309,  ..., -0.6103,  0.9020,  1.1926],\n","         ...,\n","         [ 0.9752, -0.4784, -0.7375,  ..., -0.3744, -0.1774,  0.0084],\n","         [ 1.2214,  0.1883, -0.7345,  ..., -0.1510,  0.1537, -0.3418],\n","         [ 1.4858, -0.2362, -0.3365,  ..., -1.1765,  0.2078, -0.2186]],\n","\n","        ...,\n","\n","        [[ 0.0478, -0.6467,  0.4658,  ..., -0.1851, -0.9800,  1.2564],\n","         [-0.1322,  0.0196,  0.5083,  ..., -0.3167, -0.2597,  1.4504],\n","         [-0.1772, -1.0555,  0.8321,  ..., -0.2451, -1.2075,  0.7034],\n","         ...,\n","         [ 0.3007, -0.8214,  0.4729,  ...,  0.6998, -0.6326,  0.9621],\n","         [ 0.2496, -0.7080,  0.8464,  ...,  0.7592, -0.4393,  1.2152],\n","         [ 0.4446, -1.3809,  0.7334,  ...,  1.4891, -1.3762,  0.4374]],\n","\n","        [[-0.5892, -0.9947, -0.8102,  ..., -1.0527, -1.3266,  0.6415],\n","         [ 0.2802,  0.7069, -0.2730,  ..., -0.2989,  0.2764,  0.9241],\n","         [ 1.8502,  0.0182,  0.0348,  ...,  1.4850,  0.9486,  1.8801],\n","         ...,\n","         [-0.3672, -0.7496, -0.2274,  ...,  0.0141, -0.2548,  0.2769],\n","         [ 0.1788,  0.3219, -0.1213,  ...,  0.3398,  0.4143,  0.8340],\n","         [ 0.5370,  0.5206, -0.0179,  ...,  1.1542,  0.4047,  1.1093]],\n","\n","        [[-0.1280, -1.6547,  0.5405,  ..., -0.3344, -1.5201, -0.1011],\n","         [-1.2278, -2.2764,  0.0852,  ...,  0.2924, -0.2991,  1.4613],\n","         [ 1.0783, -2.0456,  1.9478,  ...,  0.4383,  0.1644, -0.1471],\n","         ...,\n","         [ 0.0767, -0.8937,  0.6126,  ...,  0.6998, -0.5544,  0.2150],\n","         [-0.0445, -1.4153,  0.4612,  ...,  0.5030, -0.6729,  0.4049],\n","         [ 0.5112, -0.8675,  0.5795,  ...,  0.4082, -0.6908,  0.6204]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0849, -0.6323, -0.0561,  ..., -0.2341,  0.1677, -0.0297],\n","        [ 0.0406,  0.3661, -0.0968,  ...,  0.3767,  0.3287,  0.1355],\n","        [ 0.1766,  0.0537,  0.0066,  ...,  0.5651, -0.1444, -0.2456],\n","        ...,\n","        [ 0.2030,  0.1101, -0.1055,  ...,  0.3896, -0.7548,  0.1281],\n","        [ 0.4971, -0.4635, -0.0312,  ..., -0.0250,  0.1704, -0.4707],\n","        [ 0.4653,  0.1068, -0.3145,  ...,  0.4870,  0.2082,  0.6552]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.0849, -0.6323, -0.0561,  ..., -0.2341,  0.1677, -0.0297],\n","        [ 0.0406,  0.3661, -0.0968,  ...,  0.3767,  0.3287,  0.1355],\n","        [ 0.1766,  0.0537,  0.0066,  ...,  0.5651, -0.1444, -0.2456],\n","        ...,\n","        [ 0.2030,  0.1101, -0.1055,  ...,  0.3896, -0.7548,  0.1281],\n","        [ 0.4971, -0.4635, -0.0312,  ..., -0.0250,  0.1704, -0.4707],\n","        [ 0.4653,  0.1068, -0.3145,  ...,  0.4870,  0.2082,  0.6552]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.0096,  0.3348,  0.8599,  ..., -0.3541, -1.4343,  0.2820],\n","        [-0.4394,  0.4855, -0.6960,  ...,  1.0340, -1.4820, -0.3906],\n","        [ 0.8305, -0.7770, -0.9477,  ...,  0.3998, -0.3765, -0.6448],\n","        ...,\n","        [ 0.0478, -0.6467,  0.4658,  ..., -0.1851, -0.9800,  1.2564],\n","        [-0.5892, -0.9947, -0.8102,  ..., -1.0527, -1.3266,  0.6415],\n","        [-0.1280, -1.6547,  0.5405,  ..., -0.3344, -1.5201, -0.1011]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0080, -0.9593,  0.6847,  ..., -0.2346, -0.5510, -0.1944],\n","         [ 0.0868, -0.4345,  0.7783,  ..., -0.0521, -1.4579, -1.6067],\n","         [ 1.4764, -0.4340,  1.1925,  ...,  0.4461, -0.5971, -0.8227],\n","         ...,\n","         [ 0.1808, -1.8677,  0.7708,  ..., -0.0178,  0.1929,  0.6801],\n","         [ 1.4592, -1.9256,  0.0435,  ..., -0.6615,  0.4047, -0.0606],\n","         [ 0.4913, -1.7562,  1.1275,  ...,  0.0501, -0.6712,  0.0833]],\n","\n","        [[ 0.6414, -0.5195,  0.6919,  ...,  0.1811, -0.2097,  0.7843],\n","         [ 1.1602, -1.4256,  0.6086,  ...,  0.3177,  1.4005, -0.5384],\n","         [ 0.1481, -0.6980,  1.7606,  ...,  0.7613,  1.2461, -0.2834],\n","         ...,\n","         [-0.0948,  0.8791,  1.0200,  ...,  0.1166, -0.7976, -0.5536],\n","         [ 0.0835,  2.0614,  0.5059,  ...,  0.3828, -1.5231, -0.2942],\n","         [-0.3334,  0.9484,  0.4253,  ...,  0.5472, -0.7800,  0.0169]],\n","\n","        [[ 0.7401, -1.6296,  0.5791,  ...,  0.1809, -0.4153, -0.1321],\n","         [-0.7052, -2.0185,  0.1439,  ...,  0.4727,  0.6079, -0.1543],\n","         [ 0.9015, -0.7659, -0.6628,  ...,  0.1836,  0.4126,  0.7954],\n","         ...,\n","         [ 0.5085,  0.0783, -0.8289,  ..., -0.2390,  0.2384, -0.8649],\n","         [ 0.6214, -0.0099, -0.3119,  ..., -0.1503,  0.6397, -1.2089],\n","         [ 1.0671,  0.0709,  0.1234,  ..., -0.7800,  0.6737, -0.7934]],\n","\n","        ...,\n","\n","        [[ 0.5849, -1.3432, -0.6211,  ...,  0.5774, -1.1738,  0.3832],\n","         [ 0.3716, -1.0514, -0.3330,  ...,  0.8195, -0.3881, -0.1823],\n","         [-0.2899, -0.6304,  0.5514,  ..., -0.1069, -0.1359, -0.3084],\n","         ...,\n","         [ 0.5220, -0.1890, -0.1564,  ..., -0.4414,  0.0175, -0.2966],\n","         [ 0.4211, -0.7679, -0.2749,  ..., -0.2926,  0.3606, -0.0973],\n","         [ 1.1344,  0.0686,  0.7278,  ...,  0.7143,  0.1468,  0.7900]],\n","\n","        [[ 0.0756, -0.4376, -0.5171,  ..., -0.5255, -1.2847,  0.4533],\n","         [ 1.1768,  0.1339, -0.3109,  ...,  0.1958,  0.9645, -0.2207],\n","         [-0.1374,  0.6259,  0.5999,  ..., -0.2704, -1.4709, -0.1609],\n","         ...,\n","         [ 0.6146, -0.3848, -0.2353,  ..., -0.1359, -0.3849, -0.0228],\n","         [ 0.5759, -0.1357,  0.1799,  ..., -0.2621, -0.3723, -0.1510],\n","         [ 1.0907, -0.1860,  0.4254,  ..., -0.6397, -0.5959, -0.1393]],\n","\n","        [[ 0.6445, -0.7031, -0.8273,  ...,  0.8184, -2.4998,  0.4551],\n","         [-0.6702, -0.9694, -0.8194,  ...,  0.4052, -1.2093,  0.3289],\n","         [-0.2611, -1.0200,  0.0372,  ...,  0.3853, -1.4708, -0.2506],\n","         ...,\n","         [ 0.6469,  0.4352, -0.0924,  ...,  0.8279, -1.6129,  0.5319],\n","         [ 0.7907,  0.1702,  0.0190,  ...,  0.7221, -1.3913,  0.1916],\n","         [ 1.3585, -0.1048,  0.2812,  ...,  0.7764, -0.5506,  0.8483]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.1127,  0.0375, -0.2095,  ...,  0.0408, -0.5605, -0.9511],\n","        [ 0.1232,  0.3561, -0.5014,  ...,  0.1659,  0.1293, -0.8832],\n","        [ 0.1433,  0.2241,  0.0066,  ...,  0.0154, -0.4461, -0.8597],\n","        ...,\n","        [ 0.7816, -0.0139,  0.3170,  ...,  0.2735, -0.2557,  0.8304],\n","        [ 0.1712,  0.0836, -0.1114,  ..., -0.0537,  0.2320,  0.2216],\n","        [ 0.6651, -0.0208,  0.4095,  ..., -0.1264, -0.0258,  0.9333]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.1127,  0.0375, -0.2095,  ...,  0.0408, -0.5605, -0.9511],\n","        [ 0.1232,  0.3561, -0.5014,  ...,  0.1659,  0.1293, -0.8832],\n","        [ 0.1433,  0.2241,  0.0066,  ...,  0.0154, -0.4461, -0.8597],\n","        ...,\n","        [ 0.7816, -0.0139,  0.3170,  ...,  0.2735, -0.2557,  0.8304],\n","        [ 0.1712,  0.0836, -0.1114,  ..., -0.0537,  0.2320,  0.2216],\n","        [ 0.6651, -0.0208,  0.4095,  ..., -0.1264, -0.0258,  0.9333]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.0080, -0.9593,  0.6847,  ..., -0.2346, -0.5510, -0.1944],\n","        [ 0.6414, -0.5195,  0.6919,  ...,  0.1811, -0.2097,  0.7843],\n","        [ 0.7401, -1.6296,  0.5791,  ...,  0.1809, -0.4153, -0.1321],\n","        ...,\n","        [ 0.5849, -1.3432, -0.6211,  ...,  0.5774, -1.1738,  0.3832],\n","        [ 0.0756, -0.4376, -0.5171,  ..., -0.5255, -1.2847,  0.4533],\n","        [ 0.6445, -0.7031, -0.8273,  ...,  0.8184, -2.4998,  0.4551]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2191, -0.4192,  0.7686,  ..., -0.2083, -0.3023,  0.2344],\n","         [ 0.3061, -0.7731,  1.4861,  ..., -1.1702, -0.1814,  0.3033],\n","         [ 1.7907,  0.5105,  1.6516,  ..., -0.9989,  0.7233, -0.4361],\n","         ...,\n","         [ 0.3638, -0.6815,  0.2007,  ..., -0.1251, -0.1848, -0.0077],\n","         [ 0.0247, -1.5821,  0.6989,  ..., -0.5413, -0.9627, -0.3195],\n","         [-0.2624, -1.1004,  0.7983,  ..., -0.2626, -0.0215,  0.4232]],\n","\n","        [[ 0.2554, -1.0551,  0.3287,  ..., -0.0235, -1.8167,  0.2302],\n","         [ 0.5571, -2.1692,  0.4526,  ...,  0.2448,  0.3265,  0.0635],\n","         [ 2.1666, -2.2703,  0.0451,  ...,  0.6560, -2.4467, -0.4611],\n","         ...,\n","         [ 0.2594, -1.1619,  0.0576,  ...,  0.4171, -0.4098,  0.9204],\n","         [ 0.2445, -1.0916,  0.8249,  ...,  0.0538, -1.0070,  0.4540],\n","         [ 0.5798, -0.5812,  0.4738,  ...,  0.0563, -1.1846,  0.4857]],\n","\n","        [[ 1.4779, -0.1211, -1.0453,  ...,  0.6410, -0.3139,  0.9856],\n","         [-0.9138, -1.7524, -0.3418,  ...,  0.3206,  0.3482,  0.3500],\n","         [ 0.1797,  0.6081, -0.5264,  ..., -0.6780,  1.2660,  0.4824],\n","         ...,\n","         [ 0.7999,  0.4566,  0.0422,  ...,  0.6421,  0.4111,  0.0149],\n","         [ 0.7873,  0.6277,  0.3772,  ...,  0.6019,  0.5328, -0.3982],\n","         [ 0.5690,  0.5371, -0.2871,  ...,  0.5653,  0.6356, -0.1194]],\n","\n","        ...,\n","\n","        [[-0.0482, -0.6053,  0.0285,  ...,  0.3494, -1.6159,  1.1925],\n","         [ 0.5712, -0.4085, -0.1620,  ...,  1.7149,  0.8197, -0.1269],\n","         [ 0.0860,  0.3953,  0.0144,  ...,  1.1198, -0.4255, -0.7851],\n","         ...,\n","         [ 0.0430, -0.7780,  0.3270,  ...,  0.1979, -1.0307,  0.5554],\n","         [ 0.0501, -0.7495,  0.6498,  ..., -0.0811, -0.2810,  0.6566],\n","         [-0.2596, -1.3790, -0.0952,  ..., -0.1042, -0.8790,  0.2338]],\n","\n","        [[ 0.9719, -0.5981,  0.4547,  ..., -0.0070, -1.0324,  0.9424],\n","         [ 0.0415, -0.7772,  0.2280,  ..., -0.1710,  0.7711,  0.3187],\n","         [-0.0060, -0.9648,  0.1620,  ...,  0.5329, -0.4672, -0.1778],\n","         ...,\n","         [ 1.9862, -0.8221,  0.3791,  ...,  0.0194, -1.5248,  0.5240],\n","         [ 1.4957, -0.7028,  0.7689,  ...,  0.0957, -0.9590,  0.9311],\n","         [ 1.5170, -0.8158,  0.1429,  ..., -0.1436, -1.0591,  0.2982]],\n","\n","        [[ 0.9474, -0.9824,  0.2895,  ..., -0.2528, -1.2321,  0.7708],\n","         [ 1.0678, -0.3489,  0.6201,  ..., -1.2336,  0.1007, -0.4775],\n","         [-0.2639,  0.8188,  0.9809,  ..., -0.1120, -0.4138, -0.1638],\n","         ...,\n","         [ 0.0429, -0.8680,  1.1315,  ...,  0.4123, -0.9010, -0.0408],\n","         [ 0.5102, -0.9415,  0.4284,  ..., -0.1124, -1.1890, -0.5285],\n","         [ 0.2212, -1.1630,  1.2329,  ...,  0.6334, -1.2354,  0.6096]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0844, -0.0393,  0.2184,  ...,  0.4101, -0.4947, -0.9692],\n","        [ 0.4473,  0.0791, -0.4443,  ...,  0.3124, -0.6865, -0.2186],\n","        [ 0.6222, -0.3614, -0.1485,  ..., -0.0785, -0.1819,  0.8942],\n","        ...,\n","        [ 0.0587, -0.1465,  0.0294,  ...,  0.0575, -0.1173, -0.6332],\n","        [ 0.4840, -0.2668, -0.1102,  ..., -0.2829,  0.0031, -0.3691],\n","        [ 0.7475,  0.0686,  0.1914,  ...,  0.4239,  0.4690, -0.7162]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[-0.0844, -0.0393,  0.2184,  ...,  0.4101, -0.4947, -0.9692],\n","        [ 0.4473,  0.0791, -0.4443,  ...,  0.3124, -0.6865, -0.2186],\n","        [ 0.6222, -0.3614, -0.1485,  ..., -0.0785, -0.1819,  0.8942],\n","        ...,\n","        [ 0.0587, -0.1465,  0.0294,  ...,  0.0575, -0.1173, -0.6332],\n","        [ 0.4840, -0.2668, -0.1102,  ..., -0.2829,  0.0031, -0.3691],\n","        [ 0.7475,  0.0686,  0.1914,  ...,  0.4239,  0.4690, -0.7162]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.2191, -0.4192,  0.7686,  ..., -0.2083, -0.3023,  0.2344],\n","        [ 0.2554, -1.0551,  0.3287,  ..., -0.0235, -1.8167,  0.2302],\n","        [ 1.4779, -0.1211, -1.0453,  ...,  0.6410, -0.3139,  0.9856],\n","        ...,\n","        [-0.0482, -0.6053,  0.0285,  ...,  0.3494, -1.6159,  1.1925],\n","        [ 0.9719, -0.5981,  0.4547,  ..., -0.0070, -1.0324,  0.9424],\n","        [ 0.9474, -0.9824,  0.2895,  ..., -0.2528, -1.2321,  0.7708]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.9537,  0.4954,  0.4988,  ...,  0.1846, -1.1320,  0.7217],\n","         [-0.0241, -1.3912,  0.5841,  ...,  1.5418,  0.8539,  1.5992],\n","         [ 2.4853, -0.5447,  1.1543,  ...,  1.1554, -0.6849,  2.5588],\n","         ...,\n","         [ 1.2941,  1.7131,  0.1140,  ..., -0.2789, -0.5021,  0.2753],\n","         [ 2.0512,  0.8055, -0.1841,  ..., -0.0714, -0.2584,  0.0219],\n","         [ 0.9562,  0.3784, -0.1807,  ...,  0.6405, -1.1791, -0.2534]],\n","\n","        [[ 0.8820, -0.8021,  0.9253,  ...,  0.0386, -1.3746,  0.5778],\n","         [-0.0878, -0.0075,  0.1395,  ...,  0.3295, -1.1470,  0.2405],\n","         [-1.5215, -0.3943, -0.2074,  ..., -0.0477, -2.1174,  0.9725],\n","         ...,\n","         [ 0.6849, -0.9777,  0.6682,  ...,  0.3822, -0.2842,  0.5497],\n","         [ 0.6185, -0.8323,  0.6768,  ...,  0.6242,  0.1995,  0.4973],\n","         [ 0.9432, -0.7496,  0.5324,  ...,  0.8479, -0.5743,  0.9701]],\n","\n","        [[ 0.8480, -0.9789, -0.0437,  ...,  0.3835, -0.2080,  0.3639],\n","         [ 2.3620, -1.2221,  0.2051,  ...,  0.6878,  1.3057, -0.0251],\n","         [ 1.2819, -1.4226,  0.8072,  ..., -0.5122,  1.8630,  0.1244],\n","         ...,\n","         [ 1.1845, -0.5917,  0.1407,  ...,  0.0377, -0.1627,  0.5737],\n","         [ 1.1780, -0.2522,  0.0898,  ...,  0.8626, -1.7109,  0.4248],\n","         [ 0.5359, -0.0758, -0.5752,  ...,  1.4914, -0.6416, -0.3463]],\n","\n","        ...,\n","\n","        [[ 0.1609, -1.2956,  0.0086,  ...,  1.1559, -1.7385,  1.0011],\n","         [-0.0545,  0.0609,  0.1550,  ...,  1.0128,  0.6311,  1.4948],\n","         [ 1.6199, -0.5969,  0.7279,  ...,  0.8857,  0.4398,  0.8015],\n","         ...,\n","         [ 0.2473, -0.9688,  0.0243,  ...,  1.2607, -0.3248,  0.9460],\n","         [ 1.0065, -0.5745,  0.0140,  ...,  1.0129, -0.5382,  0.6224],\n","         [ 1.2099, -0.8021, -0.0438,  ...,  0.8559, -0.3131,  0.6657]],\n","\n","        [[-0.6693,  0.1044, -0.1650,  ..., -0.0732, -0.6343,  0.1452],\n","         [-0.6744, -0.1609,  0.3334,  ..., -1.5384,  1.2492,  0.4561],\n","         [-0.5598,  0.1606,  0.3477,  ..., -1.2506, -0.1876, -0.5850],\n","         ...,\n","         [ 0.2061, -0.0406,  0.1438,  ...,  0.0371, -0.8440,  0.5380],\n","         [ 0.5849, -0.1457,  0.9753,  ..., -0.2686, -0.7145,  0.7606],\n","         [-0.3744, -0.6553,  0.7378,  ...,  0.2782, -0.6465,  0.4674]],\n","\n","        [[-0.0151, -0.8009, -0.3213,  ...,  0.3303, -1.0425, -0.2351],\n","         [ 0.7700, -0.2145, -0.2809,  ...,  0.0478,  0.1636, -0.0653],\n","         [-0.2960,  0.9870, -0.4063,  ..., -0.1306, -1.5102,  0.0694],\n","         ...,\n","         [ 0.5540, -0.1215,  0.3553,  ..., -0.2110, -0.6031,  0.2466],\n","         [ 0.3989, -0.1597,  0.3430,  ..., -0.3500, -1.5679,  0.5046],\n","         [ 0.9365, -0.7480,  0.2968,  ...,  0.2495, -0.4459, -0.5345]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.4257,  0.1474,  0.0182,  ..., -0.4571, -0.2745, -0.1326],\n","        [ 0.5086,  0.0749,  0.3589,  ...,  0.5431, -0.2147,  0.7568],\n","        [ 0.4676, -0.1776,  0.4886,  ...,  0.1868, -0.2709, -0.9139],\n","        ...,\n","        [ 0.6753, -0.3168,  0.3064,  ...,  0.3600, -0.6206,  0.7844],\n","        [ 0.0911, -0.4402,  0.4636,  ...,  0.3973,  0.2126, -0.9442],\n","        [ 0.6276, -0.3594,  0.3327,  ...,  0.0886,  0.0959,  0.2689]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.4257,  0.1474,  0.0182,  ..., -0.4571, -0.2745, -0.1326],\n","        [ 0.5086,  0.0749,  0.3589,  ...,  0.5431, -0.2147,  0.7568],\n","        [ 0.4676, -0.1776,  0.4886,  ...,  0.1868, -0.2709, -0.9139],\n","        ...,\n","        [ 0.6753, -0.3168,  0.3064,  ...,  0.3600, -0.6206,  0.7844],\n","        [ 0.0911, -0.4402,  0.4636,  ...,  0.3973,  0.2126, -0.9442],\n","        [ 0.6276, -0.3594,  0.3327,  ...,  0.0886,  0.0959,  0.2689]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.9537,  0.4954,  0.4988,  ...,  0.1846, -1.1320,  0.7217],\n","        [ 0.8820, -0.8021,  0.9253,  ...,  0.0386, -1.3746,  0.5778],\n","        [ 0.8480, -0.9789, -0.0437,  ...,  0.3835, -0.2080,  0.3639],\n","        ...,\n","        [ 0.1609, -1.2956,  0.0086,  ...,  1.1559, -1.7385,  1.0011],\n","        [-0.6693,  0.1044, -0.1650,  ..., -0.0732, -0.6343,  0.1452],\n","        [-0.0151, -0.8009, -0.3213,  ...,  0.3303, -1.0425, -0.2351]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.9942, -0.7052,  0.4833,  ..., -0.0288, -1.8750,  0.7870],\n","         [ 0.4189,  0.0378,  0.7226,  ...,  0.5505, -0.4063, -0.6973],\n","         [ 1.6293,  0.3200,  0.0240,  ...,  0.6713, -1.4244, -1.3571],\n","         ...,\n","         [ 0.7094, -0.2897,  1.1354,  ...,  0.7830, -1.1448,  0.0348],\n","         [ 1.0283, -0.2346,  1.4835,  ...,  0.1385, -1.0094, -0.6701],\n","         [ 0.5551, -1.0841,  0.9890,  ...,  0.7019, -0.5981,  0.3298]],\n","\n","        [[ 0.7835, -1.5137,  0.4187,  ...,  1.3845, -2.0561,  0.5843],\n","         [ 1.0916, -0.7195,  0.3940,  ...,  0.3244, -0.4964, -0.0931],\n","         [ 0.2270, -1.8703, -0.6462,  ...,  0.7271, -0.7582, -0.2045],\n","         ...,\n","         [ 0.2184, -0.1160,  0.2398,  ...,  0.9447, -1.0470,  0.4534],\n","         [ 0.3015, -0.7209,  0.3553,  ...,  0.9909, -1.2273,  1.0238],\n","         [ 0.3393, -1.2131,  0.4385,  ...,  1.0093, -1.1149,  0.8236]],\n","\n","        [[ 0.3916,  0.0292, -0.6256,  ...,  0.4021, -2.0095, -0.9438],\n","         [-0.3933, -0.0834, -0.3024,  ..., -0.6820, -0.3085, -0.1573],\n","         [-0.7677, -1.3592, -0.4996,  ...,  0.6604, -0.3965,  0.1510],\n","         ...,\n","         [ 0.2470,  0.0126, -0.0607,  ...,  0.2050, -0.7382, -0.2982],\n","         [ 0.2820, -0.0297, -0.0750,  ...,  0.2837, -0.1951, -0.3388],\n","         [ 0.0192,  0.3248, -0.2990,  ...,  0.4860,  0.4801, -0.3363]],\n","\n","        ...,\n","\n","        [[ 0.1618, -0.4519,  0.0245,  ..., -0.0111, -1.4347,  0.3327],\n","         [-0.1550, -0.6168,  0.2947,  ..., -0.1133,  0.3524,  1.4733],\n","         [ 0.0154, -0.9936, -0.3593,  ...,  0.3873, -0.0793, -0.4826],\n","         ...,\n","         [ 0.4121, -0.8370, -0.3656,  ...,  0.5606, -1.3163,  0.8065],\n","         [ 0.5665, -0.4589, -0.2557,  ...,  0.8615, -1.5452,  0.4640],\n","         [ 0.2716,  0.5121,  0.3948,  ...,  0.4408, -0.9348,  0.6337]],\n","\n","        [[ 0.6490,  1.9104,  0.0714,  ...,  0.3878, -2.9727,  0.0458],\n","         [-0.0684, -0.0443, -0.7447,  ..., -1.0004, -1.0304, -1.3285],\n","         [-0.2455,  1.4139, -0.3533,  ...,  1.0408, -0.3190, -1.3386],\n","         ...,\n","         [ 0.5405,  0.4491,  0.7852,  ...,  0.2562, -1.6131, -0.0145],\n","         [ 0.2544,  0.7202,  0.9764,  ...,  0.5137, -1.2751, -0.4424],\n","         [ 1.1090,  0.2434,  0.4207,  ...,  0.2969, -0.7735, -0.1854]],\n","\n","        [[ 0.0041, -1.2382,  0.2660,  ..., -0.6152, -0.7262,  0.0778],\n","         [-0.0884, -0.1573,  0.9569,  ...,  0.4992, -0.7091,  0.1999],\n","         [-0.3212, -3.0010,  1.7480,  ..., -0.4004, -1.8039,  0.2112],\n","         ...,\n","         [-0.0090, -1.6937, -0.1068,  ..., -0.5334,  0.2856,  0.2879],\n","         [ 0.3594, -0.7323,  0.4942,  ..., -0.4396, -0.6263,  0.3050],\n","         [ 0.0657, -0.4953,  0.2133,  ..., -0.6599, -0.2102,  0.1754]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.3287,  0.1038, -0.0345,  ..., -0.0312, -0.3437,  0.9535],\n","        [ 0.8612, -0.0223,  0.1588,  ...,  0.2487,  0.3453,  0.9166],\n","        [-0.4861, -0.2137,  0.3758,  ...,  0.5439,  0.0352,  0.3249],\n","        ...,\n","        [ 0.2000, -0.0232,  0.3445,  ...,  0.4235, -0.0771,  0.3506],\n","        [ 0.1226, -0.1395, -0.0967,  ...,  0.2580, -0.1002, -0.2502],\n","        [-0.5153,  0.1440,  0.2146,  ..., -0.1408, -0.0710, -0.7744]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[-0.3287,  0.1038, -0.0345,  ..., -0.0312, -0.3437,  0.9535],\n","        [ 0.8612, -0.0223,  0.1588,  ...,  0.2487,  0.3453,  0.9166],\n","        [-0.4861, -0.2137,  0.3758,  ...,  0.5439,  0.0352,  0.3249],\n","        ...,\n","        [ 0.2000, -0.0232,  0.3445,  ...,  0.4235, -0.0771,  0.3506],\n","        [ 0.1226, -0.1395, -0.0967,  ...,  0.2580, -0.1002, -0.2502],\n","        [-0.5153,  0.1440,  0.2146,  ..., -0.1408, -0.0710, -0.7744]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.9942, -0.7052,  0.4833,  ..., -0.0288, -1.8750,  0.7870],\n","        [ 0.7835, -1.5137,  0.4187,  ...,  1.3845, -2.0561,  0.5843],\n","        [ 0.3916,  0.0292, -0.6256,  ...,  0.4021, -2.0095, -0.9438],\n","        ...,\n","        [ 0.1618, -0.4519,  0.0245,  ..., -0.0111, -1.4347,  0.3327],\n","        [ 0.6490,  1.9104,  0.0714,  ...,  0.3878, -2.9727,  0.0458],\n","        [ 0.0041, -1.2382,  0.2660,  ..., -0.6152, -0.7262,  0.0778]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.8785e-01, -8.7537e-01, -5.0719e-01,  ..., -3.0213e-01,\n","          -1.3626e+00, -3.8947e-01],\n","         [ 1.2444e-01, -1.1611e+00, -9.9781e-01,  ..., -2.0539e-01,\n","          -1.1834e-01, -1.2114e+00],\n","         [-3.3942e-01, -5.0780e-01,  1.8807e-01,  ...,  9.0682e-01,\n","           1.6526e-01, -1.8560e+00],\n","         ...,\n","         [ 8.9267e-02, -3.8113e-01, -4.4553e-01,  ...,  3.6632e-01,\n","          -1.4059e+00, -1.1158e-01],\n","         [ 1.8270e-01, -1.2447e-01, -5.2009e-01,  ...,  3.2444e-01,\n","          -1.0154e+00,  5.3594e-02],\n","         [-3.3546e-01,  4.8534e-01, -5.3769e-01,  ...,  8.7958e-01,\n","          -1.5515e+00, -3.3249e-02]],\n","\n","        [[ 3.5821e-01, -1.2726e+00, -5.1204e-01,  ..., -6.2131e-01,\n","          -1.0534e+00,  3.8030e-01],\n","         [ 1.5138e+00, -5.8070e-01, -1.1977e-01,  ..., -4.8373e-01,\n","           1.1294e+00,  2.8861e-01],\n","         [-1.0809e-01, -2.0327e+00, -8.1822e-02,  ...,  7.1523e-01,\n","           5.6275e-02,  1.3177e+00],\n","         ...,\n","         [ 4.2415e-01, -4.8348e-01, -4.5324e-01,  ..., -5.5263e-01,\n","           1.5544e-01,  2.5925e-01],\n","         [ 2.6715e-01, -1.1057e-01,  1.7222e-01,  ..., -2.8698e-01,\n","           4.4932e-01,  2.0694e-01],\n","         [ 5.4950e-01,  5.1711e-01,  9.8550e-02,  ..., -9.9032e-02,\n","          -5.5029e-01,  3.9358e-01]],\n","\n","        [[ 1.4074e+00, -9.1888e-01,  1.4708e+00,  ...,  3.7486e-01,\n","          -1.0322e+00,  2.8517e-01],\n","         [ 8.2760e-02, -1.5506e+00,  1.7971e+00,  ...,  3.6303e-01,\n","           4.6357e-01,  2.6508e-01],\n","         [ 1.0409e+00, -1.4110e+00,  4.7489e-01,  ...,  9.9239e-01,\n","          -6.0243e-01,  5.4189e-01],\n","         ...,\n","         [ 8.0519e-01,  2.4003e-01,  1.4213e+00,  ..., -7.4161e-02,\n","          -1.8102e+00,  8.1522e-04],\n","         [ 1.6861e+00, -1.1969e+00,  1.1253e+00,  ...,  1.3978e-01,\n","          -1.5079e+00,  7.4021e-01],\n","         [ 1.7101e+00, -1.0187e+00,  1.3808e+00,  ...,  2.0484e-01,\n","          -1.3198e+00,  3.7033e-01]],\n","\n","        ...,\n","\n","        [[ 7.1622e-01, -2.4961e-01, -3.1787e-01,  ...,  7.3382e-02,\n","          -1.0113e+00, -3.2544e-01],\n","         [ 4.0148e-01, -1.1785e-01, -4.4197e-01,  ..., -1.0789e+00,\n","           1.9858e+00, -6.7739e-01],\n","         [-3.8218e-01,  1.1696e+00, -8.2743e-01,  ..., -4.4594e-01,\n","           1.6413e+00, -4.1048e-01],\n","         ...,\n","         [ 6.7296e-01, -2.2531e-01,  7.0236e-01,  ..., -4.5330e-01,\n","          -2.3549e-01, -3.1938e-01],\n","         [ 1.6855e+00, -1.7283e-01,  2.1300e-01,  ...,  3.0580e-01,\n","           4.7154e-02, -3.8019e-02],\n","         [ 8.6718e-01,  6.1069e-02,  3.9853e-01,  ..., -5.5183e-02,\n","           1.7229e-01, -1.6842e-01]],\n","\n","        [[ 2.4612e-02, -9.7403e-02, -5.3381e-01,  ...,  6.6865e-01,\n","          -7.5214e-01, -1.0263e-01],\n","         [ 5.2274e-02, -1.9472e+00,  1.2149e-01,  ...,  5.5885e-01,\n","           1.4872e-02, -3.9873e-01],\n","         [ 1.3300e+00, -3.6661e-01, -6.1017e-01,  ...,  2.5410e-01,\n","           3.2669e-01, -7.6088e-01],\n","         ...,\n","         [ 4.5790e-01,  2.6322e-01, -2.9080e-01,  ...,  5.1932e-01,\n","          -3.0296e-01, -2.9672e-01],\n","         [ 7.6228e-01, -5.9947e-01, -3.8201e-01,  ...,  6.0705e-01,\n","          -8.6240e-01,  1.9366e-01],\n","         [ 1.7957e+00, -7.8543e-01,  1.2283e-01,  ...,  7.0150e-02,\n","          -5.0509e-01,  6.9587e-01]],\n","\n","        [[-7.0034e-01, -8.3250e-01,  6.2209e-01,  ..., -1.0619e-01,\n","          -6.4981e-01, -3.3241e-01],\n","         [ 3.2737e-02, -2.7236e-01, -3.2794e-01,  ..., -1.4945e-01,\n","           8.3783e-01, -3.7546e-01],\n","         [-7.5782e-01,  2.4452e-01,  1.3003e-01,  ...,  6.6910e-01,\n","          -1.0096e-01, -7.0297e-01],\n","         ...,\n","         [-2.0374e-01, -8.1783e-01,  3.1804e-01,  ...,  1.1543e-01,\n","          -3.1124e-01, -3.3922e-01],\n","         [ 3.4129e-01, -8.2280e-01,  3.5561e-01,  ..., -5.8481e-02,\n","          -5.3980e-01, -1.9793e-01],\n","         [ 9.6998e-01, -6.6143e-01,  1.2449e-02,  ..., -3.2642e-01,\n","          -1.5848e-01, -9.3204e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0298, -0.3906, -0.3064,  ...,  0.7586,  0.4099, -0.9877],\n","        [ 0.2745,  0.2081,  0.2739,  ...,  0.2590, -0.2792, -0.9778],\n","        [ 0.4580, -0.1175,  0.0831,  ...,  0.4301, -0.2877, -0.8119],\n","        ...,\n","        [ 0.2889,  0.4202,  0.1877,  ...,  0.2008, -0.6261, -0.8382],\n","        [ 0.6812, -0.0534, -0.1125,  ...,  0.1369,  0.0629,  0.7390],\n","        [ 0.4022, -0.0853,  0.3772,  ...,  0.0607, -0.3119, -0.9319]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.0298, -0.3906, -0.3064,  ...,  0.7586,  0.4099, -0.9877],\n","        [ 0.2745,  0.2081,  0.2739,  ...,  0.2590, -0.2792, -0.9778],\n","        [ 0.4580, -0.1175,  0.0831,  ...,  0.4301, -0.2877, -0.8119],\n","        ...,\n","        [ 0.2889,  0.4202,  0.1877,  ...,  0.2008, -0.6261, -0.8382],\n","        [ 0.6812, -0.0534, -0.1125,  ...,  0.1369,  0.0629,  0.7390],\n","        [ 0.4022, -0.0853,  0.3772,  ...,  0.0607, -0.3119, -0.9319]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.4879, -0.8754, -0.5072,  ..., -0.3021, -1.3626, -0.3895],\n","        [ 0.3582, -1.2726, -0.5120,  ..., -0.6213, -1.0534,  0.3803],\n","        [ 1.4074, -0.9189,  1.4708,  ...,  0.3749, -1.0322,  0.2852],\n","        ...,\n","        [ 0.7162, -0.2496, -0.3179,  ...,  0.0734, -1.0113, -0.3254],\n","        [ 0.0246, -0.0974, -0.5338,  ...,  0.6686, -0.7521, -0.1026],\n","        [-0.7003, -0.8325,  0.6221,  ..., -0.1062, -0.6498, -0.3324]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2384, -0.2021, -0.0034,  ...,  0.1331, -1.1468,  0.4006],\n","         [ 1.1420, -0.1278, -0.2611,  ..., -0.2296, -0.8979,  0.0340],\n","         [-0.2666, -0.0149,  0.1087,  ...,  0.5441, -0.4319, -0.1415],\n","         ...,\n","         [ 0.4019,  0.2277,  0.6649,  ...,  0.2960, -0.9482,  0.9376],\n","         [ 0.7178, -0.1313,  0.5819,  ...,  0.0308, -1.4254,  0.9113],\n","         [ 0.7109,  0.4660,  0.8589,  ...,  0.4798, -1.2969,  0.7802]],\n","\n","        [[ 0.4084, -0.4089, -1.0051,  ..., -0.1837, -0.8491,  0.1556],\n","         [ 0.0324, -1.5113, -1.0825,  ..., -0.2045,  0.0268,  0.6900],\n","         [ 0.5221, -0.8198, -0.5033,  ..., -0.0282, -0.3216, -0.0925],\n","         ...,\n","         [ 0.5720, -0.3486,  0.0892,  ...,  0.2454, -0.1279,  0.2891],\n","         [ 0.8641, -0.8101,  0.4417,  ..., -0.0342,  0.2077,  0.8390],\n","         [ 0.0885, -0.2794, -0.0451,  ...,  0.5588, -0.6768, -1.2435]],\n","\n","        [[ 0.2767, -1.5893, -0.0699,  ...,  0.0467, -0.9896, -0.2697],\n","         [-0.3063,  0.3518,  1.7889,  ..., -0.4841, -0.7747, -0.0329],\n","         [-0.6840, -0.8720,  1.1921,  ...,  0.0221, -0.8339,  0.1251],\n","         ...,\n","         [ 0.0112, -0.2283,  0.1140,  ...,  0.6865,  0.3239, -0.5297],\n","         [ 0.8581, -0.0347,  0.4819,  ...,  0.2865, -0.2092, -0.0983],\n","         [ 0.8855,  0.4505,  0.6375,  ..., -0.1328,  0.2854, -0.5492]],\n","\n","        ...,\n","\n","        [[ 0.0084,  0.0244, -0.8644,  ...,  0.7609, -2.0885,  0.4910],\n","         [-0.4758, -0.8866, -1.0055,  ...,  0.8137,  0.3444,  0.6330],\n","         [-1.1595,  0.2289, -0.3241,  ...,  0.9339, -0.9842,  1.1862],\n","         ...,\n","         [ 0.3340,  0.0568,  0.2830,  ...,  1.0504, -1.0145,  1.3784],\n","         [ 0.2098, -0.4188, -0.2472,  ...,  0.4612, -1.2353,  1.0248],\n","         [ 0.6180,  0.4500, -0.4870,  ...,  0.5244, -1.1950,  0.8502]],\n","\n","        [[ 0.4733, -0.4477, -0.7616,  ...,  0.7184, -1.1401,  0.4488],\n","         [-0.1275, -0.9675, -0.1313,  ...,  0.1308, -0.7767,  1.5078],\n","         [ 0.4874,  0.4789,  0.6470,  ...,  0.4595, -0.4127,  0.6108],\n","         ...,\n","         [ 1.3070, -0.6540,  0.0088,  ...,  0.8324, -0.8837,  0.5857],\n","         [ 1.5264, -0.2363,  0.2051,  ...,  0.6575, -0.7985,  0.3710],\n","         [ 1.8488, -0.3821,  0.6462,  ...,  0.3953, -0.8675, -0.0692]],\n","\n","        [[ 0.6505, -0.5932, -0.6472,  ...,  1.3425, -0.9747, -0.2285],\n","         [ 1.8906,  0.0427,  0.8867,  ...,  1.4128, -0.8451,  0.2721],\n","         [ 0.9393,  1.0232, -0.6161,  ...,  0.8068, -0.1490,  0.5231],\n","         ...,\n","         [ 0.3350,  0.3203,  0.4880,  ...,  0.2125,  0.0255, -0.0083],\n","         [ 0.6520,  0.8271,  0.0815,  ...,  0.8968,  0.5822, -0.3278],\n","         [ 0.9543,  0.9321,  0.4491,  ...,  1.1453, -0.0962, -0.1141]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.3610,  0.0572,  0.1240,  ...,  0.6302, -0.3779,  0.9155],\n","        [ 0.3999, -0.3781,  0.1582,  ...,  0.1715,  0.5262, -0.0416],\n","        [ 0.8099,  0.0278,  0.2278,  ...,  0.0685,  0.3638,  0.0467],\n","        ...,\n","        [ 0.7399, -0.1693,  0.7574,  ...,  0.6881, -0.1063, -0.5038],\n","        [ 0.3820, -0.0434,  0.1531,  ...,  0.2070, -0.1791,  0.0134],\n","        [ 0.5449, -0.7647, -0.2866,  ..., -0.6990,  0.5781,  0.7297]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.3610,  0.0572,  0.1240,  ...,  0.6302, -0.3779,  0.9155],\n","        [ 0.3999, -0.3781,  0.1582,  ...,  0.1715,  0.5262, -0.0416],\n","        [ 0.8099,  0.0278,  0.2278,  ...,  0.0685,  0.3638,  0.0467],\n","        ...,\n","        [ 0.7399, -0.1693,  0.7574,  ...,  0.6881, -0.1063, -0.5038],\n","        [ 0.3820, -0.0434,  0.1531,  ...,  0.2070, -0.1791,  0.0134],\n","        [ 0.5449, -0.7647, -0.2866,  ..., -0.6990,  0.5781,  0.7297]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.2384, -0.2021, -0.0034,  ...,  0.1331, -1.1468,  0.4006],\n","        [ 0.4084, -0.4089, -1.0051,  ..., -0.1837, -0.8491,  0.1556],\n","        [ 0.2767, -1.5893, -0.0699,  ...,  0.0467, -0.9896, -0.2697],\n","        ...,\n","        [ 0.0084,  0.0244, -0.8644,  ...,  0.7609, -2.0885,  0.4910],\n","        [ 0.4733, -0.4477, -0.7616,  ...,  0.7184, -1.1401,  0.4488],\n","        [ 0.6505, -0.5932, -0.6472,  ...,  1.3425, -0.9747, -0.2285]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","Step : 10, Avg Loss : 0.6704\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 6.3816e-02, -2.3589e-01, -8.4338e-01,  ...,  6.1660e-01,\n","          -1.4610e+00,  6.5779e-01],\n","         [-9.2623e-01, -1.2432e-01,  2.1579e-01,  ...,  3.6124e-01,\n","          -4.6712e-01,  5.2698e-01],\n","         [-1.9859e-01, -1.9277e-01, -8.6755e-01,  ...,  1.2071e+00,\n","          -5.5044e-01, -9.8967e-01],\n","         ...,\n","         [ 1.0719e+00, -9.5872e-01,  3.6304e-01,  ...,  3.6023e-01,\n","          -2.1148e+00,  9.2582e-01],\n","         [ 7.7132e-01, -5.8038e-01,  2.0918e-01,  ...,  4.0334e-01,\n","          -2.2625e+00,  6.7021e-01],\n","         [ 6.3284e-01, -3.2881e-01,  1.3518e-01,  ...,  2.9369e-01,\n","          -1.7251e+00,  4.8900e-01]],\n","\n","        [[-7.2848e-01,  5.7395e-02,  2.7158e-01,  ..., -9.5842e-01,\n","          -1.0965e+00, -2.3418e-03],\n","         [-6.3311e-01, -9.0510e-01,  8.9829e-01,  ..., -1.3017e-01,\n","          -6.2833e-01, -1.6058e-01],\n","         [ 2.0897e-01, -2.0625e+00, -2.7913e-01,  ..., -2.9808e-01,\n","          -5.4142e-01, -1.1201e-01],\n","         ...,\n","         [-6.7946e-01, -7.5726e-01,  5.6995e-01,  ...,  7.9528e-02,\n","          -5.2020e-01,  3.6792e-01],\n","         [-5.4336e-01, -5.1515e-01,  8.4360e-01,  ...,  1.9782e-01,\n","          -2.5172e-01,  7.3486e-01],\n","         [-6.0704e-01, -7.9663e-01,  3.2315e-01,  ...,  3.3143e-01,\n","          -3.4076e-01,  4.2152e-02]],\n","\n","        [[-9.5997e-03,  1.9717e-01,  8.3968e-02,  ..., -4.9077e-02,\n","          -7.3229e-01,  8.7546e-01],\n","         [ 9.8445e-01, -4.5518e-02,  3.3187e-01,  ...,  8.1260e-01,\n","           9.1340e-01,  6.6568e-01],\n","         [ 9.8389e-01, -1.2107e+00,  6.7160e-01,  ...,  1.8195e+00,\n","           1.4604e+00, -8.2387e-01],\n","         ...,\n","         [ 1.0229e+00, -8.9764e-01,  8.5973e-01,  ..., -7.7018e-02,\n","          -1.7844e+00,  3.8542e-01],\n","         [ 6.7465e-01,  8.4818e-02, -6.6317e-02,  ...,  6.2691e-01,\n","          -1.2047e+00,  5.7058e-01],\n","         [ 7.8801e-01, -2.6015e-01,  2.9692e-01,  ...,  1.0738e+00,\n","          -6.2128e-01,  3.5269e-02]],\n","\n","        ...,\n","\n","        [[-4.0617e-01,  2.7203e-01,  6.4241e-01,  ..., -2.7586e-01,\n","          -1.7738e+00,  9.2429e-04],\n","         [-8.9900e-01,  8.4219e-01,  7.4916e-01,  ..., -1.0079e+00,\n","           1.6122e+00,  8.2885e-01],\n","         [ 1.8519e-01,  8.9547e-01,  1.4991e+00,  ...,  2.2502e-01,\n","           3.8062e-01,  4.9853e-02],\n","         ...,\n","         [ 6.2336e-01,  8.9947e-01,  4.0987e-01,  ...,  3.3533e-03,\n","          -7.5714e-01,  2.2981e-01],\n","         [ 7.9923e-01,  5.6783e-01,  7.7305e-01,  ...,  2.7615e-01,\n","          -3.4141e-01,  4.1134e-01],\n","         [ 1.3104e+00,  8.1758e-01, -4.7307e-02,  ..., -3.5093e-01,\n","          -3.5515e-01,  3.5779e-01]],\n","\n","        [[ 3.5027e-01, -2.6602e-01, -9.7116e-01,  ...,  1.0998e-01,\n","          -2.2608e+00,  4.9219e-02],\n","         [-6.7674e-01, -1.1425e+00, -7.5427e-01,  ..., -1.0153e+00,\n","           4.0216e-02,  1.0899e+00],\n","         [ 2.8307e-01,  1.1473e+00, -3.3644e-01,  ..., -4.1233e-01,\n","          -8.4946e-02, -3.1386e-02],\n","         ...,\n","         [ 1.4526e+00, -9.9463e-01, -8.0080e-01,  ...,  5.2893e-01,\n","          -1.2605e+00, -1.4050e-01],\n","         [ 2.0350e+00, -1.1662e+00, -8.5919e-01,  ...,  5.9497e-02,\n","          -1.2148e+00,  7.4249e-01],\n","         [ 1.9658e+00, -1.8383e+00, -3.6842e-01,  ..., -4.3889e-02,\n","          -9.8905e-01,  5.4301e-01]],\n","\n","        [[ 5.3300e-01, -1.2520e+00,  1.0239e-01,  ...,  7.1353e-01,\n","          -1.0727e+00,  2.7657e-01],\n","         [-4.5976e-01,  1.3653e+00, -3.3217e-02,  ...,  2.0941e-01,\n","           1.0200e+00, -6.9871e-01],\n","         [-2.3075e+00, -7.4087e-01, -4.1551e-01,  ...,  8.8980e-01,\n","          -1.0828e+00, -2.8929e-01],\n","         ...,\n","         [ 8.1475e-01, -6.7666e-01,  2.4268e-01,  ...,  1.1794e+00,\n","          -5.0829e-01,  1.1056e+00],\n","         [ 1.1199e+00, -3.1486e-01,  8.5015e-01,  ...,  8.5418e-01,\n","          -3.9058e-01,  1.0056e+00],\n","         [ 2.3369e+00, -1.7289e-01, -5.7568e-02,  ...,  4.2208e-01,\n","          -4.4529e-01,  1.4855e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.8051, -0.4036,  0.0912,  ...,  0.0113,  0.2118,  0.9786],\n","        [ 0.3820, -0.2701,  0.3160,  ...,  0.6681, -0.8132, -0.8539],\n","        [ 0.7761,  0.4034,  0.5979,  ...,  0.5374, -0.3602, -0.4796],\n","        ...,\n","        [ 0.5050, -0.0983,  0.2177,  ...,  0.2460,  0.2973, -0.8112],\n","        [ 0.1064,  0.2718, -0.0039,  ...,  0.0858,  0.4435,  0.0171],\n","        [ 0.6495, -0.0702,  0.0907,  ...,  0.2985, -0.1305,  0.0434]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.8051, -0.4036,  0.0912,  ...,  0.0113,  0.2118,  0.9786],\n","        [ 0.3820, -0.2701,  0.3160,  ...,  0.6681, -0.8132, -0.8539],\n","        [ 0.7761,  0.4034,  0.5979,  ...,  0.5374, -0.3602, -0.4796],\n","        ...,\n","        [ 0.5050, -0.0983,  0.2177,  ...,  0.2460,  0.2973, -0.8112],\n","        [ 0.1064,  0.2718, -0.0039,  ...,  0.0858,  0.4435,  0.0171],\n","        [ 0.6495, -0.0702,  0.0907,  ...,  0.2985, -0.1305,  0.0434]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 6.3816e-02, -2.3589e-01, -8.4338e-01,  ...,  6.1660e-01,\n","         -1.4610e+00,  6.5779e-01],\n","        [-7.2848e-01,  5.7395e-02,  2.7158e-01,  ..., -9.5842e-01,\n","         -1.0965e+00, -2.3418e-03],\n","        [-9.5997e-03,  1.9717e-01,  8.3968e-02,  ..., -4.9077e-02,\n","         -7.3229e-01,  8.7546e-01],\n","        ...,\n","        [-4.0617e-01,  2.7203e-01,  6.4241e-01,  ..., -2.7586e-01,\n","         -1.7738e+00,  9.2429e-04],\n","        [ 3.5027e-01, -2.6602e-01, -9.7116e-01,  ...,  1.0998e-01,\n","         -2.2608e+00,  4.9219e-02],\n","        [ 5.3300e-01, -1.2520e+00,  1.0239e-01,  ...,  7.1353e-01,\n","         -1.0727e+00,  2.7657e-01]], device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.3343, -1.1583, -0.2446,  ..., -0.7357, -1.0399,  0.8997],\n","         [ 0.7960, -2.4075,  0.0029,  ..., -0.5014,  0.5037, -0.9053],\n","         [ 0.7445, -1.6000, -0.5859,  ...,  0.2370, -1.0206,  0.3937],\n","         ...,\n","         [ 1.5557, -1.2254,  0.3346,  ...,  1.0255, -0.0613,  1.0002],\n","         [ 1.8312, -0.7013,  0.0586,  ...,  0.6204, -0.3348,  0.6076],\n","         [ 1.6509, -0.2953,  0.0503,  ...,  0.1867, -0.1761,  0.0598]],\n","\n","        [[ 1.5308,  0.1457,  0.6839,  ...,  0.3257, -2.5075,  0.3346],\n","         [ 0.1283, -0.9551,  0.4702,  ...,  1.0195, -0.8300,  0.4855],\n","         [ 0.1816, -0.0890,  0.0593,  ...,  0.0358, -1.3276,  0.4579],\n","         ...,\n","         [ 1.9265,  1.4072,  0.7287,  ...,  0.8111, -1.9124,  0.4219],\n","         [ 1.6815,  0.4351,  0.9323,  ...,  0.8720, -1.7195,  0.4762],\n","         [ 1.9346,  0.6148,  0.7775,  ...,  1.0111, -1.5316,  0.4534]],\n","\n","        [[ 0.1837, -0.2338,  0.0552,  ..., -0.4833, -1.1047,  0.6603],\n","         [-0.2721,  0.9411,  0.5602,  ..., -0.2615,  1.3924,  0.5360],\n","         [-0.3232,  0.7041, -0.1128,  ...,  1.2202, -0.2309, -0.4644],\n","         ...,\n","         [ 0.6603, -1.8327,  0.6098,  ...,  0.5385, -0.8448,  1.0188],\n","         [ 0.1016, -0.9064,  0.3732,  ...,  0.6598,  0.0132,  1.1759],\n","         [ 0.0174, -1.1384,  0.2184,  ...,  0.5208, -0.0729,  1.0326]],\n","\n","        ...,\n","\n","        [[ 1.6403,  0.3912, -0.3838,  ...,  0.0749, -1.8174, -0.5916],\n","         [ 0.1836,  0.0729,  0.4767,  ..., -0.5578,  0.2630,  0.8414],\n","         [ 1.3092,  0.4932,  0.6068,  ...,  0.3458, -0.5025,  0.6447],\n","         ...,\n","         [ 0.3819,  0.6927, -0.8092,  ...,  0.9162, -1.8376, -0.0312],\n","         [ 1.2349,  0.0905,  0.8827,  ...,  0.4275, -1.8187,  1.6030],\n","         [ 1.2787,  0.2278,  0.7281,  ...,  0.2628, -2.1115,  1.0979]],\n","\n","        [[ 0.0327, -1.1526,  0.2297,  ..., -0.2350, -0.8690,  0.0053],\n","         [ 0.8631, -1.3586,  0.6501,  ...,  0.9548, -0.0398,  0.2898],\n","         [ 0.5880, -1.0837, -0.5013,  ...,  0.9193,  0.1178, -0.5594],\n","         ...,\n","         [ 1.1849, -0.9103,  0.9778,  ...,  0.2000, -0.3571,  1.1241],\n","         [ 0.3091, -0.4472,  0.1072,  ..., -0.1626, -0.2137, -0.5314],\n","         [ 0.2712,  0.3584,  0.1388,  ...,  0.2441, -0.2093,  0.1695]],\n","\n","        [[-0.0926,  0.2159, -0.9867,  ..., -0.6243, -0.4330,  0.4956],\n","         [ 0.9436,  0.6940,  0.2761,  ...,  0.0999,  0.6109,  0.9948],\n","         [ 0.4718, -0.0788,  0.0810,  ..., -0.2818,  0.6721, -0.7423],\n","         ...,\n","         [ 0.4650,  0.7849, -0.9705,  ...,  0.5710,  0.2246,  0.8487],\n","         [ 0.6118,  0.5520, -0.8565,  ...,  1.4636, -0.0973,  0.7059],\n","         [ 1.1171,  0.7905, -0.1034,  ...,  0.5035,  0.4336,  0.3146]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2699,  0.4754,  0.2337,  ...,  0.5744,  0.1589, -0.3879],\n","        [ 0.6281, -0.3281,  0.4202,  ...,  0.5697, -0.3040,  0.9282],\n","        [ 0.2601, -0.5930,  0.3280,  ...,  0.3533, -0.0156, -0.4184],\n","        ...,\n","        [ 0.3694, -0.2154, -0.0324,  ..., -0.2580,  0.2041,  0.7640],\n","        [ 0.6008, -0.3856,  0.0970,  ..., -0.2956, -0.4417,  0.5449],\n","        [ 0.6326, -0.8146,  0.5153,  ...,  0.2543,  0.0406, -0.1988]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.2699,  0.4754,  0.2337,  ...,  0.5744,  0.1589, -0.3879],\n","        [ 0.6281, -0.3281,  0.4202,  ...,  0.5697, -0.3040,  0.9282],\n","        [ 0.2601, -0.5930,  0.3280,  ...,  0.3533, -0.0156, -0.4184],\n","        ...,\n","        [ 0.3694, -0.2154, -0.0324,  ..., -0.2580,  0.2041,  0.7640],\n","        [ 0.6008, -0.3856,  0.0970,  ..., -0.2956, -0.4417,  0.5449],\n","        [ 0.6326, -0.8146,  0.5153,  ...,  0.2543,  0.0406, -0.1988]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 1.3343, -1.1583, -0.2446,  ..., -0.7357, -1.0399,  0.8997],\n","        [ 1.5308,  0.1457,  0.6839,  ...,  0.3257, -2.5075,  0.3346],\n","        [ 0.1837, -0.2338,  0.0552,  ..., -0.4833, -1.1047,  0.6603],\n","        ...,\n","        [ 1.6403,  0.3912, -0.3838,  ...,  0.0749, -1.8174, -0.5916],\n","        [ 0.0327, -1.1526,  0.2297,  ..., -0.2350, -0.8690,  0.0053],\n","        [-0.0926,  0.2159, -0.9867,  ..., -0.6243, -0.4330,  0.4956]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0706, -0.2736, -0.0214,  ..., -0.3339, -0.0456,  0.4121],\n","         [-0.5712,  1.2848, -0.3112,  ..., -0.8774,  0.3680, -0.1646],\n","         [-0.9634,  1.6092, -0.1341,  ..., -0.5846, -1.4568,  0.2965],\n","         ...,\n","         [-0.5966,  0.3470,  0.0529,  ..., -0.2676,  0.9313, -0.1904],\n","         [-0.1772, -0.3936,  0.3420,  ..., -0.1215,  0.4713, -0.4080],\n","         [ 0.1718, -0.8343, -0.4784,  ..., -0.1584,  0.7148,  0.0448]],\n","\n","        [[ 1.0316,  0.2795, -0.3319,  ..., -0.2442, -1.6231,  0.5612],\n","         [ 0.5879,  0.5558,  0.8295,  ..., -0.3863,  0.0713, -0.2263],\n","         [-0.3667,  0.5701,  0.5836,  ...,  1.6035,  0.1389, -0.4981],\n","         ...,\n","         [ 0.9762,  0.7795,  0.6024,  ...,  0.0889, -0.7322,  0.3531],\n","         [ 1.0168,  0.4405,  0.9061,  ..., -0.0567, -0.6273,  0.0911],\n","         [ 0.9516,  0.2159,  0.6923,  ...,  0.1241, -0.6364,  0.0925]],\n","\n","        [[ 0.1840, -0.9855,  0.3293,  ...,  0.5227, -0.9471,  0.1708],\n","         [-0.8151, -1.0521, -0.4750,  ...,  0.2348, -0.0647,  0.1173],\n","         [ 0.8669, -0.6569,  0.7471,  ...,  0.8872,  0.1206,  0.1401],\n","         ...,\n","         [ 0.9781, -1.0630,  0.2004,  ...,  0.5721, -0.5896,  0.3039],\n","         [ 1.2292, -1.0244,  0.2468,  ...,  0.5298, -1.0649,  0.4690],\n","         [ 0.8828, -1.6970, -0.0795,  ..., -0.0976, -1.8141,  0.6003]],\n","\n","        ...,\n","\n","        [[ 0.3252,  0.8160, -0.5162,  ...,  0.8647, -1.1488,  0.0623],\n","         [ 0.7846,  0.1801,  0.2055,  ...,  0.1794,  0.1151,  0.5209],\n","         [ 0.6689, -1.1528,  1.4191,  ..., -0.0184, -0.2621,  0.2306],\n","         ...,\n","         [ 0.6922,  1.1394, -0.0387,  ...,  0.5045, -0.1897,  0.0678],\n","         [ 0.3636,  1.3731,  0.4609,  ...,  0.4965, -0.0917, -0.1265],\n","         [ 1.2156,  2.0658, -0.1896,  ...,  0.0210, -0.6452, -0.2051]],\n","\n","        [[-0.1623, -0.3969, -0.0408,  ..., -0.5293, -0.6487, -0.2625],\n","         [-0.1583,  0.3172, -0.0539,  ..., -0.0630,  0.0700,  0.3471],\n","         [-0.8286,  1.0601, -0.2690,  ...,  0.8149,  0.2552,  0.6706],\n","         ...,\n","         [ 0.4539,  0.9754, -0.2521,  ..., -0.5156, -0.3475, -0.3321],\n","         [ 0.4940,  0.3435, -0.0809,  ..., -0.0099,  0.2893, -0.0807],\n","         [ 0.1307,  0.1526,  0.4348,  ...,  0.0714, -0.0309, -0.4203]],\n","\n","        [[ 0.6090, -1.2619,  0.1490,  ...,  0.1100, -1.0533,  0.6148],\n","         [ 0.4425, -1.7465,  0.3507,  ...,  1.2340, -1.8275,  0.2270],\n","         [ 0.8788, -1.9575, -0.1270,  ...,  1.4690,  0.3241,  0.0863],\n","         ...,\n","         [ 1.2578, -0.8901, -1.3376,  ...,  1.1253, -0.7332,  0.0396],\n","         [ 1.2091, -1.3843, -0.3252,  ...,  0.6517, -0.8706, -0.3228],\n","         [ 1.6497, -1.5500, -0.2191,  ...,  0.2565, -1.4776,  0.2885]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.7774, -0.2322,  0.7204,  ...,  0.4979,  0.2803, -0.3634],\n","        [ 0.1959, -0.3125,  0.4521,  ...,  0.3504, -0.0658,  0.3808],\n","        [ 0.7032,  0.0093,  0.0476,  ..., -0.3881, -0.4396,  0.7790],\n","        ...,\n","        [ 0.7207, -0.4941,  0.6025,  ..., -0.3271, -0.0236,  0.9429],\n","        [ 0.5579, -0.6980,  0.5212,  ...,  0.3402, -0.4086, -0.3835],\n","        [ 0.8182, -0.3409,  0.4621,  ..., -0.2340,  0.1471,  0.6608]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.7774, -0.2322,  0.7204,  ...,  0.4979,  0.2803, -0.3634],\n","        [ 0.1959, -0.3125,  0.4521,  ...,  0.3504, -0.0658,  0.3808],\n","        [ 0.7032,  0.0093,  0.0476,  ..., -0.3881, -0.4396,  0.7790],\n","        ...,\n","        [ 0.7207, -0.4941,  0.6025,  ..., -0.3271, -0.0236,  0.9429],\n","        [ 0.5579, -0.6980,  0.5212,  ...,  0.3402, -0.4086, -0.3835],\n","        [ 0.8182, -0.3409,  0.4621,  ..., -0.2340,  0.1471,  0.6608]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-0.0706, -0.2736, -0.0214,  ..., -0.3339, -0.0456,  0.4121],\n","        [ 1.0316,  0.2795, -0.3319,  ..., -0.2442, -1.6231,  0.5612],\n","        [ 0.1840, -0.9855,  0.3293,  ...,  0.5227, -0.9471,  0.1708],\n","        ...,\n","        [ 0.3252,  0.8160, -0.5162,  ...,  0.8647, -1.1488,  0.0623],\n","        [-0.1623, -0.3969, -0.0408,  ..., -0.5293, -0.6487, -0.2625],\n","        [ 0.6090, -1.2619,  0.1490,  ...,  0.1100, -1.0533,  0.6148]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4064,  0.9055, -0.0691,  ...,  0.1485, -1.1535,  1.0636],\n","         [-0.2235, -0.1227,  0.1095,  ..., -0.5940,  0.0173,  0.0411],\n","         [ 0.1443, -0.2835,  1.3713,  ...,  1.2066,  0.8607,  0.4739],\n","         ...,\n","         [ 1.2493,  0.3141,  2.1258,  ...,  0.1802, -0.4904,  0.7834],\n","         [ 0.2579, -0.9296,  1.2209,  ...,  0.3049, -1.2345,  1.7023],\n","         [ 0.7834,  0.3310,  1.0095,  ...,  0.1668, -0.2939,  1.2956]],\n","\n","        [[ 0.4853, -0.7004, -0.3985,  ...,  1.1247, -1.3340,  1.1334],\n","         [-0.7983, -0.6968,  0.2442,  ...,  0.7045, -0.2710,  0.1193],\n","         [ 1.0266, -2.2317,  0.1430,  ...,  0.0621, -1.5935,  0.6679],\n","         ...,\n","         [ 1.0619, -0.2639,  0.6015,  ...,  0.8519, -0.6093,  1.0231],\n","         [ 1.0597,  0.3773, -0.1900,  ...,  0.3660, -0.6045,  0.4969],\n","         [ 0.9157,  0.0654, -0.1778,  ...,  0.4983, -0.9474,  0.8150]],\n","\n","        [[ 0.5399,  1.8529,  0.4672,  ..., -0.4839, -1.8345,  0.6238],\n","         [ 1.0609,  0.5804,  0.1883,  ..., -1.3004, -2.4029,  0.2259],\n","         [ 0.9539,  1.7407, -0.1898,  ..., -0.3453, -2.0105,  0.3307],\n","         ...,\n","         [ 1.1228,  1.3026,  0.3959,  ...,  0.0173, -1.8917,  0.7413],\n","         [ 1.4022,  1.2859,  0.6237,  ..., -0.1966, -1.2465,  0.6581],\n","         [ 1.0497,  1.4130,  0.6617,  ..., -0.5059, -1.5358,  0.6370]],\n","\n","        ...,\n","\n","        [[-0.3616, -0.7350, -0.6835,  ...,  0.2184, -0.9852,  0.8702],\n","         [-2.4717, -0.6914,  0.4288,  ...,  0.3254, -0.1927,  1.8281],\n","         [-0.9897,  0.4299,  0.0524,  ..., -0.2010, -0.7483,  0.2699],\n","         ...,\n","         [-0.2893,  0.8122, -1.0374,  ..., -0.0095, -0.0625, -0.0752],\n","         [-0.2553,  0.0437, -0.8358,  ..., -0.0323, -0.2654,  0.4134],\n","         [-0.1302,  0.2872, -1.0318,  ..., -0.1393, -0.7733, -0.1165]],\n","\n","        [[ 1.0163,  0.0688, -0.1011,  ..., -0.0813, -0.2454, -0.3398],\n","         [-0.0898,  0.1529,  0.0383,  ..., -0.3113,  0.1765,  0.3130],\n","         [ 1.0944,  1.7189, -0.7371,  ..., -1.1309, -0.2281, -1.7407],\n","         ...,\n","         [ 0.5088, -0.3396, -0.2004,  ..., -1.0791,  0.0124,  0.8244],\n","         [ 0.7620,  0.2192,  0.5785,  ...,  0.4198,  0.2884,  0.2873],\n","         [ 1.1520,  0.4506,  1.4737,  ..., -0.6328, -0.2445, -0.1582]],\n","\n","        [[-0.4634, -0.5354,  0.5653,  ..., -0.9479, -0.6982,  1.5636],\n","         [-0.2142, -0.5226,  1.6127,  ..., -0.4217, -0.0600,  1.2853],\n","         [ 1.0067, -0.8281,  1.4614,  ..., -0.3112, -1.1679,  1.2498],\n","         ...,\n","         [ 0.0217, -1.1994,  0.7463,  ...,  0.0819, -0.5451,  1.5441],\n","         [ 0.0087, -0.6447,  1.1138,  ...,  0.0795, -0.5317,  1.5214],\n","         [-0.2327, -0.7869,  0.5843,  ...,  0.1623, -0.8967,  1.6053]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2109, -0.5204,  0.4440,  ...,  0.4314, -0.1762,  0.9215],\n","        [ 0.8129,  0.1269,  0.1438,  ..., -0.1977, -0.1970,  0.8799],\n","        [ 0.6870, -0.0747,  0.4302,  ..., -0.5689, -0.2569,  0.6291],\n","        ...,\n","        [ 0.5036,  0.2937,  0.2990,  ..., -0.0411, -0.2419, -0.2441],\n","        [ 0.5150, -0.7676,  0.2880,  ..., -0.1854,  0.0888,  0.5923],\n","        [ 0.4365, -0.3151,  0.4796,  ...,  0.4957, -0.5635, -0.1469]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.2109, -0.5204,  0.4440,  ...,  0.4314, -0.1762,  0.9215],\n","        [ 0.8129,  0.1269,  0.1438,  ..., -0.1977, -0.1970,  0.8799],\n","        [ 0.6870, -0.0747,  0.4302,  ..., -0.5689, -0.2569,  0.6291],\n","        ...,\n","        [ 0.5036,  0.2937,  0.2990,  ..., -0.0411, -0.2419, -0.2441],\n","        [ 0.5150, -0.7676,  0.2880,  ..., -0.1854,  0.0888,  0.5923],\n","        [ 0.4365, -0.3151,  0.4796,  ...,  0.4957, -0.5635, -0.1469]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.4064,  0.9055, -0.0691,  ...,  0.1485, -1.1535,  1.0636],\n","        [ 0.4853, -0.7004, -0.3985,  ...,  1.1247, -1.3340,  1.1334],\n","        [ 0.5399,  1.8529,  0.4672,  ..., -0.4839, -1.8345,  0.6238],\n","        ...,\n","        [-0.3616, -0.7350, -0.6835,  ...,  0.2184, -0.9852,  0.8702],\n","        [ 1.0163,  0.0688, -0.1011,  ..., -0.0813, -0.2454, -0.3398],\n","        [-0.4634, -0.5354,  0.5653,  ..., -0.9479, -0.6982,  1.5636]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 5.9854e-01, -4.4313e-01,  1.3603e-01,  ..., -4.1897e-01,\n","          -8.1013e-01, -5.8678e-01],\n","         [ 5.7260e-01, -9.7155e-02, -6.1038e-02,  ..., -8.0916e-01,\n","          -9.1067e-01,  1.9965e-01],\n","         [ 9.0339e-01,  1.4869e-01, -3.6932e-01,  ...,  2.7815e-01,\n","          -4.9501e-01, -4.3190e-01],\n","         ...,\n","         [-3.5167e-01, -6.7663e-01, -1.0132e-01,  ...,  1.0525e+00,\n","           1.6002e-01, -4.7244e-02],\n","         [ 4.0431e-01, -1.5358e+00,  6.4756e-01,  ...,  6.8528e-01,\n","          -2.1635e+00, -9.3892e-01],\n","         [ 1.6621e+00, -3.4017e-01,  7.8628e-01,  ...,  1.6054e-01,\n","          -1.9150e+00,  1.1374e+00]],\n","\n","        [[ 5.1264e-02,  2.9688e-01, -5.8131e-01,  ..., -5.3447e-01,\n","          -1.2026e+00,  3.6432e-01],\n","         [ 6.4327e-01, -1.0852e+00, -1.1163e+00,  ..., -4.0313e-01,\n","           1.1771e-01, -5.3448e-01],\n","         [ 6.3853e-02, -1.1531e+00, -5.4035e-01,  ..., -8.9550e-01,\n","          -7.3988e-01, -2.1786e-01],\n","         ...,\n","         [ 1.2708e+00, -1.0142e+00,  2.8307e-01,  ..., -1.4897e+00,\n","           3.4178e-01, -3.2541e-01],\n","         [-6.4282e-02,  1.0240e+00, -4.2459e-01,  ..., -3.4156e-01,\n","          -4.6624e-01, -3.5176e-01],\n","         [ 1.9407e-01,  1.2150e+00,  2.7213e-01,  ..., -2.9704e-01,\n","          -3.5196e-01,  9.5074e-02]],\n","\n","        [[ 3.0239e-01, -1.9887e-01,  2.2379e-01,  ...,  5.9304e-01,\n","          -1.4009e-01,  1.0531e+00],\n","         [-3.6592e-01, -2.0018e-01,  3.9232e-02,  ..., -1.4143e-01,\n","           1.4488e-01,  2.2748e-01],\n","         [ 5.1251e-01, -6.8788e-01,  1.2298e+00,  ...,  2.0045e+00,\n","           3.0633e-01, -4.5607e-02],\n","         ...,\n","         [ 1.3502e+00,  2.9799e-02,  8.9541e-01,  ...,  2.1092e-01,\n","           3.6664e-01,  1.8752e-01],\n","         [ 7.8798e-01, -3.9241e-01,  9.9259e-01,  ...,  5.9098e-01,\n","          -5.1670e-01,  2.2462e-01],\n","         [ 1.1246e+00,  2.4697e-01,  7.4091e-01,  ...,  2.6562e-01,\n","          -1.4573e-01,  7.8497e-01]],\n","\n","        ...,\n","\n","        [[ 1.8741e-01,  3.6820e-01, -8.7989e-02,  ..., -1.8466e-01,\n","          -1.0562e+00,  7.1786e-01],\n","         [-1.0125e-01, -2.2335e+00, -1.6136e-01,  ...,  2.3148e-01,\n","           1.4160e+00,  3.0257e-01],\n","         [-1.7693e-02, -6.8179e-01,  3.2889e-01,  ..., -1.8446e-01,\n","          -1.1275e+00,  1.3649e+00],\n","         ...,\n","         [ 1.5077e-01,  2.4831e-01, -1.5132e-01,  ...,  1.0246e+00,\n","          -1.4069e+00,  6.0079e-01],\n","         [ 6.8169e-02, -2.0521e-02, -1.5275e-01,  ...,  3.4700e-01,\n","          -1.7075e+00,  5.3417e-01],\n","         [ 6.4396e-01,  4.3974e-01,  4.5310e-01,  ...,  2.2177e-01,\n","          -2.1908e-01,  1.0293e+00]],\n","\n","        [[ 2.9762e-01, -1.2094e+00, -7.9665e-01,  ...,  5.2695e-01,\n","          -1.1384e+00, -4.5866e-01],\n","         [ 4.1775e-01, -1.3264e+00,  7.3522e-01,  ...,  1.4325e+00,\n","          -6.6753e-01,  7.9244e-01],\n","         [ 2.4410e-01,  5.7331e-02,  2.5937e-01,  ...,  2.0385e-01,\n","          -7.0576e-01, -2.5526e-01],\n","         ...,\n","         [ 9.4551e-01, -1.7788e+00,  1.1332e-01,  ..., -1.0323e-01,\n","          -7.2415e-01,  4.3697e-02],\n","         [ 5.3826e-01, -1.1065e+00,  2.8870e-01,  ...,  2.6849e-01,\n","          -8.2483e-01,  3.9214e-01],\n","         [ 7.8988e-01, -1.9917e+00,  3.6919e-01,  ..., -5.7266e-02,\n","          -1.2246e+00,  5.7488e-01]],\n","\n","        [[ 4.2272e-01, -1.4971e-01,  2.2449e-01,  ..., -1.8481e-01,\n","          -3.8196e-01,  1.2259e+00],\n","         [ 1.1118e+00, -3.5128e-01,  3.2228e-01,  ...,  1.4553e-03,\n","           1.3501e-01,  5.2794e-01],\n","         [ 5.0494e-01,  1.5513e+00, -4.8630e-02,  ...,  4.0757e-01,\n","          -9.3985e-02,  2.2649e-02],\n","         ...,\n","         [ 1.3012e+00,  9.5343e-01,  3.4489e-01,  ..., -4.1124e-01,\n","           1.4764e-01,  4.0670e-01],\n","         [ 5.9339e-01,  6.9367e-01,  1.6221e-01,  ..., -6.2833e-01,\n","           5.2670e-01, -3.7505e-02],\n","         [ 1.8138e-01, -7.2889e-01,  1.8492e+00,  ..., -2.4113e-01,\n","          -8.5641e-01,  9.0634e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.4038, -0.2419,  0.5384,  ...,  0.5910, -0.4780,  0.8957],\n","        [ 0.6970, -0.4158,  0.3466,  ...,  0.1630,  0.6448,  0.0522],\n","        [ 0.6834,  0.3103,  0.3133,  ...,  0.4975, -0.5062, -0.5604],\n","        ...,\n","        [ 0.5768,  0.2759,  0.7142,  ...,  0.2234, -0.2625, -0.2273],\n","        [ 0.7947, -0.7240,  0.6443,  ..., -0.0565, -0.6623,  0.3237],\n","        [ 0.6845,  0.0131,  0.5587,  ...,  0.0355, -0.0636, -0.4815]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.4038, -0.2419,  0.5384,  ...,  0.5910, -0.4780,  0.8957],\n","        [ 0.6970, -0.4158,  0.3466,  ...,  0.1630,  0.6448,  0.0522],\n","        [ 0.6834,  0.3103,  0.3133,  ...,  0.4975, -0.5062, -0.5604],\n","        ...,\n","        [ 0.5768,  0.2759,  0.7142,  ...,  0.2234, -0.2625, -0.2273],\n","        [ 0.7947, -0.7240,  0.6443,  ..., -0.0565, -0.6623,  0.3237],\n","        [ 0.6845,  0.0131,  0.5587,  ...,  0.0355, -0.0636, -0.4815]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.5985, -0.4431,  0.1360,  ..., -0.4190, -0.8101, -0.5868],\n","        [ 0.0513,  0.2969, -0.5813,  ..., -0.5345, -1.2026,  0.3643],\n","        [ 0.3024, -0.1989,  0.2238,  ...,  0.5930, -0.1401,  1.0531],\n","        ...,\n","        [ 0.1874,  0.3682, -0.0880,  ..., -0.1847, -1.0562,  0.7179],\n","        [ 0.2976, -1.2094, -0.7966,  ...,  0.5270, -1.1384, -0.4587],\n","        [ 0.4227, -0.1497,  0.2245,  ..., -0.1848, -0.3820,  1.2259]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2146, -0.2935, -0.2345,  ...,  1.1939, -0.8518, -0.2651],\n","         [ 0.1970, -0.1951,  0.2906,  ...,  0.9225, -0.0196, -0.2637],\n","         [-0.5055, -0.8016, -0.8470,  ..., -0.0555,  0.7224,  0.9652],\n","         ...,\n","         [ 1.2146,  1.1419, -0.3107,  ...,  1.4359,  0.4317, -0.7539],\n","         [ 0.8698,  0.4630,  0.4674,  ...,  0.1220,  0.1689,  0.0945],\n","         [ 1.2546,  0.6061,  0.1378,  ...,  0.0360,  0.0023, -1.1001]],\n","\n","        [[ 1.0451, -0.5102, -0.0198,  ..., -0.5113, -1.5878,  0.4909],\n","         [ 0.1549, -0.8331, -0.1921,  ..., -0.2449,  0.2781,  0.4709],\n","         [ 0.8539,  0.5311, -0.6185,  ..., -0.1095, -0.1367,  0.0721],\n","         ...,\n","         [ 0.9547, -0.8224,  0.6345,  ...,  0.2067, -0.3133,  1.2810],\n","         [ 1.2175, -0.7368,  0.2230,  ..., -0.3169, -0.4326,  0.7585],\n","         [ 0.5233, -0.5109,  0.1144,  ..., -0.3012, -1.0002,  1.2334]],\n","\n","        [[ 1.2894, -0.3127, -0.0776,  ...,  0.0934, -0.6058, -0.3736],\n","         [ 1.2291, -0.4108,  0.3709,  ...,  0.7249,  0.9639, -0.1606],\n","         [ 0.9848, -0.4997, -0.1651,  ...,  1.7398,  0.2532, -1.2833],\n","         ...,\n","         [ 1.0538, -0.3744, -0.4531,  ...,  0.2864, -1.0099, -0.5826],\n","         [ 1.2889,  0.2404,  0.4164,  ...,  0.3743, -0.0496,  0.0088],\n","         [ 0.4509, -0.7041, -0.5052,  ...,  0.3154, -1.3485, -0.9810]],\n","\n","        ...,\n","\n","        [[ 0.9186, -1.1511, -0.6752,  ..., -0.1697,  0.1113, -0.1572],\n","         [ 1.5798,  0.2194,  0.0783,  ..., -0.4846,  1.8585, -0.3974],\n","         [ 0.3430, -0.3898,  0.9713,  ...,  0.6221,  0.5167, -0.7653],\n","         ...,\n","         [ 1.0520, -0.3992,  0.3890,  ..., -0.5314,  0.0051,  0.9259],\n","         [ 0.8022, -0.5109,  0.3396,  ..., -0.0490,  0.2598,  0.7549],\n","         [ 0.5643, -0.9909, -0.1603,  ..., -0.8003, -0.4932,  1.2257]],\n","\n","        [[ 0.8008,  0.0611, -0.2854,  ...,  0.3548, -1.5020,  0.5522],\n","         [ 0.5201,  0.0153,  0.2782,  ...,  0.5435, -0.1624,  0.8919],\n","         [ 0.7789,  0.0501,  0.3641,  ...,  0.2496, -1.5355,  1.7755],\n","         ...,\n","         [-0.4004, -0.0755,  0.0486,  ...,  0.1690, -0.5082,  0.5381],\n","         [ 0.2163,  0.0299, -0.1225,  ...,  0.1659, -0.5711,  0.8452],\n","         [ 1.0602,  0.6327,  0.0224,  ...,  0.7181, -1.2797,  1.0533]],\n","\n","        [[ 0.3903, -1.2575,  0.6033,  ...,  0.0826, -0.8424,  0.5362],\n","         [-0.4801, -0.2928,  1.6258,  ..., -0.1613, -1.2993,  0.3459],\n","         [ 0.9158, -1.0211,  1.3489,  ..., -0.2204, -1.9210,  0.4753],\n","         ...,\n","         [ 0.8074, -0.2161, -0.4198,  ...,  0.1822, -0.2332, -0.0718],\n","         [ 0.6858, -0.9668,  0.1941,  ...,  1.0258, -1.0202, -0.0593],\n","         [ 0.8208,  0.1993,  1.0060,  ..., -0.0274, -0.8373,  1.0570]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.8215, -0.3662,  0.5083,  ...,  0.1545, -0.0273,  0.4969],\n","        [ 0.3348, -0.2492, -0.1415,  ...,  0.2981, -0.8556, -0.0099],\n","        [ 0.3105, -0.4868, -0.2990,  ..., -0.2662,  0.2683,  0.3984],\n","        ...,\n","        [ 0.6901, -0.5512, -0.3358,  ..., -0.0676,  0.5851,  0.8711],\n","        [ 0.7993,  0.4391,  0.8571,  ...,  0.1631, -0.3167,  0.9594],\n","        [ 0.7474, -0.3515, -0.3999,  ..., -0.4713, -0.0948,  0.9911]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.8215, -0.3662,  0.5083,  ...,  0.1545, -0.0273,  0.4969],\n","        [ 0.3348, -0.2492, -0.1415,  ...,  0.2981, -0.8556, -0.0099],\n","        [ 0.3105, -0.4868, -0.2990,  ..., -0.2662,  0.2683,  0.3984],\n","        ...,\n","        [ 0.6901, -0.5512, -0.3358,  ..., -0.0676,  0.5851,  0.8711],\n","        [ 0.7993,  0.4391,  0.8571,  ...,  0.1631, -0.3167,  0.9594],\n","        [ 0.7474, -0.3515, -0.3999,  ..., -0.4713, -0.0948,  0.9911]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.2146, -0.2935, -0.2345,  ...,  1.1939, -0.8518, -0.2651],\n","        [ 1.0451, -0.5102, -0.0198,  ..., -0.5113, -1.5878,  0.4909],\n","        [ 1.2894, -0.3127, -0.0776,  ...,  0.0934, -0.6058, -0.3736],\n","        ...,\n","        [ 0.9186, -1.1511, -0.6752,  ..., -0.1697,  0.1113, -0.1572],\n","        [ 0.8008,  0.0611, -0.2854,  ...,  0.3548, -1.5020,  0.5522],\n","        [ 0.3903, -1.2575,  0.6033,  ...,  0.0826, -0.8424,  0.5362]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 2.2972e-01,  1.6966e+00,  2.1105e-01,  ...,  4.4449e-01,\n","          -1.7304e+00,  8.2986e-01],\n","         [ 4.1612e-01,  9.6001e-01,  5.9532e-01,  ..., -2.2337e-01,\n","          -7.6286e-01,  1.4611e+00],\n","         [ 3.7394e-01,  5.7863e-01, -5.1105e-01,  ...,  7.5681e-01,\n","          -1.2096e+00,  8.4565e-01],\n","         ...,\n","         [ 5.9157e-01,  7.5951e-01,  2.3011e-01,  ...,  2.1751e-02,\n","          -1.3433e+00,  2.7861e-01],\n","         [ 4.5733e-01,  1.4285e-02,  8.2250e-01,  ...,  2.0558e-01,\n","          -9.1201e-01,  2.0094e-01],\n","         [ 7.5533e-01,  1.7232e-01,  5.1878e-01,  ...,  1.7018e-01,\n","          -6.6491e-01,  4.1391e-01]],\n","\n","        [[ 3.9536e-01, -1.2610e+00, -1.4189e-02,  ...,  7.1763e-01,\n","          -8.3770e-01,  2.3479e-01],\n","         [ 2.4144e-01, -1.2923e+00,  4.3753e-04,  ...,  5.1391e-01,\n","           1.5531e-01, -8.4866e-01],\n","         [ 3.6820e-01,  7.7051e-01,  4.0720e-01,  ...,  9.9408e-01,\n","          -3.7120e-01,  5.3039e-03],\n","         ...,\n","         [ 6.0173e-01, -8.7569e-01, -2.4219e-01,  ...,  1.2201e-01,\n","          -1.6041e-01,  1.9785e-01],\n","         [ 4.4496e-01, -7.3003e-01, -3.6411e-01,  ...,  3.1335e-01,\n","          -5.7272e-02,  6.2963e-02],\n","         [ 1.0370e+00, -1.6646e+00, -2.1090e-01,  ...,  2.5885e-01,\n","           6.9532e-03, -5.0462e-01]],\n","\n","        [[ 3.7211e-01, -1.3789e+00,  5.7650e-01,  ..., -4.2090e-01,\n","          -4.4281e-01,  2.4130e-01],\n","         [ 7.1907e-01,  4.9384e-01,  5.4023e-03,  ...,  8.2320e-01,\n","           1.2555e-01,  4.6776e-01],\n","         [-1.0975e-01, -6.7937e-01, -6.7403e-01,  ..., -8.6435e-01,\n","           4.2000e-01, -1.2289e+00],\n","         ...,\n","         [ 3.5317e-01, -1.6478e+00,  6.1094e-02,  ..., -7.0141e-01,\n","          -7.3373e-01,  7.6439e-01],\n","         [ 2.1259e-01, -1.2881e+00, -2.6546e-01,  ...,  1.1764e-01,\n","          -2.6278e-01, -2.6150e-01],\n","         [ 7.8001e-02, -2.2230e+00,  3.0316e-01,  ..., -6.1930e-01,\n","          -3.2049e-01,  6.4442e-01]],\n","\n","        ...,\n","\n","        [[ 1.7098e+00, -6.3040e-01,  5.7782e-01,  ..., -3.3977e-01,\n","          -8.4204e-01, -3.3290e-01],\n","         [ 1.2535e+00,  9.0019e-01,  5.6096e-01,  ..., -1.8734e+00,\n","           1.6171e+00, -7.0605e-02],\n","         [ 5.6675e-01, -1.2283e-01,  5.0593e-01,  ..., -6.8123e-01,\n","           2.0787e+00,  2.4108e-01],\n","         ...,\n","         [ 5.0331e-01,  1.2874e+00, -3.4040e-01,  ...,  6.3167e-01,\n","          -1.2336e+00, -1.8153e-01],\n","         [-6.2516e-01, -3.9330e-01, -4.8582e-01,  ..., -8.5703e-04,\n","          -7.1822e-01,  8.7245e-01],\n","         [ 7.4933e-01, -1.2120e-01,  8.9595e-01,  ...,  2.6116e-01,\n","          -1.0300e+00,  7.5460e-01]],\n","\n","        [[-6.8737e-01, -4.7802e-01, -5.3912e-01,  ...,  3.2020e-01,\n","          -1.0967e+00,  1.7239e-01],\n","         [-8.2173e-01, -1.2595e+00,  6.4332e-01,  ...,  2.4005e-01,\n","           1.6114e+00, -1.8038e-01],\n","         [-6.2821e-02, -1.8854e+00,  4.3969e-01,  ...,  1.5684e+00,\n","           3.7355e-01, -3.9984e-01],\n","         ...,\n","         [-4.4706e-01, -1.4138e+00, -5.3131e-01,  ..., -3.4720e-01,\n","           4.8826e-01,  1.3396e+00],\n","         [-8.8090e-01, -6.9886e-01, -1.4113e-03,  ...,  2.0348e-01,\n","           3.1073e-01,  5.2366e-01],\n","         [ 5.4599e-01, -7.9443e-01, -2.6879e-01,  ..., -3.0510e-01,\n","          -9.7928e-01,  8.1249e-01]],\n","\n","        [[ 7.2689e-01, -1.2457e+00, -3.8181e-02,  ...,  2.1319e-01,\n","           4.6684e-01,  7.1659e-01],\n","         [ 4.0824e-01,  2.3408e-01,  1.0088e+00,  ...,  6.3195e-01,\n","          -3.9804e-01,  8.9601e-01],\n","         [-4.2898e-01, -1.9923e+00,  7.6075e-01,  ..., -1.5470e+00,\n","          -1.0650e+00, -1.1431e-01],\n","         ...,\n","         [ 3.1240e-01, -4.0394e-01,  6.1821e-02,  ..., -4.0375e-01,\n","           2.7704e-01,  7.2821e-01],\n","         [ 2.0190e-01, -1.0070e+00,  2.8123e-01,  ..., -8.7654e-01,\n","          -9.3811e-02,  4.1887e-01],\n","         [ 2.5227e-01, -3.5567e-01,  9.9119e-02,  ...,  9.1372e-01,\n","           5.3685e-02,  6.5540e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.4503e-02, -7.7621e-02,  3.6960e-02,  ...,  3.8575e-01,\n","         -4.3058e-01,  3.0198e-01],\n","        [ 3.2177e-01, -1.3504e-01,  3.6079e-01,  ..., -6.2714e-02,\n","          3.4913e-01,  7.9674e-01],\n","        [ 2.5018e-02, -5.9164e-01, -7.3605e-02,  ..., -1.1624e-01,\n","          5.1388e-01,  4.2796e-01],\n","        ...,\n","        [ 6.0227e-01,  3.4324e-02,  4.8202e-02,  ..., -4.4003e-01,\n","          5.9032e-01,  9.6403e-01],\n","        [ 7.0060e-01,  1.0827e-01,  4.6670e-01,  ...,  2.4399e-01,\n","         -5.2297e-03,  8.3865e-02],\n","        [ 5.0018e-01, -5.5363e-02, -9.2941e-04,  ..., -3.3550e-01,\n","          5.2378e-01,  9.1625e-01]], device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[-1.4503e-02, -7.7621e-02,  3.6960e-02,  ...,  3.8575e-01,\n","         -4.3058e-01,  3.0198e-01],\n","        [ 3.2177e-01, -1.3504e-01,  3.6079e-01,  ..., -6.2714e-02,\n","          3.4913e-01,  7.9674e-01],\n","        [ 2.5018e-02, -5.9164e-01, -7.3605e-02,  ..., -1.1624e-01,\n","          5.1388e-01,  4.2796e-01],\n","        ...,\n","        [ 6.0227e-01,  3.4324e-02,  4.8202e-02,  ..., -4.4003e-01,\n","          5.9032e-01,  9.6403e-01],\n","        [ 7.0060e-01,  1.0827e-01,  4.6670e-01,  ...,  2.4399e-01,\n","         -5.2297e-03,  8.3865e-02],\n","        [ 5.0018e-01, -5.5363e-02, -9.2941e-04,  ..., -3.3550e-01,\n","          5.2378e-01,  9.1625e-01]], device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.2297,  1.6966,  0.2111,  ...,  0.4445, -1.7304,  0.8299],\n","        [ 0.3954, -1.2610, -0.0142,  ...,  0.7176, -0.8377,  0.2348],\n","        [ 0.3721, -1.3789,  0.5765,  ..., -0.4209, -0.4428,  0.2413],\n","        ...,\n","        [ 1.7098, -0.6304,  0.5778,  ..., -0.3398, -0.8420, -0.3329],\n","        [-0.6874, -0.4780, -0.5391,  ...,  0.3202, -1.0967,  0.1724],\n","        [ 0.7269, -1.2457, -0.0382,  ...,  0.2132,  0.4668,  0.7166]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 3.4992e-01, -6.6305e-01, -5.0599e-02,  ..., -3.9387e-01,\n","          -2.9022e-01,  6.3787e-01],\n","         [ 1.3464e+00, -2.6105e+00, -1.2651e-03,  ...,  7.6798e-01,\n","           2.8508e-01,  3.4659e-01],\n","         [ 2.1462e+00, -5.0132e-01, -2.0922e-03,  ...,  8.7578e-01,\n","           1.2976e-01,  7.3063e-01],\n","         ...,\n","         [ 1.0708e+00, -1.7458e-01,  1.9007e-01,  ..., -1.8121e-02,\n","           3.6728e-01,  2.8360e-01],\n","         [ 5.4956e-01, -7.6296e-01,  2.6221e-01,  ..., -3.6262e-01,\n","           2.6167e-01, -3.2671e-01],\n","         [ 1.2255e+00, -7.3924e-01, -4.1458e-01,  ..., -5.2062e-01,\n","          -2.4416e-01, -2.9638e-01]],\n","\n","        [[-1.8328e-01,  3.9568e-02, -7.2811e-01,  ...,  6.3001e-02,\n","          -1.0386e+00,  1.3223e+00],\n","         [ 5.8877e-03,  5.2427e-01,  9.5505e-01,  ...,  1.0896e+00,\n","          -1.2765e-01,  6.9530e-01],\n","         [-5.4353e-01,  5.9411e-01, -3.6406e-02,  ...,  2.0767e-01,\n","           1.5588e+00,  3.1042e-01],\n","         ...,\n","         [ 1.5514e+00, -3.2898e-01,  2.0840e-01,  ..., -1.0364e+00,\n","           2.5170e-01,  4.0440e-02],\n","         [ 7.0865e-01, -6.0533e-01, -2.1071e-01,  ..., -8.1459e-01,\n","           1.7584e-01,  2.9093e-01],\n","         [ 9.2020e-01,  4.3484e-01, -5.2932e-01,  ..., -6.3389e-01,\n","          -6.1874e-02,  4.5084e-01]],\n","\n","        [[ 1.6819e+00, -6.8376e-01,  3.8258e-01,  ...,  9.8089e-03,\n","          -2.3617e-01, -4.1144e-01],\n","         [ 1.1397e+00, -4.3475e-01,  5.7653e-01,  ..., -4.3625e-02,\n","           9.3654e-01, -1.5043e+00],\n","         [-1.2985e-01, -2.0713e-01, -4.8392e-01,  ...,  2.0791e-01,\n","          -1.7023e-01, -2.0263e-01],\n","         ...,\n","         [ 1.0801e+00,  6.2797e-01,  5.7351e-01,  ...,  7.2339e-01,\n","          -9.3572e-01,  6.5962e-01],\n","         [ 2.4181e-01,  1.5883e-01,  7.2355e-01,  ..., -1.5610e-02,\n","          -1.6891e+00,  6.4188e-02],\n","         [ 2.0731e+00, -1.7859e-01,  1.1044e+00,  ...,  3.4077e-01,\n","          -7.6386e-01, -1.1178e+00]],\n","\n","        ...,\n","\n","        [[ 1.3458e-01, -2.1338e-01, -3.5303e-01,  ...,  3.2272e-01,\n","          -2.0506e+00,  1.1283e+00],\n","         [-4.2220e-01, -1.0283e+00, -7.8183e-01,  ...,  7.5837e-01,\n","          -2.1927e+00,  3.9263e-01],\n","         [ 6.8200e-01, -1.4450e+00,  3.6579e-01,  ...,  1.1531e+00,\n","          -2.0943e+00,  3.7536e-01],\n","         ...,\n","         [ 1.0846e+00, -9.7063e-02,  7.3461e-01,  ...,  8.2961e-01,\n","          -1.5309e+00,  1.6393e+00],\n","         [ 8.5729e-01, -3.8698e-01,  5.9707e-01,  ...,  9.9186e-01,\n","          -1.1330e+00,  1.7205e+00],\n","         [ 1.0105e+00, -1.4077e+00,  3.1319e-01,  ...,  7.2299e-01,\n","          -1.6655e+00,  1.8067e+00]],\n","\n","        [[-2.1503e-01, -8.1206e-01, -1.6186e-01,  ...,  8.8655e-01,\n","          -2.7731e-01,  3.1741e-01],\n","         [-4.7462e-01, -1.1575e+00, -4.9693e-01,  ...,  1.9632e-01,\n","           1.5489e-01,  7.0942e-01],\n","         [ 7.9855e-01,  4.6625e-01,  7.1553e-01,  ..., -2.5819e-01,\n","          -1.5371e-01,  1.1449e-01],\n","         ...,\n","         [ 8.2810e-01,  7.5155e-01, -3.2345e-02,  ...,  5.7383e-01,\n","          -1.3338e-02, -1.0674e-01],\n","         [ 8.0249e-01,  7.1111e-01, -9.0402e-02,  ...,  6.7206e-02,\n","          -1.6683e-01,  1.5058e-01],\n","         [ 5.4978e-01, -1.2883e-01, -2.2296e-01,  ...,  1.0572e-01,\n","          -9.5847e-01,  1.0721e-01]],\n","\n","        [[ 6.4752e-01, -1.1603e+00, -3.0192e-01,  ...,  7.9173e-01,\n","          -5.0057e-02,  6.4810e-01],\n","         [ 5.5609e-01, -1.2445e+00, -4.8266e-01,  ...,  3.9444e-01,\n","           1.8919e-01, -1.3569e-01],\n","         [-7.3682e-01,  1.2691e-01, -3.5457e-01,  ...,  4.7227e-02,\n","           1.7568e-01, -8.7361e-02],\n","         ...,\n","         [ 9.0660e-01,  7.9995e-03,  3.9889e-01,  ...,  5.7479e-01,\n","          -1.9165e-01,  6.7328e-01],\n","         [ 3.0309e-01,  6.0158e-01,  2.3564e-01,  ...,  1.4140e+00,\n","           1.8719e-01,  7.1941e-01],\n","         [ 3.3019e-01,  4.5569e-01, -5.4434e-02,  ...,  1.6783e+00,\n","          -9.9858e-02, -8.4708e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2595, -0.2998, -0.4613,  ...,  0.5553,  0.2880, -0.6600],\n","        [ 0.8952, -0.3884,  0.6966,  ...,  0.0296, -0.0225,  0.8855],\n","        [ 0.4888,  0.2330,  0.3463,  ...,  0.2758,  0.5556,  0.3181],\n","        ...,\n","        [ 0.8018,  0.4637,  0.2178,  ..., -0.0317,  0.2060, -0.2634],\n","        [ 0.7925, -0.1419,  0.5599,  ...,  0.5540, -0.2198,  0.5482],\n","        [ 0.4232, -0.3982, -0.2147,  ..., -0.6785, -0.4006,  0.8814]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.2595, -0.2998, -0.4613,  ...,  0.5553,  0.2880, -0.6600],\n","        [ 0.8952, -0.3884,  0.6966,  ...,  0.0296, -0.0225,  0.8855],\n","        [ 0.4888,  0.2330,  0.3463,  ...,  0.2758,  0.5556,  0.3181],\n","        ...,\n","        [ 0.8018,  0.4637,  0.2178,  ..., -0.0317,  0.2060, -0.2634],\n","        [ 0.7925, -0.1419,  0.5599,  ...,  0.5540, -0.2198,  0.5482],\n","        [ 0.4232, -0.3982, -0.2147,  ..., -0.6785, -0.4006,  0.8814]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.3499, -0.6631, -0.0506,  ..., -0.3939, -0.2902,  0.6379],\n","        [-0.1833,  0.0396, -0.7281,  ...,  0.0630, -1.0386,  1.3223],\n","        [ 1.6819, -0.6838,  0.3826,  ...,  0.0098, -0.2362, -0.4114],\n","        ...,\n","        [ 0.1346, -0.2134, -0.3530,  ...,  0.3227, -2.0506,  1.1283],\n","        [-0.2150, -0.8121, -0.1619,  ...,  0.8865, -0.2773,  0.3174],\n","        [ 0.6475, -1.1603, -0.3019,  ...,  0.7917, -0.0501,  0.6481]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1910,  0.0517,  1.0985,  ..., -0.0618, -0.5920, -0.4509],\n","         [-0.1523, -0.8156, -0.1464,  ..., -0.8337, -0.6864, -0.3148],\n","         [-0.9927,  0.4718,  0.3062,  ...,  0.1551, -0.9369, -1.4375],\n","         ...,\n","         [-0.7756, -1.5468,  0.7947,  ...,  0.2612,  0.4763, -0.5940],\n","         [ 0.2613, -0.0981,  0.5961,  ...,  0.0305, -1.0097,  0.4133],\n","         [ 0.3969,  0.4166,  0.6755,  ..., -0.4593,  0.7352, -0.2759]],\n","\n","        [[ 0.2417, -0.5157, -0.5700,  ..., -0.5458,  0.0964,  0.0998],\n","         [ 0.5896,  0.4792, -0.3326,  ..., -1.0752,  0.1607, -0.0457],\n","         [-0.3948, -0.4469,  0.0858,  ..., -1.2741, -0.0923,  0.5992],\n","         ...,\n","         [ 0.7907, -0.7055, -0.8397,  ...,  0.6179,  0.1095,  0.1182],\n","         [ 0.5913, -1.2332, -0.7115,  ...,  0.6152, -0.7633,  0.0658],\n","         [ 0.5854, -1.6785, -0.3239,  ...,  0.6274,  0.2792,  0.9684]],\n","\n","        [[ 1.7708,  0.0230, -0.8110,  ...,  0.3736, -1.9611,  0.4646],\n","         [ 2.2540,  0.3739,  0.3108,  ...,  0.5004, -1.2185,  0.2867],\n","         [ 0.4289, -1.3024, -0.0929,  ...,  1.5166, -0.8332, -0.2518],\n","         ...,\n","         [ 2.5514,  1.1404, -0.4609,  ...,  0.3927, -1.0258, -0.1334],\n","         [ 1.9433,  0.2345, -0.4352,  ...,  0.7109, -0.8842,  0.1216],\n","         [ 1.9346,  0.4380, -0.2150,  ...,  0.9202, -0.5548,  0.3682]],\n","\n","        ...,\n","\n","        [[-0.8369,  0.6135, -0.6299,  ...,  0.7044, -0.2604,  0.0032],\n","         [ 1.2033,  0.2295,  0.5511,  ...,  2.1278,  1.3527,  1.0622],\n","         [ 1.0562, -0.5960,  1.1717,  ...,  1.2640,  1.3641,  1.0659],\n","         ...,\n","         [ 0.2620,  0.0210,  0.6946,  ...,  0.3836,  0.3709, -0.2515],\n","         [ 0.5953,  0.2168,  0.8337,  ...,  0.2155,  0.4777, -0.8785],\n","         [ 0.7061, -0.3737,  0.4322,  ...,  0.4108,  0.9728, -0.4988]],\n","\n","        [[ 0.0710, -1.7343, -0.2754,  ..., -0.0563, -0.8438,  0.8963],\n","         [-1.3950, -1.7934,  0.2504,  ..., -0.0266, -0.1945,  0.6247],\n","         [-1.6863, -1.1290, -0.3674,  ..., -0.6805, -0.7217,  1.5603],\n","         ...,\n","         [-0.0394, -1.6226,  0.3916,  ...,  0.4363, -0.2221,  0.9118],\n","         [ 0.4721, -1.3910,  0.4723,  ...,  0.1937, -0.3360,  1.1200],\n","         [ 0.4886, -1.1180,  0.5304,  ...,  0.5717, -0.0556,  0.8748]],\n","\n","        [[ 1.0718,  0.2839, -0.5983,  ..., -0.3588, -1.2288,  0.7629],\n","         [ 0.0694, -0.9319,  0.0970,  ..., -0.1464,  1.2998,  0.7842],\n","         [-0.1047, -0.8233, -0.3350,  ...,  0.5329,  0.3711, -0.4627],\n","         ...,\n","         [-0.6005, -1.2779,  0.0248,  ...,  0.3981, -0.3954, -0.5802],\n","         [-1.0199, -0.4791,  0.8248,  ...,  0.9521, -1.2734,  0.5549],\n","         [ 0.7993, -0.0800,  0.8518,  ..., -0.4387, -2.1098,  1.0660]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6218, -0.4058,  0.5320,  ..., -0.4645,  0.5580,  0.9917],\n","        [ 0.4500, -0.2719,  0.1374,  ..., -0.4534,  0.1598,  0.2967],\n","        [ 0.8063, -0.1855, -0.0086,  ..., -0.3097, -0.3335,  0.5519],\n","        ...,\n","        [ 0.6831, -0.6939,  0.6174,  ...,  0.2407, -0.2484,  0.4248],\n","        [ 0.3744, -0.2654, -0.5028,  ..., -0.2112, -0.6196,  0.1325],\n","        [ 0.7072, -0.0720,  0.6158,  ..., -0.4339,  0.1177,  0.8826]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6218, -0.4058,  0.5320,  ..., -0.4645,  0.5580,  0.9917],\n","        [ 0.4500, -0.2719,  0.1374,  ..., -0.4534,  0.1598,  0.2967],\n","        [ 0.8063, -0.1855, -0.0086,  ..., -0.3097, -0.3335,  0.5519],\n","        ...,\n","        [ 0.6831, -0.6939,  0.6174,  ...,  0.2407, -0.2484,  0.4248],\n","        [ 0.3744, -0.2654, -0.5028,  ..., -0.2112, -0.6196,  0.1325],\n","        [ 0.7072, -0.0720,  0.6158,  ..., -0.4339,  0.1177,  0.8826]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.1910,  0.0517,  1.0985,  ..., -0.0618, -0.5920, -0.4509],\n","        [ 0.2417, -0.5157, -0.5700,  ..., -0.5458,  0.0964,  0.0998],\n","        [ 1.7708,  0.0230, -0.8110,  ...,  0.3736, -1.9611,  0.4646],\n","        ...,\n","        [-0.8369,  0.6135, -0.6299,  ...,  0.7044, -0.2604,  0.0032],\n","        [ 0.0710, -1.7343, -0.2754,  ..., -0.0563, -0.8438,  0.8963],\n","        [ 1.0718,  0.2839, -0.5983,  ..., -0.3588, -1.2288,  0.7629]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-6.6312e-01, -8.3974e-01, -1.0128e+00,  ...,  1.9179e-01,\n","          -5.6701e-01,  7.9248e-01],\n","         [ 9.8441e-01, -1.8470e-01, -3.9255e-01,  ...,  8.0924e-01,\n","           6.2290e-01, -3.2013e-01],\n","         [-4.6877e-02, -1.7214e+00,  3.9199e-01,  ...,  6.0515e-01,\n","          -4.4494e-01, -1.8532e-01],\n","         ...,\n","         [ 8.0291e-01, -1.2496e-01, -1.8887e-01,  ..., -7.9693e-02,\n","           9.8029e-01, -2.7417e-01],\n","         [ 1.2315e+00,  1.3547e-01,  3.7072e-01,  ...,  1.4190e-01,\n","          -4.4550e-01,  2.2501e-01],\n","         [ 2.5905e-01,  2.4290e-01, -4.0908e-01,  ...,  3.2144e-01,\n","           1.2641e+00,  1.8121e-01]],\n","\n","        [[-4.2052e-01, -1.5489e+00,  4.7795e-01,  ...,  3.6193e-01,\n","          -1.2971e+00, -1.2600e-01],\n","         [-3.4968e-01, -2.7380e-01,  6.5727e-01,  ...,  4.5693e-01,\n","           3.3068e-01,  2.9512e-01],\n","         [ 7.7964e-01,  1.1104e+00,  6.9151e-01,  ..., -3.6824e-02,\n","          -1.1665e-02,  1.0332e-01],\n","         ...,\n","         [ 4.3816e-01, -9.8316e-01, -6.2480e-01,  ...,  5.6031e-01,\n","          -9.4718e-01,  5.1058e-01],\n","         [-5.6350e-01, -2.4382e+00,  8.8028e-01,  ...,  1.2387e+00,\n","          -1.7681e+00,  6.9208e-02],\n","         [ 7.1849e-01, -1.2594e+00,  7.1795e-01,  ..., -2.0461e-01,\n","          -3.4680e-02, -4.2374e-03]],\n","\n","        [[ 7.9666e-01,  8.0522e-01,  1.1147e+00,  ...,  8.0562e-01,\n","          -4.5926e-01,  3.8370e-01],\n","         [ 2.8785e-01, -7.1245e-01,  7.7467e-01,  ...,  8.5074e-01,\n","          -7.6995e-01,  6.6311e-01],\n","         [ 4.2587e-01, -2.2310e+00,  1.9592e-01,  ...,  9.2345e-01,\n","          -1.2810e+00, -3.3553e-01],\n","         ...,\n","         [ 1.0692e+00,  6.2106e-02,  8.4872e-01,  ...,  4.7416e-01,\n","          -1.5718e+00,  6.0800e-01],\n","         [ 3.8820e-01, -2.3645e-01,  3.4814e-01,  ...,  7.8658e-01,\n","          -2.9730e-01, -7.4514e-02],\n","         [ 4.6020e-01, -1.6057e-03,  7.3374e-01,  ...,  5.2134e-01,\n","          -5.6452e-01,  3.5820e-02]],\n","\n","        ...,\n","\n","        [[ 4.8636e-01, -3.3332e-01, -8.4018e-01,  ..., -2.8346e-01,\n","          -2.8243e-01,  9.7021e-01],\n","         [-7.4826e-01, -1.3812e+00,  3.5480e-01,  ..., -5.0361e-01,\n","           1.0437e+00,  9.7863e-01],\n","         [ 6.5420e-02, -4.1492e-01,  2.4190e-01,  ..., -3.8812e-01,\n","          -3.9308e-01,  2.4981e-01],\n","         ...,\n","         [ 4.7656e-01, -1.5903e+00, -4.2844e-01,  ...,  3.3840e-01,\n","           8.5119e-01,  9.8747e-01],\n","         [ 4.1397e-01, -1.2856e+00, -8.8516e-01,  ...,  8.5865e-01,\n","           5.6592e-01,  7.9452e-01],\n","         [ 5.7706e-01, -9.4037e-01, -1.6260e-01,  ..., -2.5708e-01,\n","          -1.9142e-01,  1.5872e-01]],\n","\n","        [[ 4.7276e-02,  8.3366e-01, -1.8364e-01,  ...,  8.7194e-02,\n","          -2.1843e+00,  9.9366e-01],\n","         [ 1.4082e+00,  2.9624e+00,  7.7684e-01,  ...,  1.0499e+00,\n","          -5.3653e-01, -1.0284e+00],\n","         [ 7.6638e-01,  1.2203e+00, -9.5210e-01,  ...,  2.4223e-01,\n","          -3.1220e-01, -6.0888e-01],\n","         ...,\n","         [ 9.3002e-01,  4.0204e-01,  4.9154e-01,  ...,  6.0202e-01,\n","          -1.3395e+00,  7.4368e-01],\n","         [ 7.5989e-01,  5.8721e-01,  1.2582e+00,  ...,  8.9134e-02,\n","          -2.7777e-01,  7.4520e-01],\n","         [ 3.8708e-01,  1.0413e+00,  7.1263e-01,  ...,  1.1193e-01,\n","          -6.2480e-01,  7.8780e-01]],\n","\n","        [[ 3.8682e-01, -2.1281e-01, -5.5882e-01,  ..., -6.8236e-02,\n","          -3.8551e-01, -3.2082e-01],\n","         [ 1.6374e-01,  7.7585e-02,  6.1997e-01,  ..., -2.3515e-01,\n","           1.0563e+00,  1.1141e+00],\n","         [-3.2528e-01,  3.4490e-02, -3.0443e-02,  ..., -3.7310e-01,\n","           7.4094e-01,  9.8735e-01],\n","         ...,\n","         [ 9.9221e-01, -4.8443e-01,  2.0072e-01,  ..., -4.5238e-01,\n","           6.9544e-01, -8.2872e-02],\n","         [ 9.3442e-01, -7.6904e-01, -1.1833e-02,  ..., -5.4717e-01,\n","           8.1919e-01,  1.0535e-01],\n","         [ 1.2846e-01, -2.8864e-01, -5.4662e-01,  ..., -1.3270e-01,\n","           2.8736e-01,  2.6167e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6890, -0.2886, -0.1453,  ...,  0.3469, -0.4971, -0.3033],\n","        [ 0.5401, -0.0802,  0.7735,  ...,  0.0661,  0.0572,  0.8877],\n","        [ 0.6109, -0.3331,  0.3261,  ...,  0.4897, -0.2125,  0.2208],\n","        ...,\n","        [-0.4261, -0.0619, -0.0254,  ..., -0.4390, -0.2119,  0.4094],\n","        [ 0.5008, -0.4964,  0.1667,  ...,  0.5354,  0.2797,  0.8918],\n","        [ 0.3825, -0.7860,  0.3505,  ..., -0.3754, -0.2984,  0.8630]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6890, -0.2886, -0.1453,  ...,  0.3469, -0.4971, -0.3033],\n","        [ 0.5401, -0.0802,  0.7735,  ...,  0.0661,  0.0572,  0.8877],\n","        [ 0.6109, -0.3331,  0.3261,  ...,  0.4897, -0.2125,  0.2208],\n","        ...,\n","        [-0.4261, -0.0619, -0.0254,  ..., -0.4390, -0.2119,  0.4094],\n","        [ 0.5008, -0.4964,  0.1667,  ...,  0.5354,  0.2797,  0.8918],\n","        [ 0.3825, -0.7860,  0.3505,  ..., -0.3754, -0.2984,  0.8630]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-0.6631, -0.8397, -1.0128,  ...,  0.1918, -0.5670,  0.7925],\n","        [-0.4205, -1.5489,  0.4780,  ...,  0.3619, -1.2971, -0.1260],\n","        [ 0.7967,  0.8052,  1.1147,  ...,  0.8056, -0.4593,  0.3837],\n","        ...,\n","        [ 0.4864, -0.3333, -0.8402,  ..., -0.2835, -0.2824,  0.9702],\n","        [ 0.0473,  0.8337, -0.1836,  ...,  0.0872, -2.1843,  0.9937],\n","        [ 0.3868, -0.2128, -0.5588,  ..., -0.0682, -0.3855, -0.3208]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","Step : 20, Avg Loss : 0.5712\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.8563e-01,  1.3459e-01, -1.2129e+00,  ...,  9.1152e-01,\n","          -4.8185e-01,  2.7338e-01],\n","         [ 4.9401e-01, -1.1580e+00, -2.9592e-01,  ..., -1.1447e-01,\n","           9.2681e-01,  5.5396e-01],\n","         [ 3.6193e-01, -2.2793e-01, -5.2777e-01,  ...,  8.2017e-01,\n","           1.3516e+00,  3.8682e-01],\n","         ...,\n","         [ 9.1136e-01, -1.3396e+00, -6.6579e-01,  ...,  5.1250e-01,\n","          -9.2183e-01,  1.0980e+00],\n","         [ 6.2392e-01, -3.3687e-01, -7.1146e-01,  ...,  4.6069e-02,\n","          -8.6936e-01,  6.3678e-01],\n","         [ 8.0569e-01, -3.6933e-01, -8.0975e-01,  ...,  1.1330e+00,\n","           1.8040e-01,  6.6193e-01]],\n","\n","        [[-1.9164e-02, -1.7618e-01, -5.2985e-01,  ...,  4.0873e-01,\n","           3.4225e-04, -5.2778e-02],\n","         [ 5.5433e-01, -2.1014e-01, -5.7062e-01,  ..., -1.8985e-01,\n","           9.9818e-01, -4.4915e-01],\n","         [-1.3259e-01,  2.2154e-01,  3.7669e-01,  ...,  1.2840e-02,\n","           4.9800e-02,  5.6927e-01],\n","         ...,\n","         [ 3.3578e-01, -6.5885e-01,  6.7702e-01,  ..., -4.3744e-01,\n","          -2.4528e-01,  2.1646e-01],\n","         [ 2.9913e-01, -1.0506e+00,  6.9807e-01,  ..., -5.3212e-01,\n","           1.2699e-01,  4.6266e-02],\n","         [ 3.0324e-02, -2.8623e-01, -6.1165e-01,  ...,  4.2682e-01,\n","           1.1915e+00, -4.9582e-01]],\n","\n","        [[ 1.1395e-01, -3.1872e-01, -5.4654e-01,  ..., -3.6983e-02,\n","          -9.0058e-01,  9.7573e-01],\n","         [-1.2437e+00, -3.4364e-01,  8.8253e-01,  ...,  3.9466e-01,\n","           7.0952e-02,  4.0109e-01],\n","         [-9.3106e-01, -1.0300e+00,  8.9884e-01,  ...,  1.4480e-01,\n","          -6.2220e-01, -3.6344e-01],\n","         ...,\n","         [ 8.8869e-01,  7.4272e-01,  2.9475e-01,  ..., -7.3961e-01,\n","          -4.6041e-01,  9.6174e-01],\n","         [ 1.0411e+00,  3.1420e-01, -8.0604e-02,  ..., -4.5992e-01,\n","           8.5104e-03,  7.8171e-01],\n","         [ 9.4010e-01,  9.7552e-02, -4.7513e-01,  ..., -2.4454e-01,\n","           3.4816e-01, -1.2990e-01]],\n","\n","        ...,\n","\n","        [[ 3.8947e-01,  1.3829e-02,  1.3655e-01,  ..., -3.9113e-01,\n","           2.6062e-01, -9.0446e-04],\n","         [ 7.8601e-01, -3.8126e-01, -1.5833e-01,  ...,  4.1535e-01,\n","          -1.2158e-01, -3.2740e-01],\n","         [ 9.9105e-01,  3.1995e-01,  2.5173e-01,  ..., -6.1593e-01,\n","           1.2897e+00, -1.1646e+00],\n","         ...,\n","         [ 9.2852e-01, -1.0880e+00, -3.0389e-01,  ...,  4.3414e-02,\n","           3.1397e-01,  3.0655e-01],\n","         [ 1.1795e+00, -1.6859e+00, -3.7958e-01,  ..., -3.7621e-01,\n","           1.9408e-01,  3.2551e-01],\n","         [ 1.3994e+00,  9.0702e-01,  3.2347e-01,  ...,  6.2953e-01,\n","          -4.9773e-01,  3.5032e-01]],\n","\n","        [[ 4.7016e-01, -5.6248e-01, -4.8805e-01,  ..., -1.5169e-01,\n","          -6.0417e-01,  1.1346e+00],\n","         [ 1.2760e+00, -2.0822e-01,  6.1757e-01,  ..., -3.8435e-01,\n","          -2.8456e-01,  2.1967e+00],\n","         [ 8.9256e-01,  4.9599e-01, -1.4434e-02,  ...,  1.0859e+00,\n","          -1.2380e-01,  1.5005e+00],\n","         ...,\n","         [ 9.0584e-03,  1.3689e-02,  4.8504e-01,  ..., -5.2638e-01,\n","          -2.8064e-01,  7.2820e-01],\n","         [ 3.0831e-01, -1.7730e-01,  1.9487e-01,  ..., -7.5886e-01,\n","           2.1247e-01,  8.0573e-01],\n","         [-1.5668e-02, -2.0726e-01,  7.2953e-01,  ..., -5.2052e-01,\n","           4.8016e-01, -2.1483e-01]],\n","\n","        [[-5.4649e-01, -5.5655e-01, -8.4559e-01,  ...,  7.0404e-01,\n","          -4.9073e-01, -1.5384e-01],\n","         [-1.1122e-01, -1.1079e+00, -1.9503e-01,  ...,  1.1324e+00,\n","           5.2671e-01, -7.1059e-01],\n","         [-3.4631e-01, -2.2410e+00, -1.4373e-01,  ...,  9.5690e-01,\n","          -1.5967e-01, -6.9092e-01],\n","         ...,\n","         [ 3.7192e-01,  3.1229e-01, -5.1901e-01,  ...,  4.0475e-01,\n","          -5.7976e-02, -4.3027e-01],\n","         [ 1.1327e-01,  2.1778e-01, -3.5430e-01,  ..., -1.1568e-01,\n","          -2.8488e-01,  3.8583e-02],\n","         [-1.2262e-01, -6.4469e-01, -2.2062e-01,  ...,  6.9449e-01,\n","          -8.2210e-01, -1.1891e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0594, -0.4832,  0.6246,  ..., -0.1116, -0.1267,  0.5980],\n","        [ 0.2794, -0.7778,  0.5732,  ..., -0.0437, -0.2801,  0.2539],\n","        [ 0.5542,  0.3589,  0.4015,  ..., -0.0666,  0.5097,  0.9676],\n","        ...,\n","        [ 0.5868, -0.5479,  0.1848,  ..., -0.2377, -0.2556,  0.8833],\n","        [ 0.8435,  0.2268,  0.2920,  ..., -0.2269,  0.0692,  0.1453],\n","        [ 0.9113, -0.7337,  0.6178,  ..., -0.5371,  0.2253,  0.8156]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.0594, -0.4832,  0.6246,  ..., -0.1116, -0.1267,  0.5980],\n","        [ 0.2794, -0.7778,  0.5732,  ..., -0.0437, -0.2801,  0.2539],\n","        [ 0.5542,  0.3589,  0.4015,  ..., -0.0666,  0.5097,  0.9676],\n","        ...,\n","        [ 0.5868, -0.5479,  0.1848,  ..., -0.2377, -0.2556,  0.8833],\n","        [ 0.8435,  0.2268,  0.2920,  ..., -0.2269,  0.0692,  0.1453],\n","        [ 0.9113, -0.7337,  0.6178,  ..., -0.5371,  0.2253,  0.8156]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-1.8563e-01,  1.3459e-01, -1.2129e+00,  ...,  9.1152e-01,\n","         -4.8185e-01,  2.7338e-01],\n","        [-1.9164e-02, -1.7618e-01, -5.2985e-01,  ...,  4.0873e-01,\n","          3.4225e-04, -5.2778e-02],\n","        [ 1.1395e-01, -3.1872e-01, -5.4654e-01,  ..., -3.6983e-02,\n","         -9.0058e-01,  9.7573e-01],\n","        ...,\n","        [ 3.8947e-01,  1.3829e-02,  1.3655e-01,  ..., -3.9113e-01,\n","          2.6062e-01, -9.0446e-04],\n","        [ 4.7016e-01, -5.6248e-01, -4.8805e-01,  ..., -1.5169e-01,\n","         -6.0417e-01,  1.1346e+00],\n","        [-5.4649e-01, -5.5655e-01, -8.4559e-01,  ...,  7.0404e-01,\n","         -4.9073e-01, -1.5384e-01]], device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.1572e-01, -1.4278e+00, -4.8526e-01,  ..., -6.5364e-01,\n","          -1.6815e-01,  6.2110e-01],\n","         [ 1.3504e-01, -1.9020e+00,  5.1954e-02,  ..., -4.7719e-01,\n","           4.3526e-01,  3.7927e-01],\n","         [ 1.2375e-02, -1.1461e-01, -1.1994e+00,  ...,  6.8124e-01,\n","          -2.1741e-02, -2.7050e-01],\n","         ...,\n","         [ 5.0845e-01, -5.9008e-01, -2.7779e-01,  ..., -1.4733e-01,\n","           1.7642e-01,  4.0275e-01],\n","         [ 1.2942e-01, -1.3190e+00, -6.0113e-02,  ..., -5.3800e-02,\n","          -1.8544e-01,  1.0780e+00],\n","         [ 2.7388e-01, -1.5026e+00, -1.0776e-01,  ...,  2.3585e-01,\n","          -3.1071e-01,  1.0361e+00]],\n","\n","        [[ 4.2664e-01, -3.7769e-01,  2.5960e-01,  ..., -5.0106e-01,\n","           1.6962e-01,  3.6021e-01],\n","         [ 7.2955e-01, -5.3405e-01,  8.1907e-01,  ..., -1.0912e-01,\n","           8.1520e-01, -5.1674e-01],\n","         [ 5.6985e-01, -8.1747e-01,  9.6191e-01,  ...,  2.0140e-01,\n","           5.5187e-01, -6.4251e-01],\n","         ...,\n","         [ 3.5587e-01,  1.0150e-01, -1.4935e-01,  ..., -3.4652e-01,\n","          -1.0622e+00,  2.7566e-01],\n","         [ 8.0828e-01,  3.1340e-01, -5.2432e-01,  ..., -2.7497e-01,\n","          -1.0254e+00,  1.0006e+00],\n","         [ 4.8846e-01, -1.0752e+00,  3.6460e-01,  ..., -5.2349e-01,\n","          -1.1587e+00, -3.7795e-01]],\n","\n","        [[ 4.0632e-01, -2.8530e-01, -1.5132e-01,  ..., -1.5613e-01,\n","          -9.6778e-01,  3.2093e-01],\n","         [ 9.5276e-01, -7.0418e-01,  1.5334e+00,  ...,  1.5929e+00,\n","           4.7027e-01,  8.0003e-01],\n","         [ 1.3594e+00,  7.7166e-01, -1.7621e-01,  ...,  1.1163e+00,\n","          -1.6342e-01, -2.0933e-01],\n","         ...,\n","         [ 1.0385e+00, -1.6780e+00,  6.1382e-01,  ...,  5.8359e-01,\n","          -3.8022e-02,  1.2110e+00],\n","         [ 6.6038e-01, -2.5534e+00,  5.7532e-01,  ...,  5.9327e-01,\n","          -8.1951e-02,  1.1857e+00],\n","         [ 1.0841e+00, -1.0773e+00,  6.4312e-01,  ...,  9.9706e-01,\n","           4.1795e-01,  1.6012e+00]],\n","\n","        ...,\n","\n","        [[ 9.6182e-01,  2.6237e-01, -8.1174e-02,  ...,  2.7837e-01,\n","          -1.5319e+00,  1.1066e+00],\n","         [ 1.0525e+00,  2.8083e-01,  6.0475e-01,  ..., -2.5487e-01,\n","          -2.7755e-01, -3.0665e-01],\n","         [ 5.1320e-01, -3.2279e-01,  8.6264e-01,  ...,  4.6910e-01,\n","          -1.4849e+00,  3.6800e-01],\n","         ...,\n","         [ 1.2350e+00,  1.0587e+00,  5.9837e-01,  ...,  2.8089e-01,\n","          -2.4432e-01,  9.7225e-01],\n","         [-4.1608e-02, -6.7998e-01, -9.3844e-04,  ...,  3.7873e-01,\n","           7.1384e-02,  1.8324e+00],\n","         [ 1.2229e+00, -2.1360e-01,  5.8935e-01,  ...,  7.8449e-01,\n","          -3.8554e-01,  1.4069e+00]],\n","\n","        [[ 7.5314e-02,  8.6838e-01, -1.8254e-01,  ...,  2.8486e-01,\n","          -7.0928e-01,  8.6143e-01],\n","         [ 2.2582e-01,  8.3935e-01,  8.1799e-01,  ...,  7.2368e-01,\n","           1.1301e+00,  1.1671e+00],\n","         [ 9.2485e-01, -2.8049e-02,  7.7330e-01,  ...,  7.6807e-01,\n","           8.3038e-01,  1.5126e+00],\n","         ...,\n","         [ 7.6612e-01,  2.8821e-01,  9.4693e-01,  ...,  4.9806e-01,\n","          -1.5745e-01,  5.0584e-01],\n","         [ 1.2375e+00, -4.7532e-01,  2.0755e-01,  ...,  3.4905e-01,\n","          -2.4626e-01,  3.8836e-01],\n","         [ 7.2353e-01, -4.0981e-01,  6.3144e-01,  ...,  4.5310e-01,\n","          -6.9410e-01,  5.7408e-01]],\n","\n","        [[ 6.4186e-01, -2.7870e-02, -5.3857e-01,  ..., -1.5345e-01,\n","          -8.6966e-01, -5.0510e-02],\n","         [ 5.8974e-01, -4.1230e-01, -2.3810e-01,  ..., -9.3172e-01,\n","           1.7349e-01, -1.0351e+00],\n","         [-2.0469e-01,  4.7851e-01,  1.0592e+00,  ...,  2.1724e-01,\n","           7.7340e-01,  2.5661e-01],\n","         ...,\n","         [ 6.8178e-01,  7.7872e-01,  1.0248e+00,  ...,  5.5829e-01,\n","           3.1673e-01,  3.3631e-01],\n","         [ 5.6045e-01,  2.1064e+00,  9.2373e-01,  ...,  1.1473e+00,\n","           7.1742e-01,  6.2924e-01],\n","         [ 1.3851e+00,  1.7964e+00,  4.9155e-01,  ...,  7.2762e-01,\n","           4.8084e-01,  3.5043e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0252,  0.0113,  0.5415,  ...,  0.1473, -0.6665,  0.3284],\n","        [ 0.0158, -0.5569,  0.0840,  ..., -0.1218,  0.0493,  0.9832],\n","        [ 0.6557, -0.5129, -0.6040,  ..., -0.9039, -0.1693,  0.8436],\n","        ...,\n","        [ 0.7429, -0.2639,  0.7678,  ..., -0.4327,  0.0323,  0.9009],\n","        [ 0.4541, -0.5566,  0.7292,  ..., -0.4790, -0.0955,  0.9924],\n","        [ 0.6130, -0.4510,  0.3289,  ..., -0.0126,  0.1426,  0.9884]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.0252,  0.0113,  0.5415,  ...,  0.1473, -0.6665,  0.3284],\n","        [ 0.0158, -0.5569,  0.0840,  ..., -0.1218,  0.0493,  0.9832],\n","        [ 0.6557, -0.5129, -0.6040,  ..., -0.9039, -0.1693,  0.8436],\n","        ...,\n","        [ 0.7429, -0.2639,  0.7678,  ..., -0.4327,  0.0323,  0.9009],\n","        [ 0.4541, -0.5566,  0.7292,  ..., -0.4790, -0.0955,  0.9924],\n","        [ 0.6130, -0.4510,  0.3289,  ..., -0.0126,  0.1426,  0.9884]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.1157, -1.4278, -0.4853,  ..., -0.6536, -0.1681,  0.6211],\n","        [ 0.4266, -0.3777,  0.2596,  ..., -0.5011,  0.1696,  0.3602],\n","        [ 0.4063, -0.2853, -0.1513,  ..., -0.1561, -0.9678,  0.3209],\n","        ...,\n","        [ 0.9618,  0.2624, -0.0812,  ...,  0.2784, -1.5319,  1.1066],\n","        [ 0.0753,  0.8684, -0.1825,  ...,  0.2849, -0.7093,  0.8614],\n","        [ 0.6419, -0.0279, -0.5386,  ..., -0.1535, -0.8697, -0.0505]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 9.2904e-01, -1.0783e+00,  5.4495e-01,  ..., -6.6244e-01,\n","          -3.5176e-01, -9.7382e-01],\n","         [ 2.7144e-01, -1.4679e+00,  4.3063e-01,  ..., -6.1136e-02,\n","           2.5129e+00,  7.2398e-01],\n","         [-1.7928e-01, -4.9890e-01, -1.5402e+00,  ...,  3.9630e-01,\n","           9.3308e-01, -6.3279e-01],\n","         ...,\n","         [-6.5796e-02,  7.4131e-01,  5.4423e-01,  ..., -9.0950e-01,\n","          -3.2608e-01, -4.2943e-01],\n","         [ 9.4945e-01,  7.2679e-01, -5.4476e-01,  ..., -6.1866e-01,\n","          -1.4608e+00, -9.0342e-01],\n","         [ 1.0222e+00,  4.6823e-04,  8.6822e-01,  ..., -6.0166e-01,\n","           1.6748e-01, -3.1462e-01]],\n","\n","        [[ 6.3858e-01, -3.5753e-01, -3.0372e-01,  ...,  1.0620e+00,\n","          -4.6670e-01,  2.4441e-01],\n","         [-6.9146e-01, -2.6729e+00,  2.4165e-01,  ...,  9.2451e-01,\n","          -8.1286e-01, -3.7388e-01],\n","         [ 1.0557e+00, -2.3653e+00, -2.3437e-01,  ...,  9.1723e-01,\n","          -1.1804e+00, -2.1658e-01],\n","         ...,\n","         [ 1.0382e+00, -2.6075e-01,  2.4961e-01,  ...,  8.7818e-01,\n","          -3.3612e-01,  4.4049e-01],\n","         [ 1.1513e+00, -1.1174e+00, -2.2763e-01,  ...,  8.6182e-01,\n","           1.3526e-01,  9.2066e-01],\n","         [ 6.6258e-01,  1.1990e-01, -3.0449e-02,  ...,  1.8505e-01,\n","          -3.3586e-02,  1.0047e+00]],\n","\n","        [[ 6.9895e-01, -2.9215e-01,  1.9242e-01,  ..., -8.0749e-02,\n","          -1.7683e-01,  6.9510e-02],\n","         [ 1.5590e+00, -1.3622e+00,  1.4697e-03,  ...,  1.3553e+00,\n","           1.2353e+00, -4.3174e-01],\n","         [-9.9501e-02, -9.4217e-01,  2.7226e-01,  ...,  1.3510e+00,\n","           2.6244e-01, -4.8840e-01],\n","         ...,\n","         [ 2.1608e+00, -9.7140e-01,  1.4868e-01,  ..., -2.0082e-01,\n","           1.5239e-01,  1.8189e-01],\n","         [ 1.0923e+00, -1.2336e+00,  1.3722e+00,  ...,  3.6404e-01,\n","          -1.7034e-01, -1.1855e-02],\n","         [ 1.3848e+00, -7.3581e-01, -2.6443e-01,  ...,  4.0305e-01,\n","          -5.0043e-01, -4.6156e-01]],\n","\n","        ...,\n","\n","        [[ 2.1884e-01, -1.6449e+00, -5.5026e-01,  ...,  6.8408e-01,\n","          -1.5892e+00,  1.0197e+00],\n","         [ 9.8916e-03, -8.8706e-01, -4.3325e-03,  ...,  4.9750e-02,\n","           8.1541e-01,  5.9599e-01],\n","         [ 6.7098e-01, -1.5600e+00,  8.9944e-02,  ...,  3.5201e-01,\n","           3.2836e-01,  3.5479e-01],\n","         ...,\n","         [ 5.0291e-01, -5.9143e-01,  5.9247e-01,  ...,  7.8855e-01,\n","           1.8689e-01,  5.5101e-01],\n","         [ 4.5374e-01, -1.2378e+00,  2.7387e-01,  ...,  5.2504e-02,\n","          -1.6732e-01,  1.0704e+00],\n","         [ 6.4153e-01, -1.2486e+00,  6.0882e-01,  ..., -4.5938e-01,\n","           2.9532e-01,  7.8840e-01]],\n","\n","        [[-2.9351e-01, -1.7126e+00, -3.1922e-01,  ...,  5.7732e-01,\n","          -3.2372e-01,  7.8864e-01],\n","         [ 3.4783e-01, -1.7426e+00, -4.7680e-02,  ..., -3.5493e-02,\n","           5.7710e-01,  1.7041e-01],\n","         [ 5.0507e-01, -2.6864e-01, -4.8704e-01,  ..., -9.4025e-02,\n","           2.4817e-01, -2.6302e-01],\n","         ...,\n","         [-8.9076e-02, -8.6928e-01, -7.3173e-01,  ...,  4.1619e-01,\n","          -7.9811e-01,  1.3164e+00],\n","         [ 3.5973e-01, -2.0791e-01, -1.7539e-01,  ...,  8.2321e-01,\n","          -2.5938e-01,  1.3221e+00],\n","         [ 4.2041e-01, -1.4313e+00, -8.2525e-02,  ...,  6.7787e-01,\n","          -7.2878e-01,  1.0694e+00]],\n","\n","        [[ 6.8341e-01,  9.7734e-02, -3.4208e-02,  ...,  1.0952e+00,\n","          -1.9016e+00,  1.3204e+00],\n","         [-1.3085e-01, -6.8050e-01, -3.6642e-01,  ...,  1.6267e+00,\n","          -5.0499e-01,  4.7143e-01],\n","         [-3.4916e-01, -6.0669e-01, -2.0011e-01,  ...,  1.1759e+00,\n","          -5.5687e-01,  6.5112e-01],\n","         ...,\n","         [ 7.3821e-01,  4.2425e-01,  5.2587e-01,  ...,  1.1629e+00,\n","          -1.8307e+00,  1.5661e-01],\n","         [ 1.0800e+00,  6.1965e-01,  6.8732e-01,  ...,  1.2570e+00,\n","          -1.0703e+00,  9.3447e-01],\n","         [ 1.6769e+00,  2.8732e-01,  3.6878e-01,  ...,  1.4419e+00,\n","          -1.3039e+00,  8.9873e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2677, -0.3278,  0.7125,  ..., -0.1078,  0.0462,  0.7355],\n","        [ 0.5932, -0.5210,  0.4264,  ..., -0.2507, -0.5413,  0.4077],\n","        [ 0.4562, -0.4685,  0.3809,  ..., -0.1823, -0.0413,  0.9583],\n","        ...,\n","        [ 0.8136, -0.2288,  0.4931,  ..., -0.3600,  0.0073,  0.9810],\n","        [ 0.3137, -0.4212,  0.2740,  ..., -0.0219, -0.1147,  0.8096],\n","        [ 0.6677,  0.0192,  0.4719,  ...,  0.3288, -0.0287,  0.9659]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.2677, -0.3278,  0.7125,  ..., -0.1078,  0.0462,  0.7355],\n","        [ 0.5932, -0.5210,  0.4264,  ..., -0.2507, -0.5413,  0.4077],\n","        [ 0.4562, -0.4685,  0.3809,  ..., -0.1823, -0.0413,  0.9583],\n","        ...,\n","        [ 0.8136, -0.2288,  0.4931,  ..., -0.3600,  0.0073,  0.9810],\n","        [ 0.3137, -0.4212,  0.2740,  ..., -0.0219, -0.1147,  0.8096],\n","        [ 0.6677,  0.0192,  0.4719,  ...,  0.3288, -0.0287,  0.9659]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.9290, -1.0783,  0.5450,  ..., -0.6624, -0.3518, -0.9738],\n","        [ 0.6386, -0.3575, -0.3037,  ...,  1.0620, -0.4667,  0.2444],\n","        [ 0.6990, -0.2921,  0.1924,  ..., -0.0807, -0.1768,  0.0695],\n","        ...,\n","        [ 0.2188, -1.6449, -0.5503,  ...,  0.6841, -1.5892,  1.0197],\n","        [-0.2935, -1.7126, -0.3192,  ...,  0.5773, -0.3237,  0.7886],\n","        [ 0.6834,  0.0977, -0.0342,  ...,  1.0952, -1.9016,  1.3204]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-4.3534e-01, -1.7971e-01, -1.0532e+00,  ...,  4.5491e-01,\n","          -1.1473e+00,  2.5209e-01],\n","         [ 1.5163e+00,  1.9640e-01,  5.4056e-02,  ...,  3.6634e-02,\n","          -8.9693e-01,  5.9457e-01],\n","         [-7.5595e-01,  1.7356e+00,  3.2861e-01,  ..., -5.3882e-01,\n","          -7.9797e-01,  5.5274e-03],\n","         ...,\n","         [ 2.9644e-01, -1.2152e+00, -1.7392e-01,  ...,  5.5612e-01,\n","           4.0995e-01,  1.3802e-01],\n","         [ 8.0421e-01, -2.6031e-01, -3.2249e-01,  ...,  8.6679e-02,\n","           2.9157e-01,  5.8839e-01],\n","         [ 1.0209e+00, -4.5521e-01, -3.8609e-01,  ...,  1.0134e+00,\n","          -5.5903e-01,  3.0039e-01]],\n","\n","        [[ 1.1559e+00, -3.7610e-01,  2.6962e-01,  ...,  2.8981e-02,\n","          -1.2653e+00,  1.6823e+00],\n","         [-8.7834e-01, -7.5915e-01, -5.4178e-01,  ...,  8.2871e-01,\n","           1.3379e+00,  1.0777e+00],\n","         [-3.4197e-01, -7.3517e-01,  5.8489e-01,  ...,  8.9552e-01,\n","          -6.9492e-01,  8.6742e-01],\n","         ...,\n","         [ 7.2099e-01, -1.8443e-01,  3.0571e-01,  ...,  8.1319e-01,\n","          -1.3604e-01,  6.9699e-01],\n","         [ 1.2835e+00,  2.6559e-02, -2.1414e-01,  ...,  3.7151e-01,\n","          -4.5881e-01,  2.0903e-01],\n","         [ 1.5571e+00, -2.4754e-01,  7.2488e-02,  ...,  2.4794e-01,\n","          -6.6952e-01,  6.2274e-01]],\n","\n","        [[ 4.5197e-01,  2.7936e-01, -2.0574e-01,  ...,  1.3226e+00,\n","          -3.1720e-01, -6.0741e-01],\n","         [ 1.3978e+00, -1.3108e+00,  4.8607e-01,  ...,  9.3635e-02,\n","           2.3725e+00, -5.4114e-01],\n","         [-5.0022e-01, -1.4305e+00, -2.2756e-01,  ..., -1.0906e-01,\n","           9.8817e-01, -6.2721e-01],\n","         ...,\n","         [ 8.7572e-01, -3.0196e-01, -2.6139e-01,  ...,  2.2209e-01,\n","           1.3171e+00, -2.4057e-01],\n","         [ 5.0292e-01, -3.2952e-01, -6.6497e-01,  ...,  3.5338e-01,\n","           9.7464e-01,  2.6788e-01],\n","         [ 5.9632e-02,  8.6125e-01, -2.4278e-01,  ...,  2.9213e-01,\n","           2.1739e-01,  8.8325e-01]],\n","\n","        ...,\n","\n","        [[ 2.2476e-01, -1.4775e+00, -1.0463e-01,  ...,  5.0541e-01,\n","          -8.7280e-01, -9.4809e-02],\n","         [ 9.6298e-01, -8.5328e-01,  4.4678e-01,  ...,  4.6867e-01,\n","           4.7317e-01,  2.7955e-01],\n","         [-5.4300e-01,  8.7276e-01,  4.5878e-02,  ...,  2.9019e-01,\n","          -1.5222e+00,  5.5299e-01],\n","         ...,\n","         [-7.2038e-03, -7.1373e-01, -9.7190e-01,  ...,  1.0542e+00,\n","           2.2214e-01,  1.3965e-01],\n","         [ 5.4625e-01, -2.2686e+00, -2.7502e-01,  ...,  4.5374e-01,\n","          -1.5751e+00, -4.9063e-02],\n","         [ 7.8484e-01, -1.1468e+00,  4.4379e-01,  ...,  7.1801e-01,\n","          -1.3686e+00, -5.4424e-01]],\n","\n","        [[-2.9388e-02,  1.8224e-04,  8.0853e-01,  ...,  6.7063e-01,\n","          -7.3275e-03, -2.0386e-01],\n","         [ 3.0688e-01, -9.7679e-01,  7.4445e-03,  ..., -5.1105e-03,\n","          -6.2411e-01,  9.2577e-01],\n","         [-9.0109e-02, -1.8651e+00,  5.8247e-02,  ...,  5.5744e-01,\n","          -1.0231e+00,  5.2487e-01],\n","         ...,\n","         [ 1.7741e-01, -9.6375e-02,  2.7383e-02,  ...,  1.0261e+00,\n","          -1.0362e-01, -3.7426e-01],\n","         [ 3.9733e-02, -1.0663e+00,  8.4224e-02,  ...,  6.1515e-01,\n","           1.2189e+00, -1.6092e-01],\n","         [ 6.6276e-01, -1.0845e+00,  4.2574e-01,  ...,  6.8327e-01,\n","           6.1051e-01,  2.2504e-01]],\n","\n","        [[ 3.3370e-01, -4.5525e-01,  1.1024e-01,  ...,  1.0398e+00,\n","          -1.2036e+00,  1.6506e+00],\n","         [ 5.5685e-01, -2.2885e+00,  2.0681e-01,  ...,  4.7924e-01,\n","           2.6504e-01,  1.0983e+00],\n","         [-5.8516e-01,  4.3464e-02, -5.7032e-01,  ...,  2.4601e-01,\n","          -3.6524e-01,  6.9568e-01],\n","         ...,\n","         [ 1.1829e+00, -2.8111e-01,  8.3598e-02,  ...,  4.9347e-01,\n","          -1.4731e+00,  5.7934e-01],\n","         [ 1.1944e+00, -1.1555e+00,  4.3262e-01,  ...,  8.9110e-01,\n","          -2.9725e-01,  1.5362e+00],\n","         [ 1.0026e+00, -8.3939e-01,  9.4713e-02,  ...,  1.1623e+00,\n","          -8.1287e-02,  1.1906e+00]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5733, -0.6015,  0.6714,  ...,  0.0731,  0.1554, -0.5101],\n","        [ 0.7039, -0.2537,  0.3935,  ..., -0.0197, -0.0107,  0.3587],\n","        [ 0.8141, -0.5439,  0.5629,  ..., -0.3659, -0.0172,  0.9603],\n","        ...,\n","        [ 0.5841, -0.0852, -0.0796,  ..., -0.0603,  0.2601,  0.9784],\n","        [ 0.6797, -0.7859,  0.5481,  ..., -0.5859, -0.0226,  0.9872],\n","        [ 0.8777, -0.4150,  0.6421,  ...,  0.2400, -0.1901,  0.8376]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.5733, -0.6015,  0.6714,  ...,  0.0731,  0.1554, -0.5101],\n","        [ 0.7039, -0.2537,  0.3935,  ..., -0.0197, -0.0107,  0.3587],\n","        [ 0.8141, -0.5439,  0.5629,  ..., -0.3659, -0.0172,  0.9603],\n","        ...,\n","        [ 0.5841, -0.0852, -0.0796,  ..., -0.0603,  0.2601,  0.9784],\n","        [ 0.6797, -0.7859,  0.5481,  ..., -0.5859, -0.0226,  0.9872],\n","        [ 0.8777, -0.4150,  0.6421,  ...,  0.2400, -0.1901,  0.8376]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-4.3534e-01, -1.7971e-01, -1.0532e+00,  ...,  4.5491e-01,\n","         -1.1473e+00,  2.5209e-01],\n","        [ 1.1559e+00, -3.7610e-01,  2.6962e-01,  ...,  2.8981e-02,\n","         -1.2653e+00,  1.6823e+00],\n","        [ 4.5197e-01,  2.7936e-01, -2.0574e-01,  ...,  1.3226e+00,\n","         -3.1720e-01, -6.0741e-01],\n","        ...,\n","        [ 2.2476e-01, -1.4775e+00, -1.0463e-01,  ...,  5.0541e-01,\n","         -8.7280e-01, -9.4809e-02],\n","        [-2.9388e-02,  1.8224e-04,  8.0853e-01,  ...,  6.7063e-01,\n","         -7.3275e-03, -2.0386e-01],\n","        [ 3.3370e-01, -4.5525e-01,  1.1024e-01,  ...,  1.0398e+00,\n","         -1.2036e+00,  1.6506e+00]], device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.4430e-01, -1.0646e+00, -5.0894e-01,  ...,  4.4455e-01,\n","           4.2010e-02,  3.4263e-01],\n","         [ 2.1738e-01, -7.6985e-01, -8.3104e-02,  ...,  5.4550e-01,\n","           9.6635e-01, -5.5804e-01],\n","         [ 6.1545e-01,  6.5333e-01,  1.0003e+00,  ..., -1.9536e-01,\n","           5.7051e-01, -1.7598e-01],\n","         ...,\n","         [ 1.4476e+00, -1.8077e-01, -5.3411e-01,  ...,  6.9521e-01,\n","           3.7158e-01,  4.1958e-01],\n","         [ 1.0362e+00, -1.1359e+00,  2.8082e-01,  ...,  1.8706e-02,\n","           5.2974e-01,  5.1803e-01],\n","         [ 7.5154e-01, -3.5563e-01,  3.2863e-01,  ...,  2.6564e-01,\n","           5.0024e-01,  6.5666e-01]],\n","\n","        [[ 1.3295e+00, -1.1720e+00,  3.5212e-01,  ...,  1.0247e+00,\n","          -1.3312e+00,  1.0549e+00],\n","         [ 4.7924e-01, -2.6100e+00,  4.7282e-01,  ...,  5.9350e-01,\n","           4.4058e-01, -5.1426e-01],\n","         [ 1.1043e+00, -7.4586e-01, -1.5110e-03,  ...,  1.8366e+00,\n","          -9.6875e-01,  1.1773e+00],\n","         ...,\n","         [ 1.3493e+00, -4.3425e-01,  5.9716e-01,  ...,  9.3913e-01,\n","          -1.3174e+00,  1.1492e+00],\n","         [ 1.7127e+00, -9.3956e-01,  8.5520e-01,  ...,  9.2608e-01,\n","          -1.9132e+00,  7.4510e-01],\n","         [ 1.8411e+00, -4.2983e-01,  9.7296e-01,  ...,  1.0695e+00,\n","          -1.4744e+00,  1.6639e+00]],\n","\n","        [[-5.7584e-02, -1.0991e+00, -1.1467e+00,  ...,  3.0876e-01,\n","          -1.4179e+00,  2.0917e+00],\n","         [ 6.5057e-01, -3.6513e-01, -7.2918e-01,  ...,  1.0004e-01,\n","          -7.3908e-01,  1.3943e+00],\n","         [ 1.6962e-01, -8.6968e-01, -5.7795e-01,  ...,  1.9252e-01,\n","           4.0793e-02,  1.9875e+00],\n","         ...,\n","         [ 8.3642e-01,  1.0735e-01,  2.4031e-01,  ...,  8.4184e-01,\n","          -3.7191e-01,  1.1599e+00],\n","         [ 9.2196e-01,  3.2684e-01,  3.8672e-01,  ...,  8.9867e-01,\n","          -3.3031e-01,  1.1633e+00],\n","         [ 5.4863e-01, -5.4565e-01,  2.9265e-01,  ...,  2.4773e-01,\n","           6.7821e-03,  1.2071e+00]],\n","\n","        ...,\n","\n","        [[ 7.0511e-01, -4.2114e-01,  8.2591e-01,  ...,  8.4375e-01,\n","           6.4861e-01,  6.8781e-01],\n","         [ 4.4792e-01, -1.4244e+00, -2.9656e-01,  ..., -6.3766e-01,\n","           1.5588e+00,  2.9023e-01],\n","         [ 3.6911e-01,  1.1719e+00,  9.3827e-01,  ...,  3.1310e-01,\n","           1.9929e+00,  6.9963e-01],\n","         ...,\n","         [ 1.1380e+00, -4.4603e-01,  1.8821e-01,  ..., -4.3272e-02,\n","           1.2143e+00, -1.7392e-01],\n","         [ 9.9895e-01, -6.1606e-01,  2.3885e-01,  ...,  3.8810e-01,\n","           7.8797e-01,  6.9432e-01],\n","         [ 1.2127e+00, -6.4226e-01,  2.1557e-01,  ...,  2.6822e-01,\n","           7.2260e-01, -3.9751e-02]],\n","\n","        [[-5.9914e-01, -1.4478e+00, -4.7684e-01,  ..., -8.3854e-02,\n","          -1.7519e-02,  8.1752e-01],\n","         [ 2.7424e-01,  2.3515e-02, -3.9038e-01,  ...,  1.4488e-01,\n","           3.5815e-01,  1.3399e+00],\n","         [ 4.0944e-01, -8.7991e-01,  7.6151e-01,  ...,  4.9947e-01,\n","          -5.8351e-02,  1.1179e+00],\n","         ...,\n","         [ 4.9729e-01, -1.6263e+00,  2.1761e-01,  ..., -5.5665e-01,\n","          -1.3678e+00,  6.2490e-01],\n","         [-3.2679e-01, -1.5130e+00,  7.3322e-01,  ...,  1.5298e-01,\n","          -7.8664e-01,  7.4085e-01],\n","         [ 1.8332e-01, -1.1832e+00, -4.3325e-01,  ...,  3.3681e-01,\n","          -1.3053e-01,  7.1877e-01]],\n","\n","        [[ 1.1134e+00,  4.2536e-01, -1.9740e-01,  ...,  2.7381e-01,\n","          -2.2041e+00,  9.7994e-01],\n","         [-1.2175e+00, -9.0562e-01,  3.6921e-02,  ...,  8.1384e-02,\n","          -1.0220e+00,  5.2300e-01],\n","         [-3.3790e-01, -1.2729e+00, -5.7678e-01,  ...,  9.2610e-02,\n","          -4.4636e-01, -7.1202e-01],\n","         ...,\n","         [ 8.1925e-01, -6.5709e-01,  6.9242e-01,  ...,  5.1716e-01,\n","          -1.3299e+00,  9.3467e-01],\n","         [ 1.3042e+00, -6.2922e-01,  6.3582e-01,  ...,  4.7215e-01,\n","          -7.5392e-01,  4.7514e-01],\n","         [ 6.2023e-01, -1.0119e+00,  3.9026e-01,  ...,  4.7670e-01,\n","          -1.3331e+00,  1.6936e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6569, -0.0927,  0.2946,  ..., -0.3967, -0.5140,  0.9594],\n","        [ 0.7126, -0.0018,  0.5016,  ..., -0.0153,  0.1042,  0.5835],\n","        [ 0.7870, -0.4222,  0.4767,  ...,  0.6208, -0.1205,  0.6567],\n","        ...,\n","        [ 0.5325, -0.1417,  0.1235,  ..., -0.7212, -0.1112,  0.8706],\n","        [ 0.5927, -0.4131,  0.4551,  ..., -0.1638,  0.5547,  0.0231],\n","        [ 0.8926, -0.0755,  0.3848,  ..., -0.2146,  0.2235,  0.9796]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6569, -0.0927,  0.2946,  ..., -0.3967, -0.5140,  0.9594],\n","        [ 0.7126, -0.0018,  0.5016,  ..., -0.0153,  0.1042,  0.5835],\n","        [ 0.7870, -0.4222,  0.4767,  ...,  0.6208, -0.1205,  0.6567],\n","        ...,\n","        [ 0.5325, -0.1417,  0.1235,  ..., -0.7212, -0.1112,  0.8706],\n","        [ 0.5927, -0.4131,  0.4551,  ..., -0.1638,  0.5547,  0.0231],\n","        [ 0.8926, -0.0755,  0.3848,  ..., -0.2146,  0.2235,  0.9796]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-0.1443, -1.0646, -0.5089,  ...,  0.4445,  0.0420,  0.3426],\n","        [ 1.3295, -1.1720,  0.3521,  ...,  1.0247, -1.3312,  1.0549],\n","        [-0.0576, -1.0991, -1.1467,  ...,  0.3088, -1.4179,  2.0917],\n","        ...,\n","        [ 0.7051, -0.4211,  0.8259,  ...,  0.8437,  0.6486,  0.6878],\n","        [-0.5991, -1.4478, -0.4768,  ..., -0.0839, -0.0175,  0.8175],\n","        [ 1.1134,  0.4254, -0.1974,  ...,  0.2738, -2.2041,  0.9799]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 9.0416e-01, -1.8952e+00, -8.5596e-02,  ...,  6.6698e-01,\n","          -1.1965e+00,  1.0479e+00],\n","         [ 8.7160e-01, -6.1391e-01,  4.5745e-01,  ...,  5.9217e-01,\n","          -1.1095e-02,  7.1955e-01],\n","         [ 1.2523e-03, -3.2927e-01,  5.5308e-01,  ...,  7.9413e-01,\n","           7.3412e-03,  5.3372e-01],\n","         ...,\n","         [ 9.9512e-01, -1.9403e+00, -2.3536e-01,  ..., -2.5840e-01,\n","          -1.4431e+00,  5.6283e-01],\n","         [ 8.0188e-01, -1.4579e+00, -3.0597e-01,  ...,  3.3245e-01,\n","          -1.9199e+00,  9.8280e-01],\n","         [ 7.4939e-01, -1.2620e+00, -4.1990e-01,  ...,  6.4109e-01,\n","          -1.6958e+00,  4.2398e-01]],\n","\n","        [[ 1.0060e+00, -2.0257e-01, -2.2743e-01,  ...,  3.6149e-01,\n","          -7.1241e-02,  7.8007e-01],\n","         [-1.5441e-01, -2.1881e+00,  2.7834e-01,  ...,  2.7230e-01,\n","           1.1271e+00,  2.8755e-01],\n","         [-1.5435e-01, -8.3462e-01,  7.4866e-01,  ...,  1.2536e+00,\n","           1.2758e+00,  5.0336e-01],\n","         ...,\n","         [ 1.2110e+00, -1.4302e+00, -4.6740e-01,  ...,  2.0327e-01,\n","           2.6303e-01, -1.6855e-01],\n","         [ 1.3569e+00, -2.0993e+00,  9.1203e-02,  ..., -3.0549e-01,\n","           3.8959e-01,  5.9863e-01],\n","         [ 1.1854e+00, -1.2294e+00, -1.5685e-02,  ..., -6.0189e-01,\n","           5.2081e-01,  8.1237e-01]],\n","\n","        [[-3.9302e-01, -5.9023e-01, -9.5788e-02,  ...,  4.5395e-01,\n","           1.2266e-02,  1.0135e+00],\n","         [-2.3896e-02, -1.1339e+00, -4.0164e-01,  ...,  1.6217e-01,\n","           4.0722e-01,  8.8683e-01],\n","         [-1.6667e-01, -3.6079e-01,  6.9543e-01,  ...,  1.1625e+00,\n","          -3.0982e-01,  5.2805e-01],\n","         ...,\n","         [ 8.5883e-01, -9.7172e-01,  4.3858e-02,  ...,  2.6907e-01,\n","           5.8058e-01,  6.6205e-02],\n","         [ 1.1345e-01, -7.9850e-01, -2.6153e-02,  ...,  7.0285e-01,\n","           3.0703e-01,  7.6347e-02],\n","         [ 8.0037e-01, -7.9993e-01, -3.5269e-02,  ...,  7.5062e-01,\n","           4.2695e-01,  6.8860e-01]],\n","\n","        ...,\n","\n","        [[ 7.1883e-01, -1.2361e+00, -7.6045e-01,  ...,  1.4770e-01,\n","          -1.9118e-01,  6.0625e-01],\n","         [ 8.3958e-01, -1.6184e+00,  5.9099e-01,  ...,  3.2723e-01,\n","          -8.5210e-02,  6.7058e-01],\n","         [ 1.4958e+00, -2.0020e-01,  2.6396e-01,  ...,  4.7392e-01,\n","           1.5165e+00,  7.1322e-01],\n","         ...,\n","         [ 1.1529e+00, -4.7357e-01, -3.0202e-01,  ...,  3.6635e-01,\n","           3.8442e-01,  9.4313e-01],\n","         [ 1.8847e+00,  3.8447e-01, -2.0647e-01,  ...,  6.2768e-01,\n","           7.9891e-01,  1.0673e+00],\n","         [ 1.8519e+00, -1.0780e-01,  4.4120e-01,  ..., -7.0942e-01,\n","           1.8031e+00,  2.4762e-01]],\n","\n","        [[-3.6915e-01, -1.0589e+00,  1.9406e-01,  ...,  1.2897e-01,\n","          -2.0989e-01,  1.3453e+00],\n","         [ 1.8778e+00, -4.8837e-01,  5.1494e-02,  ...,  4.2349e-01,\n","           2.3381e-01,  7.4620e-01],\n","         [ 5.7708e-01,  1.2646e-01, -1.8371e+00,  ...,  2.0063e-01,\n","          -6.4202e-02, -5.4932e-01],\n","         ...,\n","         [ 1.5155e+00, -4.2277e-01,  5.0485e-01,  ...,  3.3601e-01,\n","          -2.9458e-01,  4.3141e-01],\n","         [ 1.5955e+00, -6.5453e-01,  8.7375e-01,  ...,  5.0420e-01,\n","          -5.6374e-01,  7.2152e-01],\n","         [ 1.6627e+00, -3.6165e-01,  3.5123e-01,  ...,  4.0054e-01,\n","          -1.4951e-01,  1.1376e+00]],\n","\n","        [[ 2.0399e-02,  7.9415e-02, -1.0502e+00,  ...,  1.4246e+00,\n","          -1.3601e+00,  7.4685e-02],\n","         [-5.3949e-01,  1.3064e-01,  6.4680e-01,  ..., -3.8591e-01,\n","           5.4537e-01,  7.8181e-01],\n","         [-5.4253e-02,  6.4054e-01,  5.2607e-01,  ...,  1.5132e-02,\n","           1.1468e-01, -7.3769e-01],\n","         ...,\n","         [-3.0131e-01, -9.7973e-01,  2.1425e-01,  ...,  4.0026e-01,\n","          -4.8533e-01,  1.2759e+00],\n","         [ 2.1993e-01, -2.9829e-01, -7.2344e-03,  ...,  1.0844e+00,\n","          -5.6525e-01,  9.7887e-01],\n","         [-4.4032e-02, -3.5073e-01, -8.7697e-04,  ...,  1.3048e+00,\n","          -4.5806e-01,  9.3561e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6177,  0.3382,  0.1685,  ..., -0.0186,  0.2207,  0.9364],\n","        [ 0.7813, -0.5153,  0.5341,  ..., -0.2966, -0.3901,  0.9290],\n","        [ 0.4354, -0.0162,  0.0566,  ..., -0.2941, -0.2844,  0.9272],\n","        ...,\n","        [ 0.7955, -0.8210,  0.6997,  ..., -0.4377,  0.0556,  0.8661],\n","        [ 0.5235, -0.2372,  0.3175,  ...,  0.6672,  0.3233,  0.3524],\n","        [ 0.7523, -0.2332,  0.6631,  ...,  0.3636, -0.5344,  0.9412]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6177,  0.3382,  0.1685,  ..., -0.0186,  0.2207,  0.9364],\n","        [ 0.7813, -0.5153,  0.5341,  ..., -0.2966, -0.3901,  0.9290],\n","        [ 0.4354, -0.0162,  0.0566,  ..., -0.2941, -0.2844,  0.9272],\n","        ...,\n","        [ 0.7955, -0.8210,  0.6997,  ..., -0.4377,  0.0556,  0.8661],\n","        [ 0.5235, -0.2372,  0.3175,  ...,  0.6672,  0.3233,  0.3524],\n","        [ 0.7523, -0.2332,  0.6631,  ...,  0.3636, -0.5344,  0.9412]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.9042, -1.8952, -0.0856,  ...,  0.6670, -1.1965,  1.0479],\n","        [ 1.0060, -0.2026, -0.2274,  ...,  0.3615, -0.0712,  0.7801],\n","        [-0.3930, -0.5902, -0.0958,  ...,  0.4540,  0.0123,  1.0135],\n","        ...,\n","        [ 0.7188, -1.2361, -0.7605,  ...,  0.1477, -0.1912,  0.6062],\n","        [-0.3691, -1.0589,  0.1941,  ...,  0.1290, -0.2099,  1.3453],\n","        [ 0.0204,  0.0794, -1.0502,  ...,  1.4246, -1.3601,  0.0747]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3263, -0.8275, -0.9482,  ...,  0.3023, -0.6424,  0.7991],\n","         [ 0.3324, -2.0346, -0.0866,  ...,  0.0265,  0.1627,  0.8099],\n","         [ 1.0592, -0.9282, -0.1826,  ..., -0.1923, -0.0345,  1.0689],\n","         ...,\n","         [ 0.4276,  0.0456,  0.5847,  ..., -0.0106,  0.1216,  0.8216],\n","         [ 0.4675,  0.0681,  0.5692,  ..., -0.0886, -0.2282,  1.5258],\n","         [ 0.4614, -0.3390,  0.0942,  ...,  0.0537, -0.4979,  1.2444]],\n","\n","        [[ 0.2687, -0.2049, -0.8705,  ...,  0.6803, -1.2779,  1.4243],\n","         [ 0.4689,  0.1269,  0.3828,  ...,  0.5936, -0.3272,  0.8359],\n","         [ 0.0809,  0.4356, -0.3050,  ...,  0.2845, -0.7655,  1.0388],\n","         ...,\n","         [ 0.5143, -1.0127,  0.1018,  ...,  0.6862, -0.8493,  1.0240],\n","         [ 0.5624, -0.4715,  0.1116,  ...,  0.6011, -0.8246,  0.9427],\n","         [-0.0057, -0.7285,  0.1192,  ...,  0.4709, -1.2697,  1.0340]],\n","\n","        [[-0.2856,  0.9314,  0.6791,  ..., -0.4353, -0.0875,  1.1850],\n","         [ 0.5337,  0.3993,  0.7691,  ..., -0.4128, -1.8278,  1.3796],\n","         [-1.2352,  1.7017,  0.0401,  ..., -0.5886, -2.0535,  0.9231],\n","         ...,\n","         [-0.3558,  1.0619,  0.7270,  ..., -0.0559, -1.8366,  1.6271],\n","         [-0.3658,  0.5124,  0.9308,  ...,  0.5425, -1.5677,  1.9564],\n","         [-0.0638,  1.5177,  0.7054,  ...,  0.2721, -1.5229,  1.0457]],\n","\n","        ...,\n","\n","        [[ 0.0976, -0.7876, -0.1722,  ...,  0.7865, -0.3820,  0.2240],\n","         [-0.0993, -3.5405,  0.7017,  ...,  1.5467, -0.2469,  0.1353],\n","         [ 0.5971, -1.6823,  0.2508,  ...,  1.4239,  1.0474,  0.2249],\n","         ...,\n","         [ 0.8988, -0.6987,  0.2999,  ...,  0.9608,  0.3120,  1.2042],\n","         [ 0.4611, -0.7371,  1.1063,  ...,  0.0996, -0.6437,  0.5617],\n","         [ 1.4056, -0.9112,  0.6151,  ...,  0.5372, -0.5617,  1.7119]],\n","\n","        [[-0.1239, -1.0083, -1.0744,  ...,  0.0724, -0.4966, -0.6210],\n","         [-0.5664, -0.6465, -0.2010,  ...,  0.7379,  0.3877, -0.5561],\n","         [ 0.1805,  0.5414,  0.2374,  ...,  0.6787, -0.1920, -0.0105],\n","         ...,\n","         [ 0.5721, -0.3218,  0.6072,  ..., -0.3891,  0.9218,  0.1225],\n","         [ 0.6418, -0.7992,  0.9758,  ...,  0.1556,  0.3044, -0.9087],\n","         [ 0.6600, -1.0208,  0.8392,  ...,  0.3459,  0.5365, -0.4619]],\n","\n","        [[ 0.3185, -1.7235, -0.7409,  ...,  0.5878, -0.3203,  0.9786],\n","         [ 0.4020, -1.5873,  0.1063,  ...,  0.3919,  0.5247,  0.0904],\n","         [ 0.5461, -0.9458, -0.5617,  ...,  0.2584,  0.5432, -0.6644],\n","         ...,\n","         [-0.2420, -1.6488, -0.8740,  ..., -0.5099, -0.8318, -0.1784],\n","         [-0.0662, -1.7650, -1.2515,  ..., -0.0441, -0.8417, -0.4739],\n","         [ 0.3654, -1.7137, -0.3230,  ...,  0.0862, -0.3173, -0.0943]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6982, -0.4167,  0.5918,  ..., -0.3069, -0.3227,  0.9078],\n","        [ 0.4442, -0.6611,  0.3044,  ...,  0.7586, -0.5767,  0.1778],\n","        [ 0.7558, -0.2458,  0.4357,  ...,  0.4191, -0.0228,  0.9057],\n","        ...,\n","        [ 0.7286,  0.2371,  0.2077,  ...,  0.3152,  0.2521, -0.0226],\n","        [ 0.2739, -0.3790, -0.0819,  ...,  0.1482, -0.1450, -0.3518],\n","        [ 0.7911,  0.0533,  0.0821,  ..., -0.1564, -0.1115,  0.8294]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6982, -0.4167,  0.5918,  ..., -0.3069, -0.3227,  0.9078],\n","        [ 0.4442, -0.6611,  0.3044,  ...,  0.7586, -0.5767,  0.1778],\n","        [ 0.7558, -0.2458,  0.4357,  ...,  0.4191, -0.0228,  0.9057],\n","        ...,\n","        [ 0.7286,  0.2371,  0.2077,  ...,  0.3152,  0.2521, -0.0226],\n","        [ 0.2739, -0.3790, -0.0819,  ...,  0.1482, -0.1450, -0.3518],\n","        [ 0.7911,  0.0533,  0.0821,  ..., -0.1564, -0.1115,  0.8294]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-0.3263, -0.8275, -0.9482,  ...,  0.3023, -0.6424,  0.7991],\n","        [ 0.2687, -0.2049, -0.8705,  ...,  0.6803, -1.2779,  1.4243],\n","        [-0.2856,  0.9314,  0.6791,  ..., -0.4353, -0.0875,  1.1850],\n","        ...,\n","        [ 0.0976, -0.7876, -0.1722,  ...,  0.7865, -0.3820,  0.2240],\n","        [-0.1239, -1.0083, -1.0744,  ...,  0.0724, -0.4966, -0.6210],\n","        [ 0.3185, -1.7235, -0.7409,  ...,  0.5878, -0.3203,  0.9786]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-8.5504e-02, -5.0249e-01,  2.6570e-01,  ...,  1.0864e-01,\n","          -9.1562e-01,  7.9780e-01],\n","         [ 5.0350e-01, -6.2554e-01,  1.2658e+00,  ...,  4.3546e-01,\n","           7.7660e-01, -2.0396e-01],\n","         [ 1.1110e+00, -1.0057e+00,  8.5685e-01,  ...,  5.2947e-01,\n","           4.8525e-01, -4.7257e-01],\n","         ...,\n","         [ 1.0379e+00, -6.3843e-01,  7.7301e-01,  ...,  1.2933e-01,\n","          -1.4178e+00,  6.1748e-01],\n","         [ 1.1078e+00, -8.2718e-01,  1.1826e+00,  ...,  1.4808e-01,\n","          -7.4546e-01,  7.8764e-01],\n","         [ 7.6122e-01,  5.5503e-02,  1.2227e+00,  ...,  5.3244e-01,\n","          -4.7260e-01,  7.0784e-01]],\n","\n","        [[-3.2365e-01, -9.2778e-01, -7.3241e-02,  ...,  4.2744e-01,\n","          -6.1149e-01, -4.4515e-01],\n","         [-1.1402e+00, -5.0187e-02, -4.1088e-01,  ...,  7.2411e-01,\n","          -2.5640e-01, -2.5000e-01],\n","         [-3.2992e-02, -2.1378e-01, -2.8326e-01,  ..., -3.1207e-01,\n","          -1.4091e-01,  2.5157e-01],\n","         ...,\n","         [ 1.4008e-01, -8.7370e-01,  3.3660e-01,  ...,  3.4726e-01,\n","           3.1372e-01,  5.4643e-01],\n","         [ 6.1762e-01, -4.5812e-01, -6.6057e-02,  ..., -3.1806e-01,\n","           8.8201e-02, -1.0964e-03],\n","         [ 6.8573e-01, -1.3974e+00, -3.2996e-02,  ...,  4.6402e-02,\n","           4.4473e-02,  4.1194e-02]],\n","\n","        [[ 1.7756e+00, -2.7668e-01, -9.6423e-01,  ..., -8.7624e-02,\n","          -3.2756e-01,  1.9360e+00],\n","         [ 7.4167e-02,  6.0895e-02,  6.6030e-01,  ..., -1.0242e+00,\n","          -6.7674e-01,  2.0890e-02],\n","         [ 4.0517e-01,  1.1524e+00, -1.3290e-04,  ...,  9.2458e-01,\n","           5.1171e-01, -1.0177e-01],\n","         ...,\n","         [ 1.6728e+00, -6.5308e-01,  4.2795e-01,  ...,  3.2269e-01,\n","          -6.4425e-01,  8.7176e-01],\n","         [ 1.0261e+00,  3.3421e-01,  3.8388e-01,  ...,  9.3376e-02,\n","          -3.6308e-01,  1.0412e+00],\n","         [ 6.4632e-01,  1.8117e-01,  8.5860e-02,  ...,  3.8639e-01,\n","           4.8799e-01,  1.0529e+00]],\n","\n","        ...,\n","\n","        [[ 8.5177e-01, -1.0252e+00,  5.0265e-01,  ...,  9.5770e-01,\n","           1.5220e+00,  6.3691e-01],\n","         [ 3.0538e-01, -2.2835e+00,  3.1267e-01,  ...,  1.8601e+00,\n","           1.0836e+00, -2.3040e-01],\n","         [ 9.0263e-01, -8.4621e-01,  8.6546e-01,  ...,  8.5570e-01,\n","           6.6281e-01, -4.2796e-01],\n","         ...,\n","         [ 1.5805e+00, -6.3097e-01, -1.3484e-01,  ...,  1.4595e+00,\n","           4.6853e-01, -4.6715e-01],\n","         [ 1.0646e+00, -8.3379e-01,  2.7913e-01,  ...,  1.2533e+00,\n","           5.9646e-01, -1.1571e-01],\n","         [ 1.3118e+00, -5.8015e-01,  9.5973e-03,  ...,  8.5928e-01,\n","           8.1024e-01, -2.8977e-01]],\n","\n","        [[ 7.2808e-01, -1.2748e+00, -5.6803e-01,  ...,  7.7865e-02,\n","          -6.1365e-02,  9.6064e-01],\n","         [ 8.0223e-01, -1.7976e+00, -3.5507e-01,  ...,  8.1736e-01,\n","           1.3395e+00, -3.4272e-01],\n","         [ 6.8015e-01, -8.8349e-01, -7.2130e-01,  ...,  1.1489e+00,\n","           9.1534e-01, -2.0846e-01],\n","         ...,\n","         [ 1.4617e+00, -1.2445e+00, -1.5728e-01,  ..., -1.8828e-01,\n","          -2.0328e-01,  3.2070e-01],\n","         [ 1.0341e+00, -8.2532e-01, -6.6242e-01,  ..., -1.1853e-01,\n","          -1.9806e-01,  2.4711e-01],\n","         [ 4.0133e-01, -1.3445e+00,  1.5883e-01,  ..., -8.7199e-02,\n","          -9.4701e-03,  2.5993e-01]],\n","\n","        [[ 7.8510e-01, -2.0360e-01, -5.7777e-01,  ...,  1.6312e+00,\n","          -8.2436e-01,  1.5391e+00],\n","         [ 7.5228e-01, -1.2487e+00, -1.0729e-01,  ...,  8.3878e-01,\n","          -4.8688e-01,  6.2158e-01],\n","         [ 2.2706e+00, -4.5266e-01, -9.7054e-01,  ...,  1.3429e+00,\n","          -1.0211e-01,  8.4028e-01],\n","         ...,\n","         [ 1.8851e+00, -3.7416e-01, -1.9022e-02,  ...,  1.3016e+00,\n","          -6.7202e-01,  1.0207e+00],\n","         [ 1.9010e+00, -1.2367e-02, -1.8694e-01,  ...,  1.1240e+00,\n","          -1.1511e+00,  1.2673e+00],\n","         [ 1.4872e+00, -1.0738e-01,  7.4259e-01,  ...,  3.6751e-01,\n","          -1.7885e+00,  1.9349e+00]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5177,  0.1324,  0.2331,  ...,  0.4494,  0.1062,  0.9217],\n","        [ 0.8969, -0.7344,  0.0800,  ..., -0.6911, -0.2627,  0.9005],\n","        [ 0.8277,  0.0517,  0.6871,  ...,  0.0707, -0.0293, -0.5252],\n","        ...,\n","        [ 0.2192, -0.7157, -0.1782,  ..., -0.7697,  0.1058,  0.6714],\n","        [ 0.8327, -0.6520,  0.4545,  ..., -0.5861, -0.3544,  0.9871],\n","        [ 0.6972,  0.4999,  0.7039,  ..., -0.2994,  0.3042,  0.9337]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.5177,  0.1324,  0.2331,  ...,  0.4494,  0.1062,  0.9217],\n","        [ 0.8969, -0.7344,  0.0800,  ..., -0.6911, -0.2627,  0.9005],\n","        [ 0.8277,  0.0517,  0.6871,  ...,  0.0707, -0.0293, -0.5252],\n","        ...,\n","        [ 0.2192, -0.7157, -0.1782,  ..., -0.7697,  0.1058,  0.6714],\n","        [ 0.8327, -0.6520,  0.4545,  ..., -0.5861, -0.3544,  0.9871],\n","        [ 0.6972,  0.4999,  0.7039,  ..., -0.2994,  0.3042,  0.9337]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[-0.0855, -0.5025,  0.2657,  ...,  0.1086, -0.9156,  0.7978],\n","        [-0.3237, -0.9278, -0.0732,  ...,  0.4274, -0.6115, -0.4452],\n","        [ 1.7756, -0.2767, -0.9642,  ..., -0.0876, -0.3276,  1.9360],\n","        ...,\n","        [ 0.8518, -1.0252,  0.5027,  ...,  0.9577,  1.5220,  0.6369],\n","        [ 0.7281, -1.2748, -0.5680,  ...,  0.0779, -0.0614,  0.9606],\n","        [ 0.7851, -0.2036, -0.5778,  ...,  1.6312, -0.8244,  1.5391]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 7.8796e-01,  1.7429e-01,  1.2688e-01,  ...,  6.2973e-01,\n","          -1.4051e+00,  7.6414e-01],\n","         [ 1.9112e+00, -5.2386e-01, -3.3922e-01,  ..., -9.2516e-01,\n","           2.6857e-01,  7.6456e-01],\n","         [ 9.2732e-01,  1.1580e+00,  9.6797e-01,  ...,  4.3106e-01,\n","          -1.5071e+00,  5.7433e-01],\n","         ...,\n","         [ 1.2834e+00, -6.5214e-03,  2.0857e-01,  ...,  6.4118e-01,\n","          -9.3031e-01,  6.3639e-01],\n","         [-2.2944e-01,  9.1915e-01, -2.2492e-01,  ...,  5.7977e-01,\n","          -4.2054e-01,  8.4776e-01],\n","         [ 7.6565e-01,  2.1653e-01,  6.2341e-01,  ...,  2.4206e-01,\n","          -2.4606e+00,  1.1021e+00]],\n","\n","        [[ 3.0039e-01, -1.2178e+00, -1.0758e-02,  ...,  3.3694e-01,\n","           2.2403e-01,  3.6095e-01],\n","         [-4.2924e-01, -1.3147e+00,  3.4436e-02,  ...,  3.8883e-01,\n","           4.1788e-01,  2.6901e-01],\n","         [ 1.5098e+00, -2.8955e+00, -6.6984e-01,  ...,  9.3629e-01,\n","           1.1280e+00, -9.7457e-01],\n","         ...,\n","         [ 4.0785e-01, -9.7390e-01,  8.3226e-01,  ...,  3.2059e-01,\n","           6.4506e-01,  2.6863e-01],\n","         [ 2.8517e-01, -3.4049e-01, -2.2222e-02,  ...,  1.1812e+00,\n","           1.7919e-01, -9.1623e-03],\n","         [ 7.8248e-01, -3.4199e-01, -1.6340e-01,  ...,  5.5385e-01,\n","           1.9150e-02, -4.0826e-01]],\n","\n","        [[ 7.4267e-01,  2.6390e-01, -1.6804e-01,  ..., -9.2716e-01,\n","          -1.0530e+00,  1.2265e+00],\n","         [ 9.1860e-01, -9.9120e-01, -4.9120e-01,  ...,  6.4537e-01,\n","          -3.7426e-01,  5.9130e-01],\n","         [ 1.4686e+00,  9.5204e-01, -8.1091e-01,  ..., -6.1843e-01,\n","          -2.8675e-01,  3.1916e-01],\n","         ...,\n","         [ 7.8271e-01, -1.1729e-01,  6.5976e-01,  ..., -6.8480e-01,\n","          -6.6003e-01,  1.0061e+00],\n","         [ 5.4437e-01,  7.6540e-02,  1.2727e+00,  ..., -4.9127e-01,\n","          -7.4660e-01,  4.2329e-01],\n","         [ 3.8564e-01, -1.9892e-01,  6.5654e-01,  ..., -5.9817e-01,\n","          -1.3238e+00,  2.1694e-01]],\n","\n","        ...,\n","\n","        [[ 3.3331e-01,  5.3122e-02,  4.4690e-01,  ...,  4.7638e-01,\n","          -4.6861e-01,  5.6790e-02],\n","         [ 9.6367e-01, -8.3073e-01,  2.5907e-01,  ...,  3.1621e-01,\n","           4.0757e-01, -2.4892e-01],\n","         [ 3.0262e-01, -5.0836e-01,  5.9531e-02,  ...,  7.4368e-01,\n","           6.6404e-01, -8.8425e-01],\n","         ...,\n","         [ 1.2058e+00, -8.0510e-01, -5.9696e-02,  ..., -5.4827e-01,\n","           2.0938e-01, -2.6144e-01],\n","         [ 1.1486e+00, -7.0100e-01, -1.3020e-01,  ..., -3.5728e-01,\n","           1.9428e-01, -2.8427e-01],\n","         [ 8.0522e-01, -3.0096e-01, -1.9286e-01,  ..., -3.3966e-01,\n","           5.0453e-01, -7.5604e-01]],\n","\n","        [[-2.1834e-03, -7.8797e-02, -4.7421e-01,  ..., -2.5084e-01,\n","          -8.0657e-01,  3.3020e-01],\n","         [ 4.5991e-01,  9.5212e-01, -3.1881e-01,  ...,  1.2241e+00,\n","           3.6846e-01,  1.4484e+00],\n","         [ 7.4036e-01,  1.3097e-01, -4.1210e-01,  ...,  4.9054e-01,\n","          -7.2976e-01, -1.3644e-01],\n","         ...,\n","         [ 2.0993e+00,  3.9676e-01, -4.0904e-01,  ...,  3.1397e-01,\n","           1.5602e-02,  3.3997e-03],\n","         [ 8.9423e-01,  1.2710e+00, -4.3647e-01,  ...,  1.1643e+00,\n","           1.1648e+00,  3.1709e-01],\n","         [ 1.9287e+00,  7.3605e-01, -5.0608e-02,  ...,  1.9290e-01,\n","          -1.4155e-01, -3.2792e-01]],\n","\n","        [[ 2.1293e-01, -4.6668e-01, -7.6876e-01,  ...,  5.2983e-01,\n","          -1.9954e-01,  6.3877e-01],\n","         [ 5.3272e-01,  1.6055e-01, -4.2866e-03,  ..., -4.4840e-02,\n","           4.7746e-01, -2.6150e-03],\n","         [-6.2710e-01,  5.4706e-01, -6.2281e-01,  ..., -6.0942e-01,\n","           6.8873e-01,  2.5754e-01],\n","         ...,\n","         [ 6.6352e-01, -4.7735e-01,  6.2694e-01,  ...,  1.9485e-01,\n","           3.9144e-01, -1.3306e-01],\n","         [ 7.2224e-01, -1.2643e-02,  4.7595e-01,  ...,  5.6107e-01,\n","           6.0252e-01, -2.1942e-01],\n","         [ 1.9831e-01,  9.2176e-01, -1.1154e+00,  ..., -6.7842e-03,\n","          -5.4924e-01,  5.8140e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.7640,  0.2943,  0.4754,  ...,  0.1747, -0.2464,  0.9344],\n","        [ 0.7285, -0.4217,  0.2611,  ..., -0.6534,  0.1542,  0.9287],\n","        [ 0.5909, -0.6099,  0.6387,  ...,  0.2094,  0.4569,  0.6100],\n","        ...,\n","        [ 0.2525, -0.7181,  0.1958,  ..., -0.2961,  0.3951,  0.8511],\n","        [ 0.5401, -0.7334,  0.7756,  ..., -0.0207, -0.3498,  0.8348],\n","        [ 0.6148, -0.5807, -0.0424,  ..., -0.4512,  0.0565,  0.9597]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.7640,  0.2943,  0.4754,  ...,  0.1747, -0.2464,  0.9344],\n","        [ 0.7285, -0.4217,  0.2611,  ..., -0.6534,  0.1542,  0.9287],\n","        [ 0.5909, -0.6099,  0.6387,  ...,  0.2094,  0.4569,  0.6100],\n","        ...,\n","        [ 0.2525, -0.7181,  0.1958,  ..., -0.2961,  0.3951,  0.8511],\n","        [ 0.5401, -0.7334,  0.7756,  ..., -0.0207, -0.3498,  0.8348],\n","        [ 0.6148, -0.5807, -0.0424,  ..., -0.4512,  0.0565,  0.9597]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.7880,  0.1743,  0.1269,  ...,  0.6297, -1.4051,  0.7641],\n","        [ 0.3004, -1.2178, -0.0108,  ...,  0.3369,  0.2240,  0.3609],\n","        [ 0.7427,  0.2639, -0.1680,  ..., -0.9272, -1.0530,  1.2265],\n","        ...,\n","        [ 0.3333,  0.0531,  0.4469,  ...,  0.4764, -0.4686,  0.0568],\n","        [-0.0022, -0.0788, -0.4742,  ..., -0.2508, -0.8066,  0.3302],\n","        [ 0.2129, -0.4667, -0.7688,  ...,  0.5298, -0.1995,  0.6388]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0093, -1.2326, -0.4919,  ..., -0.2810,  0.2690, -0.6041],\n","         [ 1.8792, -0.5148,  0.1872,  ...,  0.0668,  1.6405,  0.3155],\n","         [ 0.9596, -0.2194,  0.5272,  ..., -0.2128, -0.6389,  0.0255],\n","         ...,\n","         [ 0.3382, -0.6024, -0.1478,  ..., -0.1909, -0.5771,  0.0942],\n","         [ 1.3038, -1.1966, -0.3554,  ...,  0.2934,  0.6087,  0.0701],\n","         [ 0.9013, -1.3814,  0.2287,  ...,  0.1485,  0.3113,  0.3372]],\n","\n","        [[ 0.1392,  0.0880, -0.5430,  ..., -0.5154, -0.0089,  1.0296],\n","         [-0.1832, -1.1571, -0.2486,  ..., -0.7111,  0.2396,  0.8008],\n","         [ 0.8313,  0.3395, -0.5235,  ..., -0.4330, -0.4266,  1.2899],\n","         ...,\n","         [ 0.4574, -0.7561, -0.4025,  ..., -0.4080,  0.2685,  0.2596],\n","         [ 0.4007, -0.8185, -0.0995,  ..., -0.0953,  0.5644,  0.2598],\n","         [ 0.3146, -1.1475, -0.6481,  ..., -0.2700,  0.6815,  0.5784]],\n","\n","        [[ 1.1123,  1.1719, -0.3639,  ..., -0.4295,  0.2343,  1.6437],\n","         [ 0.6236, -0.1849,  0.6453,  ...,  0.4943, -0.3400,  0.8421],\n","         [ 1.6228,  0.7853,  0.1407,  ..., -0.5428, -0.3775, -0.1135],\n","         ...,\n","         [ 0.7925, -0.0090,  0.7528,  ...,  0.2164, -1.1056,  1.4784],\n","         [ 0.7934, -0.0533,  0.8173,  ...,  0.6452, -0.7622,  1.9441],\n","         [ 0.4417, -0.2938,  0.5881,  ...,  0.4920, -0.9517,  1.4287]],\n","\n","        ...,\n","\n","        [[ 0.2160, -1.3170, -0.9297,  ..., -0.3747, -0.7993,  0.8805],\n","         [ 0.9813, -1.4762,  0.1373,  ...,  0.4404,  1.4507,  0.4654],\n","         [ 0.2585,  0.6322,  0.3011,  ..., -0.3867, -0.8867,  0.5879],\n","         ...,\n","         [ 0.7117, -1.4828, -0.3864,  ..., -0.6616, -0.3665,  0.7230],\n","         [ 0.1335, -1.3962, -0.4926,  ..., -0.2072,  0.3155,  0.6033],\n","         [ 0.4961, -1.0761, -0.5045,  ..., -0.0892,  0.3705,  0.2839]],\n","\n","        [[ 0.5980, -1.1653,  0.2548,  ...,  0.3363, -0.0208,  0.2391],\n","         [-0.0846, -1.2000,  1.3134,  ..., -0.2737,  0.8206,  0.2494],\n","         [ 1.6270,  0.1756,  0.8734,  ..., -1.0254, -0.1505, -0.3014],\n","         ...,\n","         [ 0.3210, -0.0893,  1.0179,  ..., -0.2426, -0.5603,  1.2890],\n","         [-0.0581, -0.7780,  0.5502,  ...,  0.1214, -0.5936,  0.4924],\n","         [ 0.8967, -0.6997,  0.2582,  ...,  0.4165,  0.4295, -0.2700]],\n","\n","        [[ 0.1715, -1.6545, -0.3612,  ...,  0.1414, -0.2230,  0.0339],\n","         [-0.3744, -2.1865, -0.2111,  ..., -0.1791,  0.8565, -0.5419],\n","         [ 1.4278, -1.8486, -0.3369,  ..., -0.2771, -1.3258,  0.6589],\n","         ...,\n","         [ 0.5705,  0.0269, -0.3903,  ...,  0.3617,  0.2564,  0.3336],\n","         [ 0.7523, -0.0369,  0.3419,  ...,  0.0030,  0.2100, -0.1160],\n","         [ 1.0678, -0.7299,  0.6389,  ...,  0.0794, -0.8869, -0.1452]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.8056, -0.3475,  0.5055,  ..., -0.6013, -0.0335,  0.9912],\n","        [ 0.1563,  0.2178,  0.2193,  ...,  0.7301,  0.0826,  0.8005],\n","        [ 0.6094, -0.3269,  0.7546,  ...,  0.5537, -0.3388,  0.4778],\n","        ...,\n","        [ 0.8229, -0.2795,  0.5862,  ..., -0.2178,  0.2839,  0.9472],\n","        [ 0.6043,  0.2938,  0.1733,  ..., -0.5026, -0.3225,  0.9968],\n","        [ 0.3994,  0.2273,  0.3979,  ...,  0.1344, -0.4664,  0.8225]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.8056, -0.3475,  0.5055,  ..., -0.6013, -0.0335,  0.9912],\n","        [ 0.1563,  0.2178,  0.2193,  ...,  0.7301,  0.0826,  0.8005],\n","        [ 0.6094, -0.3269,  0.7546,  ...,  0.5537, -0.3388,  0.4778],\n","        ...,\n","        [ 0.8229, -0.2795,  0.5862,  ..., -0.2178,  0.2839,  0.9472],\n","        [ 0.6043,  0.2938,  0.1733,  ..., -0.5026, -0.3225,  0.9968],\n","        [ 0.3994,  0.2273,  0.3979,  ...,  0.1344, -0.4664,  0.8225]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.0093, -1.2326, -0.4919,  ..., -0.2810,  0.2690, -0.6041],\n","        [ 0.1392,  0.0880, -0.5430,  ..., -0.5154, -0.0089,  1.0296],\n","        [ 1.1123,  1.1719, -0.3639,  ..., -0.4295,  0.2343,  1.6437],\n","        ...,\n","        [ 0.2160, -1.3170, -0.9297,  ..., -0.3747, -0.7993,  0.8805],\n","        [ 0.5980, -1.1653,  0.2548,  ...,  0.3363, -0.0208,  0.2391],\n","        [ 0.1715, -1.6545, -0.3612,  ...,  0.1414, -0.2230,  0.0339]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","Step : 30, Avg Loss : 0.4679\n","outputs\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6757, -0.8470, -0.3431,  ...,  0.2736, -1.2114,  0.6061],\n","         [ 0.4529, -2.9898,  1.1221,  ...,  0.2978, -0.2117,  0.6681],\n","         [-0.0683, -2.0692,  1.1893,  ...,  0.0388,  1.0284,  0.9426],\n","         ...,\n","         [ 0.1343, -1.7185, -0.0131,  ...,  0.7172, -1.1159,  0.9677],\n","         [ 0.3472, -0.1791,  1.0475,  ...,  0.0727, -0.4828,  2.1994],\n","         [ 0.2259, -1.0505,  0.0929,  ...,  0.1877,  0.1247,  1.1534]],\n","\n","        [[ 0.9319,  0.2859,  0.3918,  ...,  0.5843, -0.6787,  1.8757],\n","         [ 1.5398,  0.3473,  0.1554,  ...,  0.4019, -1.0750,  1.2684],\n","         [ 0.3236, -0.3576, -0.4996,  ..., -0.4428, -0.0300,  0.9756],\n","         ...,\n","         [ 1.0851, -0.1222,  0.2426,  ...,  0.4106, -0.9933,  0.2248],\n","         [ 0.9725, -0.7685,  0.3048,  ...,  0.4982, -0.2138,  0.9961],\n","         [ 1.0923,  0.0870,  0.0829,  ...,  0.9228, -0.8227, -0.2020]],\n","\n","        [[ 0.2264,  0.5431, -0.3997,  ..., -0.1422, -0.4770,  1.1765],\n","         [ 0.6417, -0.5251,  0.1248,  ..., -0.2672, -0.8120,  0.2403],\n","         [-0.4048,  1.0881, -0.5948,  ...,  0.8324, -0.6857,  1.0015],\n","         ...,\n","         [ 1.0166,  0.5791,  0.5500,  ..., -0.0722, -1.7307,  1.3599],\n","         [ 0.5222,  0.2911,  1.1022,  ...,  0.8847, -1.1201,  1.4895],\n","         [ 0.2249,  0.7263,  1.2309,  ...,  0.8738, -1.1062,  0.9737]],\n","\n","        ...,\n","\n","        [[ 0.4149, -0.2102, -0.2068,  ..., -0.4590, -1.7171,  0.5548],\n","         [ 1.1248, -2.6481,  0.0088,  ..., -0.5587, -1.3854,  0.0767],\n","         [ 1.2083, -0.5771,  0.0333,  ...,  0.4926, -1.2569, -0.0265],\n","         ...,\n","         [-0.5044, -0.0649,  0.2007,  ..., -0.3336, -1.2428,  0.7389],\n","         [-0.3607, -0.3853,  0.1150,  ..., -0.5633, -1.0758,  0.5133],\n","         [-0.6285, -0.2363,  0.2360,  ..., -0.4503, -1.1272,  0.7034]],\n","\n","        [[ 0.0564, -0.5777, -0.2695,  ...,  0.4068, -0.5159, -0.0600],\n","         [-0.6514, -1.3510, -0.3240,  ...,  0.5412,  0.1417,  2.3195],\n","         [ 0.5219,  0.1536,  0.2354,  ...,  0.7206,  0.1333, -0.2237],\n","         ...,\n","         [ 0.7232, -1.0734, -0.7040,  ...,  0.5127, -0.1205,  0.6857],\n","         [ 1.1363,  0.0218,  0.4619,  ..., -0.9430, -0.0795,  0.0497],\n","         [ 1.8393, -0.1271,  0.6565,  ..., -0.3156,  0.1881, -0.1662]],\n","\n","        [[ 0.8586, -1.9367,  0.1807,  ..., -0.1684,  0.1811,  0.3361],\n","         [ 1.4157, -0.3840,  1.3554,  ...,  0.0379,  0.4387,  1.7709],\n","         [-0.0393,  0.3480,  0.1869,  ..., -0.1607,  1.0143,  0.2701],\n","         ...,\n","         [ 0.5272, -0.6621, -0.1753,  ...,  0.0874,  0.1809, -0.6598],\n","         [ 1.3912, -0.6002, -0.3099,  ..., -0.6963, -0.1876,  0.2159],\n","         [ 0.4498,  0.0716, -0.0690,  ..., -0.5872, -0.7511, -0.2137]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6624, -0.3808,  0.1221,  ...,  0.1311, -0.0382, -0.3733],\n","        [ 0.8845,  0.0815,  0.1514,  ...,  0.5850,  0.3263,  0.2127],\n","        [ 0.7666, -0.4146,  0.5630,  ..., -0.2986, -0.2940,  0.8127],\n","        ...,\n","        [ 0.4273, -0.0640,  0.7253,  ..., -0.1162, -0.0790,  0.9138],\n","        [ 0.2815, -0.0993, -0.0783,  ..., -0.3028, -0.3993,  0.9913],\n","        [ 0.4413, -0.3665,  0.3364,  ..., -0.4553,  0.1445,  0.9879]],\n","       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","pooler_output\n","tensor([[ 0.6624, -0.3808,  0.1221,  ...,  0.1311, -0.0382, -0.3733],\n","        [ 0.8845,  0.0815,  0.1514,  ...,  0.5850,  0.3263,  0.2127],\n","        [ 0.7666, -0.4146,  0.5630,  ..., -0.2986, -0.2940,  0.8127],\n","        ...,\n","        [ 0.4273, -0.0640,  0.7253,  ..., -0.1162, -0.0790,  0.9138],\n","        [ 0.2815, -0.0993, -0.0783,  ..., -0.3028, -0.3993,  0.9913],\n","        [ 0.4413, -0.3665,  0.3364,  ..., -0.4553,  0.1445,  0.9879]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n","answer\n","tensor([[ 0.6757, -0.8470, -0.3431,  ...,  0.2736, -1.2114,  0.6061],\n","        [ 0.9319,  0.2859,  0.3918,  ...,  0.5843, -0.6787,  1.8757],\n","        [ 0.2264,  0.5431, -0.3997,  ..., -0.1422, -0.4770,  1.1765],\n","        ...,\n","        [ 0.4149, -0.2102, -0.2068,  ..., -0.4590, -1.7171,  0.5548],\n","        [ 0.0564, -0.5777, -0.2695,  ...,  0.4068, -0.5159, -0.0600],\n","        [ 0.8586, -1.9367,  0.1807,  ..., -0.1684,  0.1811,  0.3361]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n","Mean Loss : 0.5649\n","Train Finished\n"]}],"source":["# 학습 시작\n","train(model, train_iterator)"]},{"cell_type":"markdown","metadata":{"id":"37UbAkh7LnJ3"},"source":["## fine-tuning 2가지 방법론 비교\n","- pre-trained BERT 모델 파라미터를 **freeze**한 채 학습하라\n","    - BERT의 파라미터의 `requires_grad` 값을 `False`로 바꾸면, 학습 시 BERT의 파라미터는 미분이 계산되지도, 업데이트 되지도 않는다. \n","    - 이렇게 특정 모델의 파라미터가 업데이트 하지 못하도록 설정하는 것을 **freeze**라고 한다. \n","    - BERT 파라미터를 freeze시킨 채 학습을 진행해보자. 이럴 경우, 우리가 직접 쌓은 fine-tuning layer의 파라미터만 업데이트 된다. \n","- **unfreeze**와 **freeze** 모델의 성능을 비교해 보자. 어떤 방식이 더 우수한가?\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ld260K3YLnJ3","executionInfo":{"status":"aborted","timestamp":1647004359726,"user_tz":-540,"elapsed":186,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["class CustomClassifierFreezed(nn.Module):\n","\n","  def __init__(self, hidden_size: int, n_label: int):\n","    super(CustomClassifierFreezed, self).__init__()\n","\n","    self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n","\n","    # freeze BERT parameter\n","    # BERT의 파라미터는 고정값으로 두고 BERT 위에 씌운 linear layer의 파라미터만 학습하려고 한다. \n","    # 이 경우, BERT의 파라미터의 'requires_grad' 값을 False로 변경해줘야 학습 시 해당 파라미터의 미분값이 계산되지 않는다.\n","    for param in self.bert.parameters():\n","        param.requires_grad = False\n","\n","    dropout_rate = 0.1\n","    linear_layer_hidden_size = 32\n","    self.classifier = nn.Sequential(nn.Linear(hidden_size, linear_layer_hidden_size),\n","                                    nn.ReLU(), \n","                                    nn.Dropout(dropout_rate),\n","                                    nn.Linear(linear_layer_hidden_size, n_label))\n","      \n","  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n","\n","    outputs = self.bert(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        token_type_ids=token_type_ids,\n","    )\n","    \n","    # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱(내 답)\n","    # pooler_output : the last layer hidden-state of the first token of the sequence (classification token) further processed by a Linear layer and a Tanh activation function.\n","    cls_token_last_hidden_states = outputs['pooler_output'] # 마지막 layer의 첫 번째 토큰 (\"[CLS]\") 벡터를 가져오기, shape = (1, hidden_size)\n","\n","    # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱(정답)\n","    last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n","    cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n","\n","    return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ClEEHB6F6LW","executionInfo":{"status":"aborted","timestamp":1647004359727,"user_tz":-540,"elapsed":184,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# freeze 모델\n","# model을 제외한 설정값은 위에서 실행한 unfreeze 모델과 동일\n","model = CustomClassifierFreezed(hidden_size=768, n_label=2)\n","\n","# 데이터 이터레이터\n","batch_size = 32\n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n","\n","# 로스 및 옵티마이저\n","loss_fct = CrossEntropyLoss()\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=2e-5,\n","    eps=1e-8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqcPcWZeLnJ3","executionInfo":{"status":"aborted","timestamp":1647004359728,"user_tz":-540,"elapsed":180,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# 학습 시작\n","train(model, train_iterator)"]},{"cell_type":"markdown","source":["각 모델을 5번 이상 돌려보았고 모든 실험에서 파라미터를 Unfreeze한 모델의 Loss가 더 낮게 나왔다. 즉 Unfreeze한 모델의 성능이 더 좋다는 것이다."],"metadata":{"id":"f66btiBXxJ9_"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Week2-2-assignment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c4d2e96f7af5441b9ab19a3c2aa391a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bfb15349bdd64ce0b607415cd099ede0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4d56797b47414b37873f15dc66fd2a63","IPY_MODEL_b1fa9519123546daad32dfd4f458182a","IPY_MODEL_bed2fb92934d437bb1f6bb7366c10ee7"]}},"bfb15349bdd64ce0b607415cd099ede0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d56797b47414b37873f15dc66fd2a63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_50abb0bb2cb949df8228ea0d8e180b3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c30f5691f3c844bcb60788db49ecd536"}},"b1fa9519123546daad32dfd4f458182a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c29f6203718b4a8ab5cd04cada9ca3e3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":248477,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":248477,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bbda07457c86491b8c04392d346ce0f2"}},"bed2fb92934d437bb1f6bb7366c10ee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f14ffbb2aa32480ea5a8a75677e2e535","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243k/243k [00:00&lt;00:00, 1.08MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09c4a0e102e2433e958fef48c82a7d32"}},"50abb0bb2cb949df8228ea0d8e180b3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c30f5691f3c844bcb60788db49ecd536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c29f6203718b4a8ab5cd04cada9ca3e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bbda07457c86491b8c04392d346ce0f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f14ffbb2aa32480ea5a8a75677e2e535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"09c4a0e102e2433e958fef48c82a7d32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ddc663740f78434c9ffbff23c15196cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_11dac798102d48e8a44d95275d208042","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_49f2460afd644f44b7bc20a891e9b3ac","IPY_MODEL_561bce0e4a5e4dd0ac2d213f85df8f48","IPY_MODEL_da1e71ffa2d3473cb035171868e8341f"]}},"11dac798102d48e8a44d95275d208042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49f2460afd644f44b7bc20a891e9b3ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0dd5361f6f743c187c03103863daf04","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99dc5bd2096547a3a459411dd305db2a"}},"561bce0e4a5e4dd0ac2d213f85df8f48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_026c6eebe1304d399f22fb136562c000","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed110e59e7cf414d864ee67f2c1a5c51"}},"da1e71ffa2d3473cb035171868e8341f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10bf8bc16c9e495cbac8e539277d5ca3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [00:00&lt;00:00, 2.89kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68aa72069358477b9f9f16a151768236"}},"b0dd5361f6f743c187c03103863daf04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99dc5bd2096547a3a459411dd305db2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"026c6eebe1304d399f22fb136562c000":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ed110e59e7cf414d864ee67f2c1a5c51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10bf8bc16c9e495cbac8e539277d5ca3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68aa72069358477b9f9f16a151768236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d4777f98dd242abb787823401f64f10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d1b097e4c38146a7826aaf702a8a6b25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3e1f721f1d584479aa19f87a7909f6be","IPY_MODEL_3657867be1d349a894fb953995b11847","IPY_MODEL_13168d576eeb4c5b9bd8f0e380c22044"]}},"d1b097e4c38146a7826aaf702a8a6b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e1f721f1d584479aa19f87a7909f6be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_366880aa3d294098bba52b87b64ba9f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83b870e637434455a8ed99771d0f4e6c"}},"3657867be1d349a894fb953995b11847":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8f10a37db47a4d98a982b433d7cee763","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e43486a0dca46d5a77af1c6b3c4deac"}},"13168d576eeb4c5b9bd8f0e380c22044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_15f39b52556742b5a1e9775de27cbb9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 289/289 [00:00&lt;00:00, 7.21kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_888990740d674c33b478f0a672ca11bc"}},"366880aa3d294098bba52b87b64ba9f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"83b870e637434455a8ed99771d0f4e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f10a37db47a4d98a982b433d7cee763":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e43486a0dca46d5a77af1c6b3c4deac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15f39b52556742b5a1e9775de27cbb9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"888990740d674c33b478f0a672ca11bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ffa3a3414cc4ac9ba28871830f95a0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e6d641f6f95f4dcba65f1886180a772a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2412c9a604f4ae496160019c3529535","IPY_MODEL_53f49a479263432aa49011891ea10f80","IPY_MODEL_7314e3fb1bd94a668744ac8236c0f6c9"]}},"e6d641f6f95f4dcba65f1886180a772a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2412c9a604f4ae496160019c3529535":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b525c0b0a6604f5c8aac30cdd07ed835","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4762ca351ca9402888aa9ea37d37af3b"}},"53f49a479263432aa49011891ea10f80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_727425711bc64dd6adfd9ff3449fe9ad","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":425,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":425,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_393d0a099629467f9c799d8743060c25"}},"7314e3fb1bd94a668744ac8236c0f6c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f4f18b1275e6480b9c43401cd758a007","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 425/425 [00:00&lt;00:00, 10.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d82c545da9f1475783e7d6ebe9ca77c2"}},"b525c0b0a6604f5c8aac30cdd07ed835":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4762ca351ca9402888aa9ea37d37af3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"727425711bc64dd6adfd9ff3449fe9ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"393d0a099629467f9c799d8743060c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f4f18b1275e6480b9c43401cd758a007":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d82c545da9f1475783e7d6ebe9ca77c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}