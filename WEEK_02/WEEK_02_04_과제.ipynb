{"cells":[{"cell_type":"markdown","metadata":{"id":"592U6lXs3d2t"},"source":["# Week2_4 Assignment\n","\n","## [BASIC](#Basic) \n","- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n","- **autograd**의 개념 복습\n","\n","\n","## [CHALLENGE](#Challenge)\n","- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n","- **validate() 함수를 구현**할 수 있다.\n","\n","\n","## [ADVANCED](#Advanced)\n","- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n","- **predict 함수를 구현**할 수 있다. \n","- **evaluation metric 구현**할 수 있다. \n","    - accuracy\n","\n","\n","\n","### Reference\n","- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:47.370876Z","start_time":"2022-02-02T04:01:46.520392Z"},"id":"KSX-wQA1RD1h","executionInfo":{"status":"ok","timestamp":1647006740905,"user_tz":-540,"elapsed":6511,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["import os\n","import sys\n","import pandas as pd\n","import numpy as np \n","import torch\n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:47.375658Z","start_time":"2022-02-02T04:01:47.372242Z"},"id":"MH7RJjtZXOHf","executionInfo":{"status":"ok","timestamp":1647006740906,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}}},"outputs":[],"source":["# set seed\n","seed = 7777\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:07:00.849353Z","start_time":"2022-01-31T13:06:56.187962Z"},"id":"62plMahMWr0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006762147,"user_tz":-540,"elapsed":21249,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"39f061ea-c585-4e26-9483-a9fa6c286426"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.8 MB 2.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 34.7 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 31.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 18.2 MB/s \n","\u001b[?25h"]}],"source":["!pip install transformers -qq"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6WagJcj-Ud4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006800399,"user_tz":-540,"elapsed":23517,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"848f8873-6c2f-4ad2-8547-35aa4f8ebd80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"qnETqIqdVApF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006804929,"user_tz":-540,"elapsed":492,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"1743de4e-0688-4e2f-963a-ac72a8f42432"},"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/원티드AIML']\n"]}],"source":["# 어제 자신이 구현한 helper.py 모듈 경로를 입력\n","path = '/content/drive/MyDrive/원티드AIML'\n","sys.path.append(path)\n","print(sys.path)"]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:49.735578Z","start_time":"2022-02-02T04:01:49.475969Z"},"id":"N84mZeYMUFxJ","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["75c5fb9269cd498181073c95a6e1aac0","e8651ce9c63c44f9b218404a133899b8","deefbdf568514e05a8eff335446579a2","10c3e83c7ee84e93bc655751e145a155","65927d41de07489bb087ca843ef6120b","3fbabd4123a949c789ab66e9dd672a47","31a83fdc4bc74ab7a32f770522942426","2ca9def0b44d436ba7eaf0691f292e1f","5dee13cfe5d045a48555d2c2a66029eb","7bbb9bb93f9d47dd91ccafb90c5dae45","5db4565d13684e54b3aa7df731b7273e","ba12f92c30674e3287a7c4ea34a81a45","52b412f2316b41ed867d5f557aac7cb6","b60c9951329b4008917b2bbb92ae0ea4","68528f9910fd4ab8a5bc7d73cd35fe74","0ab5c0db96b54144bb08a93ae198bd18","82432a99b03a4f74bffb62de7974f857","c8faa0d05d744342ac025c74ea647604","dcce093850434a3eab4871fc174f337f","ec5bd6d89e7b49dda183f6fdb88f3360","ffc79e5830ca4c5e9911af6591ae24b6","49b56514fdf746df8be88cb244a165ef","b29a567a39604d5fb748f84998bc6462","1450549409c24560b8f240fff2770572","d052a40e8e024fd78c06362f3f5b8152","d140ddd4d0064271a15c9cd4528589a4","965f77110fb34c309eb35234abcc1c1b","48be6e17df154f808c3f91be6933e934","ba803d53e5e448cc8ffe703f1631b437","0e1825789dac492dbe6abf5c498e82e2","01eb81393938461db3b9b47f6f9a988f","62e39072041a40f487ca925327c94589","2b74a950804b49b5a341bd0c75207d19","80e25a7acf574b1ab74782ad8fe61fef","9de0e622506d49f58f5d247595459d70","31fcb498557a43e2a422c6e9298e5eaa","1976e65653c44a83bcae45e50536f471","c387651d73684e54b30e91e8df09880b","a98daca006a840588d429206ab74c173","29d11763898a4b6eb402ef292c8da2cb","c13b279cfb1448e184edba95c53dce69","c4d59702f41c4a998981f60a9fc644d3","0c7a223f2425421e97eca737993447c3","3f3f8561176c472ab1a7e521294bf59f"]},"executionInfo":{"status":"ok","timestamp":1647006814732,"user_tz":-540,"elapsed":9313,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"6b84ec51-585e-4480-d1aa-bdfb7acec770"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75c5fb9269cd498181073c95a6e1aac0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba12f92c30674e3287a7c4ea34a81a45","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b29a567a39604d5fb748f84998bc6462","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80e25a7acf574b1ab74782ad8fe61fef","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{}}],"source":["# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음 \n","# 함수: set_device()\n","# 함수: custom_collate_fn() \n","# 클래스: CustomDataset\n","# 클래스: CustomClassifier\n","# 가 import 됨\n","\n","from helper import *\n","from torch.utils.data import RandomSampler, SequentialSampler"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:49.771743Z","start_time":"2022-02-02T04:01:49.736866Z"},"id":"oR5EWmh5UFxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006888762,"user_tz":-540,"elapsed":473,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"c83df140-cf35-4081-ba74-071690b6dab3"},"outputs":[{"output_type":"stream","name":"stdout","text":["# available GPUs : 1\n","GPU name : Tesla K80\n","device: cuda\n"]}],"source":["# device\n","device = set_device()\n","print(f\"device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"pkNxrCV45Q3m"},"source":["## Basic"]},{"cell_type":"markdown","metadata":{"id":"9YBUQykS5Q3n"},"source":["### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n","- train_dataset, train_dataloader\n","- valid_dataset, valid_dataloader\n","- test_dataset, test_dataloader"]},{"cell_type":"code","source":["# # train dataframe 다운로드\n","# !wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv -P '/content/drive/MyDrive/원티드AIML'"],"metadata":{"id":"cjNksUEwGACb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # test dataframe 다운로드\n","# !wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv -P '/content/drive/MyDrive/원티드AIML'"],"metadata":{"id":"kXfk8ZEHGB0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.037044Z","start_time":"2022-02-02T04:01:52.707669Z"},"id":"KVo5dPnmUFxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006893749,"user_tz":-540,"elapsed":1434,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"2423d399-b438-4e22-990b-7dca3c13077a"},"outputs":[{"output_type":"stream","name":"stdout","text":["train shape : (10000, 3)\n","test shape : (1000, 3)\n"]}],"source":["# 학습 & 평가 데이터셋 로드\n","# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n","\n","df_train = pd.read_csv('/content/drive/MyDrive/원티드AIML/sample_df.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/원티드AIML/sample_df_test.csv')\n","\n","print(f\"train shape : {df_train.shape}\")\n","print(f\"test shape : {df_test.shape}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.085720Z","start_time":"2022-02-02T04:01:53.081413Z"},"id":"Ql82Ew2VUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006894434,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"36def156-7e81-4b71-a129-4f30ff24476a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset len: 10000\n","Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n","Test Dataset len: 1000\n","Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"]}],"source":["# Dataset 구현\n","# helper.py에 있는 CustomDataset 활용하여 train datset, test dataset 만들기\n","\n","train_dataset = CustomDataset(list(df_train['document']), list(df_train['label']))\n","test_dataset = CustomDataset(list(df_test['document']), list(df_test['label']))\n","\n","print(f\"Train Dataset len: {len(train_dataset)}\")\n","print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n","\n","print(f\"Test Dataset len: {len(test_dataset)}\")\n","print(f\"Test Dataset 1st element: {test_dataset[0]}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.152070Z","start_time":"2022-02-02T04:01:53.145410Z"},"id":"7WUY6h8WUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006896212,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"575ebea9-8107-4594-9837-49a37c284ccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset len: 9000\n","Valid dataset len: 1000\n"]}],"source":["# Train Dataset을 학습과 검증 셋으로 분리\n","# 학습 셋과 검증 셋의 비율은 9:1\n","# torch.utils.data에서 제공되는 데이터 세트를 임의로 분할할 수 있는 함수 찾아서 사용\n","n_train_sample = df_train.shape[0]\n","\n","n_train = int(n_train_sample*0.9)\n","n_valid = n_train_sample - n_train \n","train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [n_train, n_valid])\n","\n","print(f\"Train dataset len: {len(train_dataset)}\")\n","print(f\"Valid dataset len: {len(valid_dataset)}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.268838Z","start_time":"2022-02-02T04:01:53.263780Z"},"id":"H5nc7SpTUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006898243,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"968b150a-6c6e-41f8-d122-36f28ef9ba70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataloader # steps: 282\n","Valid dataloader # steps: 16\n","Test dataloader # steps: 32\n"]}],"source":["# DataLoader 구현\n","# train과 validation의 batch size는 각각 32, 64로 설정\n","# test의 batch size는 validation과 동일\n","# train에 사용할 DataLoader에서는 sampler로 RandomSampler 사용\n","# validation과 test에 사용할 DataLoader에서는 sampler로 SequentialSampler 사용\n","# 모든 DataLoader의 collate_fn은 helper.py에 있는 custom_collate_fn 사용\n","\n","train_batch_size = 32\n","valid_batch_size = 64\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, collate_fn=custom_collate_fn, sampler=RandomSampler(train_dataset))\n","\n","valid_dataloader = DataLoader(valid_dataset, batch_size=valid_batch_size, collate_fn=custom_collate_fn, sampler=SequentialSampler(valid_dataset))\n","\n","test_dataloader = DataLoader(test_dataset, batch_size=train_batch_size, collate_fn=custom_collate_fn, sampler=SequentialSampler(test_dataset))\n","\n","print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n","print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n","print(f\"Test dataloader # steps: {len(test_dataloader)}\")"]},{"cell_type":"markdown","metadata":{"id":"9kEgqvBIUFxN"},"source":["### `auto_grad` 개념 복습\n","- torch의 `auto_grad` 기능\n","    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n","    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:45:23.502936Z","start_time":"2022-01-31T13:45:20.029987Z"},"id":"oYjYpQ1DUFxN","colab":{"base_uri":"https://localhost:8080/","height":124,"referenced_widgets":["bfa1f3a906f64842b0f09c080d4f0b7e","70649b72c20a4abda9bccbd6fa775c38","99bd9c603e1a4e9d9d59077ca7e3e2b4","83577a824faf43ceac2107a2a7fc674c","90ed4f3323af4813ba20fb29aa966b0a","9f17301f28a34e5183cc77b26f1b2ce3","7fe03b60c06c4092a8c9ae62731acfb4","7dbbc00275b24816b7395fde0505396e","179873c4a1c743a3be03d3f8ff57c57f","8f478d01a0df4678bc7a7407b6d365c0","6f7f65a988fb47c088072160eeb20097"]},"executionInfo":{"status":"ok","timestamp":1647006933344,"user_tz":-540,"elapsed":24250,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"e29ea382-7eeb-4d5e-80d7-08e360485fb3"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfa1f3a906f64842b0f09c080d4f0b7e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# helper.py에 있는 CustomClassifier 모델을 로드해 model_freeze 변수에 instance를 생성\n","# hidden_size=768\n","# n_label=2\n","# freeze_base=True\n","\n","model_unfreeze = CustomClassifier(hidden_size=768, n_label=2)"]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:45:34.604914Z","start_time":"2022-01-31T13:45:34.586711Z"},"id":"XxNFh8KZUFxN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647006933344,"user_tz":-540,"elapsed":20,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"cf298306-1992-410e-e825-e24837b09278"},"outputs":[{"output_type":"stream","name":"stdout","text":["CustomClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=768, out_features=32, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.1, inplace=False)\n","    (3): Linear(in_features=32, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["# model_freeze 모델의 모든 파라미터를 출력해보고 아래 질문에 답해 보자\n","\n","print(model_unfreeze)"]},{"cell_type":"markdown","metadata":{"id":"KloNNAKI5Q3r"},"source":["### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n","- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n","> 예\n","- `classifier.0.weight` 텐서의 shape은? \n","> (32, 768)\n","- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n","> 아니오\n","- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n",">정답 : NONE\n","\n","weight와 gradient를 동일하게 생각해서 생긴 문제\n","- 추가된 레이어의 텐서의 가중치는 임의로  초기한 값이 들어가 있다. 거의 0에 가까운 값들이 존재한다.\n","- 추가된 레이어의 텐서의 기울기는 None이다.\n","\n","Gradient는 손실 함수의 최저점을 찾기 위해 사용하는 방향(도구)이고 weight는 최저점에 도돌하기 위한 포인트(목적)라고 생각하자."]},{"cell_type":"markdown","metadata":{"id":"4iIrHg1xUFxP"},"source":["### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"]},{"cell_type":"code","source":["for name, param in model_unfreeze.named_parameters():\n","    if name == 'classifier.0.weight':\n","        print(param.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqtNhPYiQx1u","executionInfo":{"status":"ok","timestamp":1647006933345,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"8cd8adc4-3e44-4e3c-b5ea-1828fac49e5c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["for name, param in model_unfreeze.named_parameters():\n","    if name == 'classifier.0.weight':\n","        print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDYI9gtpQ7gP","executionInfo":{"status":"ok","timestamp":1647006959644,"user_tz":-540,"elapsed":503,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"611e34b4-cc56-4ae6-b596-e532ba3b3740"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[-0.0175, -0.0060, -0.0251,  ...,  0.0293, -0.0258, -0.0341],\n","        [ 0.0007, -0.0295, -0.0096,  ..., -0.0269,  0.0298,  0.0083],\n","        [ 0.0201,  0.0189, -0.0330,  ..., -0.0082,  0.0135,  0.0053],\n","        ...,\n","        [ 0.0178,  0.0220,  0.0258,  ...,  0.0003,  0.0011,  0.0074],\n","        [ 0.0020, -0.0170, -0.0345,  ..., -0.0314, -0.0292, -0.0003],\n","        [-0.0113, -0.0169, -0.0195,  ..., -0.0068,  0.0018,  0.0051]])\n"]}]},{"cell_type":"code","source":["for name, param in model_unfreeze.named_parameters():\n","    if name == 'classifier.0.weight':\n","        print(name, param)\n","        print(param.grad)\n","\n","for param in model_unfreeze.parameters():\n","    param.requires_grad = False\n","\n","for name, param in model_unfreeze.named_parameters():\n","    if param.requires_grad == True:\n","        print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nehmq7NvStqZ","executionInfo":{"status":"ok","timestamp":1647006933345,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"6e202e2f-8c38-43ec-972f-8e1f65446107"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["classifier.0.weight Parameter containing:\n","tensor([[-0.0175, -0.0060, -0.0251,  ...,  0.0293, -0.0258, -0.0341],\n","        [ 0.0007, -0.0295, -0.0096,  ..., -0.0269,  0.0298,  0.0083],\n","        [ 0.0201,  0.0189, -0.0330,  ..., -0.0082,  0.0135,  0.0053],\n","        ...,\n","        [ 0.0178,  0.0220,  0.0258,  ...,  0.0003,  0.0011,  0.0074],\n","        [ 0.0020, -0.0170, -0.0345,  ..., -0.0314, -0.0292, -0.0003],\n","        [-0.0113, -0.0169, -0.0195,  ..., -0.0068,  0.0018,  0.0051]],\n","       requires_grad=True)\n","None\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:49:26.820569Z","start_time":"2022-01-31T13:49:26.816511Z"},"id":"sHkaFgC8UFxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646302837353,"user_tz":-540,"elapsed":332,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"b61db1e0-a5eb-4943-ace8-b11f31c84844"},"outputs":[{"output_type":"stream","name":"stdout","text":["CustomClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=768, out_features=32, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.1, inplace=False)\n","    (3): Linear(in_features=32, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["# 모든 파라미터의 gradient를 freeze 해보고 제대로 변경되었는지 \b확인하기 위해 모델의 모든 파라미터를 출력해보자.\n","print(model_unfreeze)"]},{"cell_type":"markdown","metadata":{"id":"NsMgM3sK5Q3t"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"vUn-6PFP5Q3t"},"source":["### `scheduler` 를 생성 \n","- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n","- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n","- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 `get_linear_schedule_with_warmup`는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "]},{"cell_type":"markdown","metadata":{"id":"_FuADvuT5Q3t"},"source":["### `model`, `optimizer`, `scheduler`를 초기화(=인스턴스 생성)하는 함수를 구현하라"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:59.217735Z","start_time":"2022-02-02T04:01:59.210482Z"},"id":"-sE7xjYcRD1p"},"outputs":[],"source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import AdamW\n","from torch.nn.utils import clip_grad_norm_\n","import torch.nn.functional as F\n","from transformers import get_linear_schedule_with_warmup, get_constant_schedule"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:59.549660Z","start_time":"2022-02-02T04:01:59.545752Z"},"id":"2eTFXzy8VK9R"},"outputs":[],"source":["# model:CustomClassifier 사용, hidden size는 768, label 개수는 2\n","# optimizer: AdamW 사용, learning rate는 2e-5\n","# scheduler: transformers.get_linear_schedule_with_warmup 함수 사용, 단, num_warmup_steps 매개 변수는 사용하지 않음\n","\n","def initializer(train_dataloader, epochs=2):\n","    \"\"\"\n","    모델, 옵티마이저, 스케쥴러를 초기화한 후 반환\n","    \"\"\"\n","    \n","    model = CustomClassifier(hidden_size=768, n_label=2)\n","\n","    optimizer = AdamW(\n","            model.parameters(),\n","            lr=2e-5,\n","    )\n","    \n","    total_steps = len(train_dataloader) * epochs\n","    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","    return model, optimizer, scheduler"]},{"cell_type":"markdown","metadata":{"id":"Xz-8_5as5Q3u"},"source":["### model, optimizer, scheduler의 파라미터 저장하는 함수를 구현하라\n","\n","참고 문서 : https://tutorials.pytorch.kr/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n","\n","\n","state_dict() 사용 이유\n","> 학습된 모델을 불러와서 사용할수 있도록 모델 내의 파라미터값을 저장해서 사용하게 되는데 그걸 출력하는 메소드가 state_dict()이다. \n","모델자체를 저장하기에는 너무 크기때문에 파라미터만 압축하여 저장한다.\n","\n","출처 : 6팀 정태호님"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:02.786877Z","start_time":"2022-02-02T04:02:02.783726Z"},"id":"vIP1BjFA5Q3u"},"outputs":[],"source":["# 모델 저장 함수 구현\n","\n","def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n","    file_name = f'{path}/model.ckpt.{epoch}'\n","    \n","    # torch.save 함수 참고\n","    torch.save(\n","        {\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss' : loss\n","        }, \n","        file_name\n","    )\n","    \n","    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"]},{"cell_type":"markdown","metadata":{"id":"a3BUrgtJ5Q3v"},"source":["### `validate()` 함수 구현 \n","- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n","- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:11.636684Z","start_time":"2022-02-02T04:02:11.631550Z"},"id":"VHpuV0CXUFxR"},"outputs":[],"source":["# input: model, valid_dataloader\n","# output: loss, 정확도\n","\n","def validate(model, valid_dataloader):\n","    global loss_fct\n","   \n","    # 모델을 evaluate 모드로 설정 & device 할당\n","    model.eval()\n","    \n","    total_loss, total_acc= 0,0\n","        \n","    for step, batch in enumerate(valid_dataloader):\n","        \n","        # tensor 연산 전, 각 tensor에 device 할당\n","        batch = tuple(item.to(device) for item in batch)\n","            \n","        batch_input, batch_label = batch\n","            \n","        # gradient 계산하지 않고 forward 진행\n","        with torch.no_grad():\n","            logits = model(input_ids = batch_input['input_ids'],\n","                           attention_mask = batch_input['attention_mask'],\n","                           token_type_ids = batch_input['token_type_ids'])\n","            \n","        # loss\n","        loss = loss_fct(logits, batch_label)\n","        total_loss += loss.item()\n","        \n","        # accuracy\n","        probs = F.softmax(logits, dim=1)\n","        preds = torch.argmax(probs, dim=1).flatten()\n","        acc = (preds == batch_label).cpu().numpy().mean()\n","        total_acc+=acc\n","    \n","    total_loss = total_loss/(step+1)\n","    total_acc = total_acc/(step+1)*100\n","\n","    return total_loss, total_acc"]},{"cell_type":"markdown","metadata":{"id":"NukaJc15UFxQ"},"source":["### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n","- data_loader를 `epoch`만큼 반복하면서 학습하도록 `train()` 함수를 수정하라\n","- `gradient cliping`은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n","- Reference\n","  - [clip_grad_norm_ official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n","  - [그래디언트 클립핑 설명 한국어 블로그](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:10.624280Z","start_time":"2022-02-02T04:02:10.615781Z"},"id":"ZvY5rxDKHQAp"},"outputs":[],"source":["# 위에서 구현한 모델 저장 함수(save_checkpoint)와 validate 함수도 추가해보자\n","\n","loss_fct = CrossEntropyLoss()\n","\n","def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n","        global scheduler, loss_fct\n","        \n","        # train_dataloaer 학습을 epochs만큼 반복\n","        for epoch in range(epochs):\n","            print(f\"*****Epoch {epoch} Train Start*****\")\n","            \n","            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n","            total_loss, batch_loss, batch_count = 0,0,0\n","        \n","            # model을 train 모드로 설정 & device 할당\n","            model.train()\n","            model.to(device)\n","            \n","            # data iterator를 돌면서 하나씩 학습\n","            for step, batch in enumerate(train_dataloader):\n","                batch_count+=1\n","                \n","                # tensor 연산 전, 각 tensor에 device 할당\n","                batch = tuple(item.to(device) for item in batch)\n","            \n","                batch_input, batch_label = batch\n","            \n","                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n","                model.zero_grad()\n","            \n","                # forward\n","                logits = model(**batch_input)\n","            \n","                # loss\n","                loss = loss_fct(logits, batch_label)\n","                batch_loss += loss.item()\n","                total_loss += loss.item()\n","            \n","                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n","                loss.backward()\n","                \n","                # gradient clipping 적용 (max_norm = 1)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","                \n","                # optimizer & scheduler 업데이트\n","                optimizer.step()\n","                scheduler.step()\n","                \n","                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n","                if (step % 10 == 0 and step != 0):\n","                    learning_rate = optimizer.param_groups[0]['lr']\n","                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n","\n","                    # reset \n","                    batch_loss, batch_count = 0,0\n","\n","            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n","            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n","            \n","            if valid_dataloader is not None:\n","                print(f\"*****Epoch {epoch} Valid Start*****\")\n","                valid_loss, valid_acc = validate(model, valid_dataloader)\n","                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n","                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n","            \n","            # checkpoint 저장\n","            path = '/content/drive/MyDrive/원티드AIML'\n","            save_checkpoint(path, model, optimizer, scheduler, epoch, loss)\n","                \n","        print(\"Train Completed. End Program.\")"]},{"cell_type":"markdown","metadata":{"id":"4NWKzxIaf1QJ"},"source":["## Advanced"]},{"cell_type":"markdown","metadata":{"id":"gFWnii7a5Q3w"},"source":["### 학습 데이터를 epoch 4까지 학습\n","- 매 epoch마다 다음을 수행한다.\n","  - 학습이 끝난 후 validate() 함수 실행 \n","  - validate() 함수가 끝난 후 model save 함수 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:02:11.377612Z","start_time":"2022-02-02T04:02:20.931961Z"},"id":"7Er1qKtsf1QJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646304783499,"user_tz":-540,"elapsed":526080,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"63aa75fb-63a8-4ded-bcbf-dc7447c64ea4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Total train steps with 4 epochs: 1128\n","*****Epoch 0 Train Start*****\n","Epoch: 0, Step : 10, LR : 1.9804964539007094e-05, Avg Loss : 0.6742\n","Epoch: 0, Step : 20, LR : 1.962765957446809e-05, Avg Loss : 0.5924\n","Epoch: 0, Step : 30, LR : 1.945035460992908e-05, Avg Loss : 0.5102\n","Epoch: 0, Step : 40, LR : 1.927304964539007e-05, Avg Loss : 0.4393\n","Epoch: 0, Step : 50, LR : 1.9095744680851064e-05, Avg Loss : 0.4853\n","Epoch: 0, Step : 60, LR : 1.891843971631206e-05, Avg Loss : 0.4159\n","Epoch: 0, Step : 70, LR : 1.8741134751773053e-05, Avg Loss : 0.4111\n","Epoch: 0, Step : 80, LR : 1.8563829787234043e-05, Avg Loss : 0.4145\n","Epoch: 0, Step : 90, LR : 1.8386524822695038e-05, Avg Loss : 0.3975\n","Epoch: 0, Step : 100, LR : 1.8209219858156032e-05, Avg Loss : 0.4131\n","Epoch: 0, Step : 110, LR : 1.8031914893617023e-05, Avg Loss : 0.4109\n","Epoch: 0, Step : 120, LR : 1.7854609929078013e-05, Avg Loss : 0.4127\n","Epoch: 0, Step : 130, LR : 1.7677304964539008e-05, Avg Loss : 0.3709\n","Epoch: 0, Step : 140, LR : 1.7500000000000002e-05, Avg Loss : 0.3598\n","Epoch: 0, Step : 150, LR : 1.7322695035460996e-05, Avg Loss : 0.3821\n","Epoch: 0, Step : 160, LR : 1.7145390070921987e-05, Avg Loss : 0.3469\n","Epoch: 0, Step : 170, LR : 1.696808510638298e-05, Avg Loss : 0.3787\n","Epoch: 0, Step : 180, LR : 1.6790780141843972e-05, Avg Loss : 0.3788\n","Epoch: 0, Step : 190, LR : 1.6613475177304966e-05, Avg Loss : 0.3477\n","Epoch: 0, Step : 200, LR : 1.6436170212765957e-05, Avg Loss : 0.3907\n","Epoch: 0, Step : 210, LR : 1.625886524822695e-05, Avg Loss : 0.2963\n","Epoch: 0, Step : 220, LR : 1.6081560283687945e-05, Avg Loss : 0.4272\n","Epoch: 0, Step : 230, LR : 1.590425531914894e-05, Avg Loss : 0.3585\n","Epoch: 0, Step : 240, LR : 1.572695035460993e-05, Avg Loss : 0.3549\n","Epoch: 0, Step : 250, LR : 1.5549645390070924e-05, Avg Loss : 0.3848\n","Epoch: 0, Step : 260, LR : 1.5372340425531915e-05, Avg Loss : 0.3507\n","Epoch: 0, Step : 270, LR : 1.5195035460992908e-05, Avg Loss : 0.3194\n","Epoch: 0, Step : 280, LR : 1.5017730496453902e-05, Avg Loss : 0.3572\n","Epoch 0 Total Mean Loss : 0.4076\n","*****Epoch 0 Train Finish*****\n","\n","*****Epoch 0 Valid Start*****\n","Epoch 0 Valid Loss : 0.3582 Valid Acc : 86.04\n","*****Epoch 0 Valid Finish*****\n","\n","Saving epoch 0 checkpoint at /content/drive/MyDrive/원티드AIML/model.ckpt.0\n","*****Epoch 1 Train Start*****\n","Epoch: 1, Step : 10, LR : 1.4804964539007095e-05, Avg Loss : 0.2286\n","Epoch: 1, Step : 20, LR : 1.4627659574468087e-05, Avg Loss : 0.2429\n","Epoch: 1, Step : 30, LR : 1.4450354609929078e-05, Avg Loss : 0.2910\n","Epoch: 1, Step : 40, LR : 1.427304964539007e-05, Avg Loss : 0.2590\n","Epoch: 1, Step : 50, LR : 1.4095744680851065e-05, Avg Loss : 0.2603\n","Epoch: 1, Step : 60, LR : 1.3918439716312057e-05, Avg Loss : 0.2072\n","Epoch: 1, Step : 70, LR : 1.3741134751773051e-05, Avg Loss : 0.2033\n","Epoch: 1, Step : 80, LR : 1.3563829787234044e-05, Avg Loss : 0.2988\n","Epoch: 1, Step : 90, LR : 1.3386524822695038e-05, Avg Loss : 0.2770\n","Epoch: 1, Step : 100, LR : 1.320921985815603e-05, Avg Loss : 0.2301\n","Epoch: 1, Step : 110, LR : 1.3031914893617021e-05, Avg Loss : 0.2372\n","Epoch: 1, Step : 120, LR : 1.2854609929078014e-05, Avg Loss : 0.2960\n","Epoch: 1, Step : 130, LR : 1.2677304964539008e-05, Avg Loss : 0.2474\n","Epoch: 1, Step : 140, LR : 1.25e-05, Avg Loss : 0.2436\n","Epoch: 1, Step : 150, LR : 1.2322695035460995e-05, Avg Loss : 0.2925\n","Epoch: 1, Step : 160, LR : 1.2145390070921987e-05, Avg Loss : 0.2612\n","Epoch: 1, Step : 170, LR : 1.196808510638298e-05, Avg Loss : 0.2259\n","Epoch: 1, Step : 180, LR : 1.1790780141843972e-05, Avg Loss : 0.2993\n","Epoch: 1, Step : 190, LR : 1.1613475177304965e-05, Avg Loss : 0.2597\n","Epoch: 1, Step : 200, LR : 1.1436170212765957e-05, Avg Loss : 0.2383\n","Epoch: 1, Step : 210, LR : 1.1258865248226952e-05, Avg Loss : 0.2493\n","Epoch: 1, Step : 220, LR : 1.1081560283687944e-05, Avg Loss : 0.2586\n","Epoch: 1, Step : 230, LR : 1.0904255319148938e-05, Avg Loss : 0.2089\n","Epoch: 1, Step : 240, LR : 1.072695035460993e-05, Avg Loss : 0.2179\n","Epoch: 1, Step : 250, LR : 1.0549645390070923e-05, Avg Loss : 0.2434\n","Epoch: 1, Step : 260, LR : 1.0372340425531916e-05, Avg Loss : 0.2743\n","Epoch: 1, Step : 270, LR : 1.0195035460992908e-05, Avg Loss : 0.2710\n","Epoch: 1, Step : 280, LR : 1.00177304964539e-05, Avg Loss : 0.2544\n","Epoch 1 Total Mean Loss : 0.2527\n","*****Epoch 1 Train Finish*****\n","\n","*****Epoch 1 Valid Start*****\n","Epoch 1 Valid Loss : 0.3905 Valid Acc : 83.42\n","*****Epoch 1 Valid Finish*****\n","\n","Saving epoch 1 checkpoint at /content/drive/MyDrive/원티드AIML/model.ckpt.1\n","*****Epoch 2 Train Start*****\n","Epoch: 2, Step : 10, LR : 9.804964539007093e-06, Avg Loss : 0.1966\n","Epoch: 2, Step : 20, LR : 9.627659574468086e-06, Avg Loss : 0.1865\n","Epoch: 2, Step : 30, LR : 9.450354609929078e-06, Avg Loss : 0.1693\n","Epoch: 2, Step : 40, LR : 9.273049645390073e-06, Avg Loss : 0.1747\n","Epoch: 2, Step : 50, LR : 9.095744680851063e-06, Avg Loss : 0.2590\n","Epoch: 2, Step : 60, LR : 8.918439716312058e-06, Avg Loss : 0.1762\n","Epoch: 2, Step : 70, LR : 8.74113475177305e-06, Avg Loss : 0.1696\n","Epoch: 2, Step : 80, LR : 8.563829787234044e-06, Avg Loss : 0.1787\n","Epoch: 2, Step : 90, LR : 8.386524822695035e-06, Avg Loss : 0.1289\n","Epoch: 2, Step : 100, LR : 8.20921985815603e-06, Avg Loss : 0.1605\n","Epoch: 2, Step : 110, LR : 8.031914893617022e-06, Avg Loss : 0.1655\n","Epoch: 2, Step : 120, LR : 7.854609929078016e-06, Avg Loss : 0.2161\n","Epoch: 2, Step : 130, LR : 7.677304964539007e-06, Avg Loss : 0.1595\n","Epoch: 2, Step : 140, LR : 7.500000000000001e-06, Avg Loss : 0.1357\n","Epoch: 2, Step : 150, LR : 7.3226950354609935e-06, Avg Loss : 0.2033\n","Epoch: 2, Step : 160, LR : 7.145390070921986e-06, Avg Loss : 0.1857\n","Epoch: 2, Step : 170, LR : 6.968085106382979e-06, Avg Loss : 0.1788\n","Epoch: 2, Step : 180, LR : 6.790780141843972e-06, Avg Loss : 0.1625\n","Epoch: 2, Step : 190, LR : 6.613475177304965e-06, Avg Loss : 0.1763\n","Epoch: 2, Step : 200, LR : 6.436170212765958e-06, Avg Loss : 0.1640\n","Epoch: 2, Step : 210, LR : 6.258865248226951e-06, Avg Loss : 0.1347\n","Epoch: 2, Step : 220, LR : 6.081560283687944e-06, Avg Loss : 0.1784\n","Epoch: 2, Step : 230, LR : 5.904255319148937e-06, Avg Loss : 0.1744\n","Epoch: 2, Step : 240, LR : 5.7269503546099295e-06, Avg Loss : 0.1489\n","Epoch: 2, Step : 250, LR : 5.549645390070923e-06, Avg Loss : 0.1638\n","Epoch: 2, Step : 260, LR : 5.372340425531915e-06, Avg Loss : 0.1546\n","Epoch: 2, Step : 270, LR : 5.195035460992908e-06, Avg Loss : 0.1333\n","Epoch: 2, Step : 280, LR : 5.017730496453901e-06, Avg Loss : 0.1794\n","Epoch 2 Total Mean Loss : 0.1722\n","*****Epoch 2 Train Finish*****\n","\n","*****Epoch 2 Valid Start*****\n","Epoch 2 Valid Loss : 0.4361 Valid Acc : 84.71\n","*****Epoch 2 Valid Finish*****\n","\n","Saving epoch 2 checkpoint at /content/drive/MyDrive/원티드AIML/model.ckpt.2\n","*****Epoch 3 Train Start*****\n","Epoch: 3, Step : 10, LR : 4.804964539007093e-06, Avg Loss : 0.1141\n","Epoch: 3, Step : 20, LR : 4.6276595744680855e-06, Avg Loss : 0.1225\n","Epoch: 3, Step : 30, LR : 4.450354609929078e-06, Avg Loss : 0.1115\n","Epoch: 3, Step : 40, LR : 4.273049645390071e-06, Avg Loss : 0.1041\n","Epoch: 3, Step : 50, LR : 4.095744680851064e-06, Avg Loss : 0.1025\n","Epoch: 3, Step : 60, LR : 3.918439716312057e-06, Avg Loss : 0.1086\n","Epoch: 3, Step : 70, LR : 3.74113475177305e-06, Avg Loss : 0.1413\n","Epoch: 3, Step : 80, LR : 3.5638297872340426e-06, Avg Loss : 0.1219\n","Epoch: 3, Step : 90, LR : 3.386524822695036e-06, Avg Loss : 0.0749\n","Epoch: 3, Step : 100, LR : 3.2092198581560285e-06, Avg Loss : 0.0870\n","Epoch: 3, Step : 110, LR : 3.031914893617022e-06, Avg Loss : 0.1431\n","Epoch: 3, Step : 120, LR : 2.8546099290780144e-06, Avg Loss : 0.1319\n","Epoch: 3, Step : 130, LR : 2.6773049645390077e-06, Avg Loss : 0.1465\n","Epoch: 3, Step : 140, LR : 2.5e-06, Avg Loss : 0.1042\n","Epoch: 3, Step : 150, LR : 2.322695035460993e-06, Avg Loss : 0.1339\n","Epoch: 3, Step : 160, LR : 2.145390070921986e-06, Avg Loss : 0.1149\n","Epoch: 3, Step : 170, LR : 1.968085106382979e-06, Avg Loss : 0.1358\n","Epoch: 3, Step : 180, LR : 1.790780141843972e-06, Avg Loss : 0.1304\n","Epoch: 3, Step : 190, LR : 1.6134751773049648e-06, Avg Loss : 0.1094\n","Epoch: 3, Step : 200, LR : 1.4361702127659578e-06, Avg Loss : 0.1620\n","Epoch: 3, Step : 210, LR : 1.2588652482269503e-06, Avg Loss : 0.1687\n","Epoch: 3, Step : 220, LR : 1.0815602836879434e-06, Avg Loss : 0.1196\n","Epoch: 3, Step : 230, LR : 9.042553191489363e-07, Avg Loss : 0.1047\n","Epoch: 3, Step : 240, LR : 7.26950354609929e-07, Avg Loss : 0.0973\n","Epoch: 3, Step : 250, LR : 5.496453900709221e-07, Avg Loss : 0.1958\n","Epoch: 3, Step : 260, LR : 3.723404255319149e-07, Avg Loss : 0.0985\n","Epoch: 3, Step : 270, LR : 1.9503546099290782e-07, Avg Loss : 0.1673\n","Epoch: 3, Step : 280, LR : 1.773049645390071e-08, Avg Loss : 0.0638\n","Epoch 3 Total Mean Loss : 0.1224\n","*****Epoch 3 Train Finish*****\n","\n","*****Epoch 3 Valid Start*****\n","Epoch 3 Valid Loss : 0.4727 Valid Acc : 85.37\n","*****Epoch 3 Valid Finish*****\n","\n","Saving epoch 3 checkpoint at /content/drive/MyDrive/원티드AIML/model.ckpt.3\n","Train Completed. End Program.\n"]}],"source":["# 4 epoch 학습\n","epochs=4\n","model, optimizer, scheduler = initializer(train_dataloader, epochs)\n","train(model, train_dataloader, valid_dataloader, epochs)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2022-02-02T03:27:18.246441Z","start_time":"2022-02-02T03:27:18.236617Z"},"id":"vA3_vqqCXccc"},"source":["### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:27.646150Z","start_time":"2022-02-02T06:22:26.945572Z"},"id":"mvfkSff25Q3z"},"outputs":[],"source":["# torch.load 함수 사용\n","best_model_path = '/content/drive/MyDrive/원티드AIML/model.ckpt.0'\n","checkpoint = torch.load(best_model_path, map_location=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:36.415665Z","start_time":"2022-02-02T06:22:36.407250Z"},"id":"YqcxMmTj5Q3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646304921314,"user_tz":-540,"elapsed":317,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"aa89cda7-b463-4c57-faff-258aef588d13"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"]},"metadata":{},"execution_count":79}],"source":["# checkpoint의 key 종류를 확인\n","checkpoint.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:40.272939Z","start_time":"2022-02-02T06:22:37.010491Z"},"id":"wTvFYgNi5Q30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646304925393,"user_tz":-540,"elapsed":2663,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"d2076883-9637-4f3b-d255-3eddc5cd0586"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Total train steps with 1 epochs: 282\n"]}],"source":["# 위에서 구현한 initializer 함수 사용하여 model, optimizer, scheduler 초기화\n","\n","epochs=1\n","model, optimizer, scheduler = model, optimizer, scheduler = initializer(train_dataloader, epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:40.443912Z","start_time":"2022-02-02T06:22:40.274323Z"},"id":"CtR2sTW55Q30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646304927007,"user_tz":-540,"elapsed":384,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"33a57590-66eb-4ad7-a4b7-c3225f1fa909"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":81}],"source":["model.load_state_dict(checkpoint[\"model_state_dict\"])"]},{"cell_type":"markdown","metadata":{"id":"Tzske7SR5Q30"},"source":["### 모델 예측 함수 구현\n","- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n","- 함수 정의\n","  - 입력 매개변수\n","    - `model` : `CustomClassifier` 모델. logits를 반환함 \n","    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n","  - 조건\n","    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n","  - 반환값\n","    - `probs`\n","      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n","    - `labels`\n","      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:48.062229Z","start_time":"2022-02-02T06:22:48.057531Z"},"id":"yQ7WiD1Oigg9"},"outputs":[],"source":["def predict(model, test_dataloader):\n","    \"\"\"\n","    test_dataloader의 label별 확률값과 실제 label 값을 반환\n","    \"\"\"\n","\n","    # model을 eval 모드로 설정 & device 할당\n","    model.eval()\n","    model.to(device)\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        \n","        batch_input, batch_label = batch\n","        \n","        # batch_input을 device 할당\n","        batch_input.to(device)\n","\n","        # model에 batch_input을 넣어 logit 반환 & all_logits, all_labels 리스트에 값 추가 \n","        with torch.no_grad():\n","            logits = model(input_ids = batch_input['input_ids'],\n","                           attention_mask = batch_input['attention_mask'],\n","                           token_type_ids = batch_input['token_type_ids'])\n","            \n","        # logits을 확률값으로 변환 & Tensor 타입을 numpy.array 타입으로 변환\n","        probs = F.softmax(logits, dim=1)\n","        all_logits.append(probs.cpu().numpy())\n","        # Tensor 타입을 numpy.array 타입으로 변환\n","        all_labels.append(batch_label.cpu().numpy())\n","\n","    return all_logits, all_labels"]},{"cell_type":"markdown","source":["- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n","- 함수 정의 \n","  - 입력 매개변수 \n","    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n","    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n","  - 조건\n","    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n","  - 반환값 \n","    - `acc` : 정확도 (Float type)"],"metadata":{"id":"lOxCjZ2g6ZeK"}},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:22.752497Z","start_time":"2022-02-02T06:22:48.652784Z"},"id":"SwkrRPAhjsXb"},"outputs":[],"source":["probs, labels = predict(model, test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:48.296419Z","start_time":"2022-02-02T06:22:48.293737Z"},"id":"42-umZ3m5Q32"},"outputs":[],"source":["# # accuracy 함수 구현, torch.argmax 활용\n","# import itertools\n","# def accuracy(probs, labels):\n","#     y_pred = []\n","#     for prob in probs:\n","#         # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)\n","#         y_pred.append(torch.argmax(torch.tensor(prob), dim=1).flatten().tolist())\n","#     y_pred = sum(y_pred, [])\n","#     acc = (np.array(y_pred) == np.array(labels)).mean() # 정확도 계산\n","#     return acc "]},{"cell_type":"code","source":["def accuracy(probs, labels):\n","    y_pred = []\n","    for prob in probs:\n","        # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)\n","        for p in prob:\n","            if p[0] >= 0.5:\n","                y_pred.append(0)\n","            else:\n","                y_pred.append(1)\n","    acc = (np.array(y_pred) == np.array(labels)).mean() # 정확도 계산\n","    return acc "],"metadata":{"id":"dOdIglfZqVZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:22.759367Z","start_time":"2022-02-02T06:24:22.753997Z"},"id":"MxDI8PRA5Q32","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646309029472,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"72c453b1-c0b2-41a2-dbc4-307c3be78598"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.869"]},"metadata":{},"execution_count":254}],"source":["import itertools\n","accuracy(probs, list(itertools.chain(*labels)))"]},{"cell_type":"markdown","metadata":{"id":"3mqUfkx-5Q33"},"source":["### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.111879Z","start_time":"2022-02-02T06:24:22.760568Z"},"id":"VFWj4lcp5Q33"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.116872Z","start_time":"2022-02-02T06:24:23.113064Z"},"id":"p9BEe2mflTem","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646309065799,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"384fbb43-f304-455e-fdc6-ab6dec2a858c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.869"]},"metadata":{},"execution_count":255}],"source":["# 정확도 출력\n","# y_pred = []\n","# for prob in probs:\n","#     # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)\n","#     y_pred.append(torch.argmax(torch.tensor(prob), dim=1).flatten().tolist())\n","# y_pred = sum(y_pred, [])\n","\n","y_pred = []\n","for prob in probs:\n","    # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)\n","    for p in prob:\n","        if p[0] >= 0.5:\n","            y_pred.append(0)\n","        else:\n","            y_pred.append(1)\n","\n","y_true = list(itertools.chain(*labels))\n","\n","accuracy_score(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.125650Z","start_time":"2022-02-02T06:24:23.117847Z"},"id":"oCl6BiPGpCPW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646309067626,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jia Son","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02994747840857838932"}},"outputId":"7de51e74-9bfd-4bd7-f854-01e51b63212f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.869"]},"metadata":{},"execution_count":256}],"source":["# auc 출력\n","\n","roc_auc_score(y_true, y_pred)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Week2-4-assignment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"75c5fb9269cd498181073c95a6e1aac0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8651ce9c63c44f9b218404a133899b8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_deefbdf568514e05a8eff335446579a2","IPY_MODEL_10c3e83c7ee84e93bc655751e145a155","IPY_MODEL_65927d41de07489bb087ca843ef6120b"]}},"e8651ce9c63c44f9b218404a133899b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"deefbdf568514e05a8eff335446579a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3fbabd4123a949c789ab66e9dd672a47","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31a83fdc4bc74ab7a32f770522942426"}},"10c3e83c7ee84e93bc655751e145a155":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ca9def0b44d436ba7eaf0691f292e1f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":248477,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":248477,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5dee13cfe5d045a48555d2c2a66029eb"}},"65927d41de07489bb087ca843ef6120b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7bbb9bb93f9d47dd91ccafb90c5dae45","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243k/243k [00:00&lt;00:00, 330kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5db4565d13684e54b3aa7df731b7273e"}},"3fbabd4123a949c789ab66e9dd672a47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"31a83fdc4bc74ab7a32f770522942426":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ca9def0b44d436ba7eaf0691f292e1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5dee13cfe5d045a48555d2c2a66029eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bbb9bb93f9d47dd91ccafb90c5dae45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5db4565d13684e54b3aa7df731b7273e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba12f92c30674e3287a7c4ea34a81a45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_52b412f2316b41ed867d5f557aac7cb6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b60c9951329b4008917b2bbb92ae0ea4","IPY_MODEL_68528f9910fd4ab8a5bc7d73cd35fe74","IPY_MODEL_0ab5c0db96b54144bb08a93ae198bd18"]}},"52b412f2316b41ed867d5f557aac7cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b60c9951329b4008917b2bbb92ae0ea4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_82432a99b03a4f74bffb62de7974f857","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8faa0d05d744342ac025c74ea647604"}},"68528f9910fd4ab8a5bc7d73cd35fe74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dcce093850434a3eab4871fc174f337f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec5bd6d89e7b49dda183f6fdb88f3360"}},"0ab5c0db96b54144bb08a93ae198bd18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffc79e5830ca4c5e9911af6591ae24b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [00:00&lt;00:00, 3.08kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49b56514fdf746df8be88cb244a165ef"}},"82432a99b03a4f74bffb62de7974f857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c8faa0d05d744342ac025c74ea647604":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dcce093850434a3eab4871fc174f337f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec5bd6d89e7b49dda183f6fdb88f3360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffc79e5830ca4c5e9911af6591ae24b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"49b56514fdf746df8be88cb244a165ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b29a567a39604d5fb748f84998bc6462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1450549409c24560b8f240fff2770572","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d052a40e8e024fd78c06362f3f5b8152","IPY_MODEL_d140ddd4d0064271a15c9cd4528589a4","IPY_MODEL_965f77110fb34c309eb35234abcc1c1b"]}},"1450549409c24560b8f240fff2770572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d052a40e8e024fd78c06362f3f5b8152":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_48be6e17df154f808c3f91be6933e934","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba803d53e5e448cc8ffe703f1631b437"}},"d140ddd4d0064271a15c9cd4528589a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0e1825789dac492dbe6abf5c498e82e2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01eb81393938461db3b9b47f6f9a988f"}},"965f77110fb34c309eb35234abcc1c1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62e39072041a40f487ca925327c94589","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 289/289 [00:00&lt;00:00, 6.97kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b74a950804b49b5a341bd0c75207d19"}},"48be6e17df154f808c3f91be6933e934":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba803d53e5e448cc8ffe703f1631b437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e1825789dac492dbe6abf5c498e82e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01eb81393938461db3b9b47f6f9a988f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62e39072041a40f487ca925327c94589":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b74a950804b49b5a341bd0c75207d19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80e25a7acf574b1ab74782ad8fe61fef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9de0e622506d49f58f5d247595459d70","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_31fcb498557a43e2a422c6e9298e5eaa","IPY_MODEL_1976e65653c44a83bcae45e50536f471","IPY_MODEL_c387651d73684e54b30e91e8df09880b"]}},"9de0e622506d49f58f5d247595459d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31fcb498557a43e2a422c6e9298e5eaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a98daca006a840588d429206ab74c173","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29d11763898a4b6eb402ef292c8da2cb"}},"1976e65653c44a83bcae45e50536f471":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c13b279cfb1448e184edba95c53dce69","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":425,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":425,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c4d59702f41c4a998981f60a9fc644d3"}},"c387651d73684e54b30e91e8df09880b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0c7a223f2425421e97eca737993447c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 425/425 [00:00&lt;00:00, 10.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f3f8561176c472ab1a7e521294bf59f"}},"a98daca006a840588d429206ab74c173":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"29d11763898a4b6eb402ef292c8da2cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c13b279cfb1448e184edba95c53dce69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c4d59702f41c4a998981f60a9fc644d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c7a223f2425421e97eca737993447c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3f3f8561176c472ab1a7e521294bf59f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfa1f3a906f64842b0f09c080d4f0b7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_70649b72c20a4abda9bccbd6fa775c38","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_99bd9c603e1a4e9d9d59077ca7e3e2b4","IPY_MODEL_83577a824faf43ceac2107a2a7fc674c","IPY_MODEL_90ed4f3323af4813ba20fb29aa966b0a"]}},"70649b72c20a4abda9bccbd6fa775c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99bd9c603e1a4e9d9d59077ca7e3e2b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9f17301f28a34e5183cc77b26f1b2ce3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fe03b60c06c4092a8c9ae62731acfb4"}},"83577a824faf43ceac2107a2a7fc674c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7dbbc00275b24816b7395fde0505396e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":445025130,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445025130,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_179873c4a1c743a3be03d3f8ff57c57f"}},"90ed4f3323af4813ba20fb29aa966b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8f478d01a0df4678bc7a7407b6d365c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 424M/424M [00:19&lt;00:00, 33.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f7f65a988fb47c088072160eeb20097"}},"9f17301f28a34e5183cc77b26f1b2ce3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7fe03b60c06c4092a8c9ae62731acfb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7dbbc00275b24816b7395fde0505396e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"179873c4a1c743a3be03d3f8ff57c57f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f478d01a0df4678bc7a7407b6d365c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f7f65a988fb47c088072160eeb20097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}